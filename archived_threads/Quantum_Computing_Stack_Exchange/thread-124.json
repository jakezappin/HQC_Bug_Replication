{"question": "\nI'm trying to reproduce the basic method of classical shadow, which is based on the tutorial of pennylane. However, I've met some realization problems here when I finish reading the tutorial of pennylane, and trying to finish the method myself, just to check if my understanding is correct, because I'm not sure if my understanding about the inverse of the map MM mentioned in the paper is correct.\nI will describe the method shortly first, and then showing my code with qiskit, pennylane, and matlab. But all of them failed to have the same effect as the tutorial of pennylane does(increasing the number of measurements, the distance between the state I want to reconstruct and the original state should be more and more close).\nThe idea of classical shadow(or the process of the algorithm) is kind of simple while the math behind it might be complicated. The process states that for any density matrix \u03c1\u03c1, we act some unitary matrix UU which are chosen randomly from a specific set of the unitary matrix UU on it, i.e., U\u03c1U\u2020U\u03c1U\u2020. Then we do one-shot measurement based on the computational basis on U\u03c1U\u2020U\u03c1U\u2020. Then the state will collapse into some state |b^\u27e9|b^\u27e9. And then we do the rest of the work in classical data analysis style. First we undo the unitary matrix, i.e., U\u2020|b^\u27e9\u27e8b^|UU\u2020|b^\u27e9\u27e8b^|U . Then we do the inverse of the map \u03c1^\u2261M\u22121(U\u2020|b^\u27e9\u27e8b^|U)\u03c1^\u2261M\u22121(U\u2020|b^\u27e9\u27e8b^|U) which can be defined as M(\u03c1)\u2261E(U\u2020|b^\u27e9\u27e8b^|U)M(\u03c1)\u2261E(U\u2020|b^\u27e9\u27e8b^|U), where the EE stands for expectation over both unitary matrix and measurement result |b^\u27e9|b^\u27e9.  And for a specific choice of unitary set(seems Clifford group, not very clear here), we have a form of the inverse of MM states as\n\u03c1^=\u2a02j=1n(3U\u2020j|b^j\u27e9\u27e8b^j|Uj\u2212I)(1)(1)\u03c1^=\u2a02j=1n(3Uj\u2020|b^j\u27e9\u27e8b^j|Uj\u2212I)\nThen I will introduce my code first. We specify the unitary group into Hadamard gate, phase gate, and identity. Then we do the computational basis measurement and rebuild the classical shadow \u03c1^\u03c1^ with the help of eq.(1), and then calculate the expectation value of \u03c1^\u03c1^ by directly divide measurement times.\nFollowing the codes(pennylane, qiskit, Matlab), aiming at construct the classical shadow of bell state:\nfrom networkx.algorithms.centrality import harmonic\nfrom networkx.exception import HasACycle\nfrom networkx.readwrite.sparse6 import write_sparse6\nfrom numpy import dtype\nfrom numpy.random.mtrand import rand\nimport pennylane as qml\nfrom pennylane import wires\nimport pennylane.numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\ndef distance(rho):\n    return np.sqrt(np.trace(rho.conjugate().transpose() @ rho))\n\ndef my_quantum_function(x, y):\n    unitary = [qml.Hadamard, qml.S, qml.Identity]\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n        \n    unitary[y[0]](wires=0)\n    unitary[y[1]](wires=1)\n\n    # all measure in computational basis, i.e., mean value of pauliz, one-shot case\n    return [qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1))]\n\n# one-shot case shots = 1 to simulate the measure in computational basis requirement\ndev = qml.device('default.qubit', wires=2, shots=1)\ncircuit = qml.QNode(my_quantum_function, dev)\n\n# generate random number seed for easy replicate the experiment\nnp.random.seed(666)\n\n# init\nphase_z = np.array([[1, 0], [0, 1j]], dtype=complex)\nhadamard = qml.Hadamard(0).matrix\nidentity = qml.Identity(0).matrix\n\nunitary = [hadamard, phase_z, identity]\n\nsnapshot = 1000\nstate0 = np.array([[1,0],[0,0]])\nstate1 = np.array([[0,0],[0,1]])\nrecord_rho = np.zeros([4,4])\n\nfor i in range(snapshot):\n    randnum = np.random.randint(0,3,size=2)\n    [res0, res1] = circuit(0,randnum)\n    # print(circuit.draw())\n    if res0 == 1:\n        rho1 = 3*(unitary[randnum[0]].conj().T @ state0 @ unitary[randnum[0]]) - identity\n    else:\n        rho1 = 3*(unitary[randnum[0]].conj().T @ state1 @ unitary[randnum[0]]) - identity\n\n    if res0 == 1:\n        rho2 = 3*(unitary[randnum[1]].conj().T @ state0 @ unitary[randnum[1]]) - identity\n    else:\n        rho2 = 3*(unitary[randnum[1]].conj().T @ state1 @ unitary[randnum[1]]) - identity\n\n    record_rho = record_rho + np.kron(rho1,rho2)\n\nrecord_rho = record_rho/snapshot\nbell_state = np.array([[0.5, 0, 0, 0.5], [0, 0, 0, 0], [0, 0, 0, 0], [0.5, 0, 0, 0.5]])\nprint(record_rho)\n\nprint(distance(record_rho - bell_state))\n\n\nfrom math import exp\nfrom qiskit import *\nfrom qiskit import Aer\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom random import randrange\n\nnp.random.seed(222)\ndef one_shot(operator):\n    \n    sim = Aer.get_backend('aer_simulator')\n    qc = QuantumCircuit(2)\n    unitary = [qc.h, qc.sdg, qc.id]\n    qc.h(0)\n    qc.cx(0,1)\n    unitary[operator[0]](0)\n    unitary[operator[1]](1)\n    qc.measure_all()\n\n    qobj = assemble(qc,shots=1)\n    result = sim.run(qobj).result().get_counts()\n    return result\n\ndef distance(rho):\n    '''\n    calculate distance of two density matrix\n    '''\n    return np.sqrt(np.trace(rho.conjugate().transpose().dot(rho)))\n\nhadamard = 1/np.sqrt(2)*np.array([[1,1],[1,-1]])\ns_gate = np.array([[1,0],[0,-1j]],dtype=complex)\nid = np.identity(2)\nunitary = [hadamard,np.dot(hadamard,s_gate),id]\n\nsnapshot_num = 1000\nstate0 = np.array([[1,0],[0,0]])\nstate1 = np.array([[0,0],[0,1]])\nrecord_rho = np.zeros([4,4])\nfor i in range(snapshot_num):\n    randnum = np.random.randint(0,3,size=2)\n    result = one_shot(randnum)\n    if result.get('00') == 1:\n        rho = np.kron(3*np.dot(unitary[randnum[0]].conj().T,state0).dot(unitary[randnum[0]] - id),3*np.dot(unitary[randnum[1]].conj().T,state0).dot(unitary[randnum[1]]) - id)\n    elif result.get('01') == 1:\n        rho = np.kron(3*np.dot(unitary[randnum[0]].conj().T,state0).dot(unitary[randnum[0]] - id),3*np.dot(unitary[randnum[1]].conj().T,state1).dot(unitary[randnum[1]]) - id)\n    elif result.get('10') == 1:\n        rho = np.kron(3*np.dot(unitary[randnum[0]].conj().T,state1).dot(unitary[randnum[0]] - id),3*np.dot(unitary[randnum[1]].conj().T,state0).dot(unitary[randnum[1]]) - id)\n    else:\n        rho = np.kron(3*np.dot(unitary[randnum[0]].conj().T,state1).dot(unitary[randnum[0]] - id),3*np.dot(unitary[randnum[1]].conj().T,state1).dot(unitary[randnum[1]]) - id)\n\n    record_rho = record_rho + rho\nrecord_rho = record_rho/snapshot_num\nbell_state = np.array([[0.5, 0, 0, 0.5], [0, 0, 0, 0], [0, 0, 0, 0], [0.5, 0, 0, 0.5]])\nprint(record_rho)\nprint(distance(record_rho - bell_state))\n\n\n% Pauli matrix as random unitary\npauli = eye(2);\npauli(:,:,2) = [1 0;0 -1j]; pauli(:,:,3) = 1/sqrt(2)*pauli(:,:,2)'*[1 1;1 -1];\n% two computational basis |0) and |1)\nstate = eye(4);\nstate0 = [1;0];\nstate1 = [0;1];\n\npsi = 1/sqrt(2)*[1;0;0;1];\nrho = psi*psi';\nrecord_rho = zeros(4);\nn = 6000;\nfor i = 1:n\n    randnum = randi([1 3],[1 2]);\n    rhot = kron(pauli(:,:,randnum(1)),pauli(:,:,randnum(2)))*rho*kron(pauli(:,:,randnum(1)),pauli(:,:,randnum(2)))';\n    prob1 = state(:,1)'*rhot*state(:,1);\n    prob2 = state(:,2)'*rhot*state(:,2);\n    prob3 = state(:,3)'*rhot*state(:,3);\n    prob4 = state(:,4)'*rhot*state(:,4);\n    \n    % Utilizing if to simulate the quantum measurement\n    % The inverse process is using the formula of eq(S44) in supplemental\n    % material of the original paper\n    if rand < prob1\n        rhot = 3*pauli(:,:,randnum(1))'*(state0*state0')*pauli(:,:,randnum(1)) - eye(2);\n        rhot = kron(rhot,3*pauli(:,:,randnum(2))'*(state0*state0')*pauli(:,:,randnum(2)) - eye(2));\n    elseif rand < prob1 + prob2\n        rhot = 3*pauli(:,:,randnum(1))'*(state0*state0')*pauli(:,:,randnum(1)) - eye(2);\n        rhot = kron(rhot,3*pauli(:,:,randnum(2))'*(state1*state1')*pauli(:,:,randnum(2)) - eye(2));\n    elseif rand < prob1 + prob2 + prob3\n        rhot = 3*pauli(:,:,randnum(1))'*(state1*state1')*pauli(:,:,randnum(1)) - eye(2);\n        rhot = kron(rhot,3*pauli(:,:,randnum(2))'*(state0*state0')*pauli(:,:,randnum(2)) - eye(2));\n    else\n        rhot = 3*pauli(:,:,randnum(1))'*(state1*state1')*pauli(:,:,randnum(1)) - eye(2);\n        rhot = kron(rhot,3*pauli(:,:,randnum(2))'*(state1*state1')*pauli(:,:,randnum(2)) - eye(2));\n    end\n    record_rho = record_rho + rhot;\nend\nrecord_rho = record_rho/n;\nsqrt(trace((rho - record_rho)'*(rho - record_rho)))\nFidelity(rho,record_rho)\n\n", "answers": ["\nThere's a few bugs in your code as well as a slight misunderstanding about the guarantees of the protocol.\nFirst to clarify some details: The protocol you implement samples U\u2208Cl(2)\u22972U\u2208Cl(2)\u22972 (not the same as U\u2208Cl(22)U\u2208Cl(22)!) and then applies these operators pre-measurement. Up to global phase this is equivalent to performing local measurements randomly selected to be in either the xx-, yy-, or zz-basis. And so equivalently this can be implemented as randomly applying a unitary UjUj drawn from {H,HS\u2020,I}{H,HS\u2020,I}, applying to each qubit j=0,1j=0,1, and then measuring |b0b1\u27e9\u27e8b0b1||b0b1\u27e9\u27e8b0b1|.\nMathematically the effect of this pre-measurement rotation on an input state averaged over many trials turns out to be the depolarizing channel. This is why you recover a shadow of the input state by applying the inverse of a depolarizing channel\n\u03c1^=(D\u221211/3)\u22972\u2218(U\u20200\u2297U\u20201)|b0b1\u27e9\u27e8b0b1|(U0\u2297U1)=\u2a02j=12(3U\u2020j|b^j\u27e9\u27e8b^j|Uj\u2212I)(1)(1)\u03c1^=(D1/3\u22121)\u22972\u2218(U0\u2020\u2297U1\u2020)|b0b1\u27e9\u27e8b0b1|(U0\u2297U1)=\u2a02j=12(3Uj\u2020|b^j\u27e9\u27e8b^j|Uj\u2212I)\nwhere the equivalence of these two expressions is derived very nicely in Huang's paper. However, this protocol doesn't actually guarantee tight bounds on  Tr(\u03c1\u03c1^)Tr(\u03c1\u03c1^). Rather, the guarantee of this protocol is that for OiOi taken from the set of 22-local Paulis, the difference\n|Tr(Oi\u03c1^)\u2212Tr(Oi\u03c1)|\u2264\u03f5(2)(2)|Tr(Oi\u03c1^)\u2212Tr(Oi\u03c1)|\u2264\u03f5\nwill be upper bounded according to the shadow norm and accuracy parameters. On the other hand, if you were interested in observables with much lower locality than the size of the system you would still see good convergence re: Equation (2) but the distance between the input state and the classical shadow could be large.\nWith these factors in mind, here is a working codeblock slightly modified from yours:\nfrom math import exp\nfrom qiskit import *\nfrom qiskit import Aer\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom random import randrange\n\nnp.random.seed(222)\ndef one_shot(operator):\n    \n    sim = Aer.get_backend('aer_simulator')\n    qc = QuantumCircuit(2)\n#     unitary = [qc.h, qc.sdg, qc.id] # no! Bug #1\n    unitary = [[qc.h], [qc.sdg, qc.h], [qc.id]] \n    qc.h(0)\n    qc.cx(0,1)\n    # new code:\n    for x in unitary[operator[0]]:\n        x(0)\n    for x in unitary[operator[1]]:\n        x(1)\n    qc.measure_all()\n    qobj = assemble(qc,shots=1)\n    result = sim.run(qobj).result().get_counts()\n    return result\n\ndef distance(rho):\n    '''\n    calculate distance of two density matrix\n    '''\n    return np.sqrt(np.trace(rho.conjugate().transpose().dot(rho)))\n\nhadamard = 1/np.sqrt(2)*np.array([[1,1],[1,-1]])\ns_gate = np.array([[1,0],[0,-1j]],dtype=complex)\nid = np.identity(2) # don't overwrite builtins with variables!\nunitary = [hadamard,np.dot(hadamard,s_gate),id]\nsnapshot_num = 5000 # more shots\nstate0 = np.array([[1,0],[0,0]])\nstate1 = np.array([[0,0],[0,1]])\nstates = [state0, state1]\nrecord_rho = np.zeros([4,4])\nfor i in range(snapshot_num):\n    randnum = np.random.randint(0,3,size=2)\n    result = one_shot(randnum)\n    \n    bit0, bit1 = [int(x) for x in list(result.keys())[0]] # assuming one shot\n    U0, U1 = unitary[randnum[0]], unitary[randnum[1]]\n    # No! Bug #2: your parentheses were incorrect here\n    rhohat = np.kron(3* U0.conj().T @ states[bit0] @ U0 - id , 3* U1.conj().T @ states[bit1] @ U1 - id)\n    record_rho = record_rho + rhohat\n    \nrecord_rho = record_rho/snapshot_num\nbell_state = np.array([[0.5, 0, 0, 0.5], [0, 0, 0, 0], [0, 0, 0, 0], [0.5, 0, 0, 0.5]])\n\nprint(\"State distance\")\nprint(distance(record_rho - bell_state))\n\n# VERIFICATION\nprint(\"verify 2-local expecations converge\")\nI = np.eye(2)\nX = np.array([[0, 1], [1, 0]])\nY = np.array([[0, -1j], [1j, 0]])\nZ = np.array([[1, 0], [0, -1]])\npaulis = [I, X, Y, Z]\n\nfor i in range(4):\n    for j in range(4):\n        twolocal_pauli = np.kron(paulis[i], paulis[j])\n        expectation_true = np.trace(bell_state @ twolocal_pauli)\n        expectation_rhohat = np.trace(record_rho @ twolocal_pauli)\n        print((i,j), abs(expectation_true - expectation_rhohat))\n\nwhich outputs:\nState distance\n(0.06070337717129093+0j)\nverify 2-local expecations converge\n(0, 0) 0.0\n(0, 1) 0.045599999999999995\n(0, 2) 0.0108\n(0, 3) 0.008400000000000074\n(1, 0) 0.009000000000000003\n(1, 1) 0.03160000000000007\n(1, 2) 0.03779999999999999\n(1, 3) 0.003599999999999997\n(2, 0) 0.006599999999999998\n(2, 1) 0.0342\n(2, 2) 0.04960000000000009\n(2, 3) 0.04319999999999999\n(3, 0) 0.013200000000000045\n(3, 1) 0.0414\n(3, 2) 0.034199999999999994\n(3, 3) 0.036799999999999944\n\nSo after increasing shots to 5000 can see nice convergence on Tr(\u03c1^\u03c3i\u2297\u03c3j)Tr(\u03c1^\u03c3i\u2297\u03c3j) even if the fidelity Tr(\u03c1^\u03c1)Tr(\u03c1^\u03c1) is increasing at a slower rate11.\nThe bugs are described below:\n\nunitary = [qc.h, qc.sdg, qc.id] in the function one_shot: The S\u2020S\u2020 is not how you perform a measurement in the Y-basis. You need HS\u2020HS\u2020.\nrho = np.kron(3*np.dot(unitary[randnum[0]].conj().T,state0).dot(unitary[randnum[0]] - id),3*np.dot(unitary[randnum[1]].conj().T,state0).dot(unitary[randnum[1]]) - id) in the loop over snapshot_num: specifically, .dot(unitary[randnum[0]] - id) has the parentheses in the wrong place. If you had inspected \u03c1\u03c1 you would have observed it was often equal to the all-zeros matrix which is a bad sign. While we can't rely on Tr(\u03c1^)=1Tr(\u03c1^)=1 in this protocol because M\u22121M\u22121 is not trace preserving, we can at least expect Tr(\u03c1^)\u22651Tr(\u03c1^)\u22651.\n\n\n11 In this special case where the observables are nn-local rather than kk-local for k<nk<n, I think by triangle inequality the state distance is actually bounded as a sum of the bounds on the observables:\n\u2225\u03c1\u2212\u03c1^\u22251\u2264=\u2225\u2225\u2225\u2225\u2211i\u2208{I,X,Y,Z}2(Tr(Pi\u03c1)\u2212Tr(Pi\u03c1^))Pi\u2225\u2225\u2225\u22251\u2211i\u2208{I,X,Y,Z}2\u2225(Tr(Pi\u03c1)\u2212Tr(Pi\u03c1^))Pi\u22251\u226416\u03f5\u2016\u03c1\u2212\u03c1^\u20161=\u2016\u2211i\u2208{I,X,Y,Z}2(Tr(Pi\u03c1)\u2212Tr(Pi\u03c1^))Pi\u20161\u2264\u2211i\u2208{I,X,Y,Z}2\u2016(Tr(Pi\u03c1)\u2212Tr(Pi\u03c1^))Pi\u20161\u226416\u03f5\nwhere Pi=\u03c3i1\u2297\u03c3i2Pi=\u03c3i1\u2297\u03c3i2 and the bound of Equation (2) was applied. This is why the sample complexity of estimating classical shadows for nn-local Pauli operators (which are a basis for nn-qubit states) with error parameter \u03f5\u03f5 is much lower than the sample complexity for state tomography with error parameter \u03f5\u03f5.\n"], "comments": ["Thanks a lot. One more thing to ask: I learned that the generator of the Clifford group is <Hi,Sj,CNOTij><Hi,Sj,CNOTij> from this lecture, but in Huang's supplemental material, he stated a term that I didn't hear before:(global and local) Clifford circuit. What does global mean? Thanks!", "I believe what the authors are describing there is implementing unitaries UU sampled from Cl(2n)Cl(2n) (to use their notation), which you provided a generator for. And so the global Clifford circuit would be an element sampled (uniformly at random) from that group. This is in contrast to a \"local Clifford circuit\" which is sampled from Elements randomly sampled from this group look a lot different than those sampled from Cl(2)\u2297nCl(2)\u2297n, which actually just describes performing local measurements randomly in either the x\u2212x\u2212, y\u2212y\u2212, or z\u2212z\u2212 basis.", "But the distinction is important, since each choice of UU has its corresponding guarantees based on \u2225\u22c5\u2225shadow\u2016\u22c5\u2016shadow. The protocol using U=Cl(2n)U=Cl(2n) guarantees good accuracy for computing expectation values of fixed-norm operators, while the protocol using U=Cl(2)\u2297nU=Cl(2)\u2297n guarantees good accuracy for computing expectation values of kk-local Pauli operators, with the tightness of the bound on accuracy falling of like 3k3k if I recall correctly.", "Suddenly recall that you said ''However, this protocol doesn't actually guarantee tight bounds on Tr\u03c1\u03c1^Tr\u03c1\u03c1^''. But actually, we have E\u03c1^=\u03c1E\u03c1^=\u03c1, so why maybe what you said is wrong?", "Maybe better wording is \"...doesn't guarantee tight bounds on Tr(\u03c1\u03c1^)Tr(\u03c1\u03c1^) with respect to sample size\". So its true that the expected value of \u03c1^\u03c1^ eventually converges on \u03c1\u03c1, but this isn't useful to us if it takes, say, 4n4n many experiments to get good convergence.", "So typically these arguments proceed by bounding the variance of the random variable you're interested in. In this case, no bounds were supplied for Var[Tr(\u03c1\u03c1^)]Var[Tr(\u03c1\u03c1^)] but its easy to show that Var[Tr(O\u03c1^)]\u2264\u2225O\u2225shadowVar[Tr(O\u03c1^)]\u2264\u2016O\u2016shadow. So the fact that E[Tr(O\u03c1^)]=Tr(O\u03c1)E[Tr(O\u03c1^)]=Tr(O\u03c1)  AND that Var[Tr(O\u03c1^)]Var[Tr(O\u03c1^)] is \"small\" is what makes this a powerful application.", "But since \u03c1\u03c1 is also a special observable, we can take \u03c1\u03c1 as a special OO, which is exactly the fidelity example.", "\u03c1^\u03c1^ is approximating \u03c1\u03c1, which is the state produced \"in the lab\". I guess if you knew exactly that state then yes you could set O:=\u03c1O:=\u03c1 and you would be guaranteed that Tr(\u03c1^\u03c1)Tr(\u03c1^\u03c1) would approach 11 implying good convergence of \u03c1^\u03c1^ towards \u03c1\u03c1 . But a more likely application is that your device produces state \u03c1\u03c1, your goal is to produce \u03c3\u03c3, and you efficiently check the fidelity by computing Tr(\u03c3\u03c1^)Tr(\u03c3\u03c1^). Now its unclear how quickly \u03c1^\u03c1^ converges to \u03c1\u03c1."], "link": "https://quantumcomputing.stackexchange.com//questions/21311/implement-the-classical-shadow-coding-error?r=SearchResults"}