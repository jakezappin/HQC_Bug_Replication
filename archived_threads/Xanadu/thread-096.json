{"0": {"author": "Shawn", "date": "1594205367982", "content": "I have two separate codes \u2013 one with classical machine learning (nothing to do with pennylane) and one with quantum ml (below). The only difference between the two is that the qml has additional pennylane code in the DQN class. Running the classical ml code runs without a problem on the GPU but when I run the qml code I get an error. Here is part of the code:\nimport gym\nimport math\nimport random\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom collections import namedtuple\nfrom itertools import count\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torch.nn.functional import relu, sigmoid\nimport pennylane as qml\nimport time\n\nout_dim = 2  # output dimension of model\nwires = 1  # this is the width of the quantum element\nn_quantum_layers = 2  # this is the depth of the quantum element\n\n\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    qml.templates.SqueezingEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10,\n                                    wires=range(wires))\n    return [qml.expval(qml.X(wires=i)) for i in range(wires)]\n\n\nclass DQN(nn.Module):\n\n    def __init__(self, img_height, img_width):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(in_features=img_height * img_width * 3, out_features=12)\n        self.fc2 = nn.Linear(in_features=12, out_features=8)\n       # self.fc3 = nn.Linear(in_features=10, out_features=8)\n        self.clayer_in = torch.nn.Linear(in_features=8, out_features=wires)\n        self.clayer_out = torch.nn.Linear(wires, out_dim)\n\n        dev = qml.device('strawberryfields.fock', wires=wires, cutoff_dim=3)\n        self.layer_qnode = qml.QNode(layer, dev)\n\n        weights = qml.init.cvqnn_layers_all(n_quantum_layers, wires)\n        weight_shapes = {\"w{}\".format(i): w.shape for i, w in enumerate(weights)}\n        \n        self.qlayer = qml.qnn.TorchLayer(self.layer_qnode, weight_shapes)\n\n    def forward(self, t):\n        t = self.flatten(t)\n        t = self.fc1(t)\n        t = self.fc2(t)\n       # t = self.fc3(t)\n        t = self.clayer_in(t)\n        t = self.qlayer(t)\n        t = self.clayer_out(t)\n        t = t.sigmoid()\n        return t\n\n\n\n\n\n#A lot of code between these two parts is left \n#out for the sake of brevity and necessity\n\n\n\nbatch_size = 128\ngamma = 0.999\neps_start = 1\neps_end = 0.01\neps_decay = 0.0005\ntarget_update = 10\nmemory_size = 500000\nlr_start = 0.01\nlr_end = 0.00001\nlr_decay = 0.00009\nnum_episodes = 1000 # run for more episodes for better results\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nem = CartPoleEnvManager(device)\nstrategy = EpsilonGreedyStrategy(eps_start, eps_end, eps_decay)\nagent = Agent(strategy, em.num_actions_available(), device)\nmemory = ReplayMemory(memory_size)\n#learning_rate = LearningRate(lr_start,lr_end,lr_decay)\n#learn = lr(learning_rate)\n\npolicy_net = DQN(em.get_screen_height(), em.get_screen_width()).to(device)\ntarget_net = DQN(em.get_screen_height(), em.get_screen_width()).to(device)\ntarget_net.load_state_dict(policy_net.state_dict())\ntarget_net.eval() #tells pytorch that target_net is only used for inference, not training\noptimizer = optim.Adam(params=policy_net.parameters(), lr=0.01)\n\ni = 0\nepisode_durations = []\nfor episode in range(num_episodes): #iterate over each episode\n    program_starts = time.time()\n    em.reset()\n    state = em.get_state()\n    \n    for timestep in count():\n        action = agent.select_action(state, policy_net)\n        reward = em.take_action(action)\n        next_state = em.get_state()\n        memory.push(Experience(state, action, next_state, reward))\n        state = next_state\n        #i+=1\n        #print(i)\n        if memory.can_provide_sample(batch_size):\n            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.9)\n            experiences = memory.sample(batch_size)\n            states, actions, rewards, next_states = extract_tensors(experiences)\n            \n            current_q_values = QValues.get_current(policy_net, states, actions)\n            next_q_values = QValues.get_next(target_net, next_states) #will get the max qvalues of the next state, q values of next state are used via next state\n            target_q_values = (next_q_values * gamma) + rewards\n\n            loss = F.mse_loss(current_q_values, target_q_values.unsqueeze(1))\n            optimizer.zero_grad() # sets the gradiesnt of all weights n biases in policy_net to zero\n            loss.backward() #computes gradient of loss with respect to all weights n biases in the policy net\n            optimizer.step() # updates the weights n biases with the gradients that were computed form loss.backwards\n            scheduler.step()\n        if em.done:\n            episode_durations.append(timestep)\n            plot(episode_durations, 100)\n            break\n    if episode % target_update == 0:\n        target_net.load_state_dict(policy_net.state_dict()) \n    now = time.time()\n    print(\"Episode hat {0} Sekunden gedauert\".format(now - program_starts))     \n        \nem.close()\n\nAnd when running the code, the following error appears:\nTraceback (most recent call last):\n  File \"qdqn.py\", line 328, in <module>\n    loss.backward() #computes gradient of loss with respect to all weights n biases in the policy net\n  File \"/home/ubuntu/anaconda3/envs/gymm/lib/python3.8/site-packages/torch/tensor.py\", line 198, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n  File \"/home/ubuntu/anaconda3/envs/gymm/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 98, in backward\n    Variable._execution_engine.run_backward(\nRuntimeError: Expected object of device type cuda but got device type cpu for argument #2 'mat2' in call to _th_mm\n\nAny insight is greatly appreciated.\n\n\n Solved by Tom_Bromley in post #6 \n\n\n                Hey @Shawn, \n\nI checked out the TorchLayer class \u2013 is it an open question if it could by chance run on a GPU? \n\nRight now I\u2019d say that either it doesn\u2019t work on GPU, or it doesn\u2019t yet work reliably on GPU and would suggest not using them. We haven\u2019t prioritized GPU support yet since we were focusing\u2026\n              \n", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/1"}, "1": {"author": "antalszava", "date": "1594263977231", "content": "Hi @Shawn!\nFor now it would be suggested to use the CPU with the TorchLayer from PennyLane. Although some examples might work, complete GPU support for the TorchLayer is something we\u2019d have to further explore.\nRecommend keeping an eye on the following relevant thread too:\n\n\n\nDifferent interfaces, different performances PennyLane Help\n\n\n    There is an example presented by PennyLane for qml.qnn.TorchLayer which I copy below. If one modifies only the interface line from @qml.qnode(dev) to @qml.qnode(dev, interface='torch') the convergence behavior drastically changes: \nfor the case @qml.qnode(dev): \nAverage loss over epoch 10: 0.1589\nAverage loss over epoch 20: 0.1331\nAverage loss over epoch 30: 0.1321\n\nand for the case  @qml.qnode(dev, interface='torch'): \nAverage loss over epoch 100: 0.1709\nAverage loss over epoch 200: 0.1593\nAver\u2026\n  \n\n1", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/2"}, "2": {"author": "Shawn", "date": "1594274175972", "content": "Hi @antalszava Many thanks for the reply. Yea that is a bummer because with a CPU the code will take too long to finish (like a year). Does Pennylane have a working GPU option with Tensorflow?", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/3"}, "3": {"author": "Tom_Bromley", "date": "1594292688098", "content": "Hi @Shawn,\nNote that it should be possible to have a QNode using the PyTorch interface that runs on GPU. It is the addition of using TorchLayer, i.e., converting the QNode to a torch.nn layer, that is more of an open question for running on GPU. This should also be the same with the TensorFlow interface and KerasLayer.\nOn the other hand, it\u2019s also not clear that running on GPU will provide a speed up. The strawberryfields.fock device you are using works with the NumPy-based Fock backend of Strawberry Fields. Instead, I\u2019d only be expecting a GPU-based speedup when using a device that is designed to interact with GPUs. One example in the qubit setting may be the default.qubit.tf 8 device, which is written in TensorFlow and might be more amenable to running on GPU. Although, right now I\u2019d say that GPU support/speedups are still on the to-do list in PennyLane.\nThanks,\nTom", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/4"}, "4": {"author": "Shawn", "date": "1594301088924", "content": "Hi @Tom_Bromley thanks for the insight. Hm that\u2019s unfortunate. I checked out the TorchLayer class \u2013 is it an open question if it could by chance run on a GPU? If so, is it in the pipeline to make the class work with certainty with GPUs?\nTo your last comment, will there be an option for GPU-based devices for  continuous-variable systems soon? It just seems odd that with the non pennylane code, the code ran with CPU and GPU fine but the pennylane code takes a very long time to run with CPU.\nThanks again for the time and info.", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/5"}, "5": {"author": "Tom_Bromley", "date": "1594319553786", "content": "Hey @Shawn,\n\nI checked out the TorchLayer class \u2013 is it an open question if it could by chance run on a GPU?\n\nRight now I\u2019d say that either it doesn\u2019t work on GPU, or it doesn\u2019t yet work reliably on GPU and would suggest not using them. We haven\u2019t prioritized GPU support yet since we were focusing on the core feature, so we\u2019re really relying on users such as yourself and @mamadpierre in this post for feedback.\n\nIf so, is it in the pipeline to make the class work with certainty with GPUs?\n\nIt\u2019s good to know that there\u2019s some interest for this feature and we can add it to our to-do list. I can\u2019t make any promises on when it will be available. As a side note if you\u2019re interested, we always welcome contributors and this might be a nice and well specified thing to add.\n\nTo your last comment, will there be an option for GPU-based devices for continuous-variable systems soon? It just seems odd that with the non pennylane code, the code ran with CPU and GPU fine but the pennylane code takes a very long time to run with CPU.\n\nI\u2019d say the slow down is due to:\n\n\nFundamentally, we\u2019re simulating a quantum system which in the strawberryfields.fock simulator scales exponentially with the number of modes. Unfortunately this is not something we can really get around with simulators, but a nice motivation for using hardware!\n\n\nThe code could be more optimized: we\u2019re gradually adding performance improvements to elements of the code. For example, we\u2019ve been implementing gates more efficiently in Strawberry Fields. I think there\u2019s probably still room to optimize the performance running on CPUs before we concentrate on using GPUs.\n\n\nThanks!Solution1", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/6"}, "6": {"author": "Shawn", "date": "1594322681800", "content": "Hi @Tom_Bromley many thanks for the insight! I would be very interested in helping build this out. How would one get started? Make an issue and start from there? I am guessing I would have to learn a lot of the code from the packages first.", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/7"}, "7": {"author": "Tom_Bromley", "date": "1594326120968", "content": "Thanks @Shawn, that would be cool!\nWe have a guide 5 here on the forum for contributing to PennyLane. However in this case, I think you\u2019re right that it would be good to first get a handle on the errors that we get when trying to run TorchLayer on GPU and report them as an issue on the PennyLane GitHub. We can then decide from there whether there is a reasonable fix.", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/8"}, "8": {"author": "Shawn", "date": "1594383043833", "content": "Ok I made a new issue here: https://github.com/XanaduAI/pennylane/issues/709 54", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/9"}, "9": {"author": "nathan", "date": "1594661540270", "content": "Thanks @Shawn for this!", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/10"}, "10": {"author": "Daniel63656", "date": "1625138134427", "content": "Hi,\nwhat is the situation on GPU support right now? I don\u2019t use qml.qnn.TorchLayer but get a similar error.\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport pennylane as qml\n\nclass QuanumLayer(nn.Module):\n    def __init__(self, n_qubits, n_layers):\n        super().__init__()\n        self.n_qubits = n_qubits\n        self.n_layers = n_layers\n        self.weight = nn.Parameter(torch.randn((n_layers, n_qubits*(n_qubits-1)))).to(device)\n        self.sim_dev = qml.device('default.qubit', wires=n_qubits)\n\n    def entanglement_layer(self, qubits):\n        n = len(qubits)\n        for i in range(0, n):\n            qml.CNOT(wires=[qubits[i], qubits[(i+1)%n]])\n        \n    def rotation_embedding(self, params, qubits):\n        # parametrized ry, rz rotations\n        n = len(qubits)\n        for i,q in enumerate(qubits):\n            qml.RY(params[i], wires=q)\n        for i,q in enumerate(qubits):\n            qml.RZ(params[i+n], wires=q)\n        for i,q in enumerate(qubits):\n            qml.RY(params[i+2*n], wires=q)\n        self.entanglement_layer(qubits)\n\n    def variation_layer(self, params, qubits):\n        # parametrized ry, rz rotations\n        n = len(qubits)\n        count = 0\n        for i,q in enumerate(qubits):\n            for j,r in enumerate(qubits):\n                if (r != i):\n                    qml.CRY(params[count], wires=[r, i])\n                    count +=1\n                \n    def QNode(self, inputs, weights):\n        if (len(inputs) != self.n_qubits*3):\n            raise IndexError(\"Inputvector must have length 3*qubits\")\n        \n        @qml.qnode(self.sim_dev, interface=\"torch\")\n        def qnode(inputs, weights):\n            self.rotation_embedding(inputs, range(self.n_qubits))\n            #variational circuit\n            measureWires = range(self.n_qubits)\n            for w in weights:\n                self.variation_layer(w, measureWires)\n            #measure\n            return [qml.expval(qml.PauliZ(i)) for i in measureWires]\n        return qnode(inputs, weights).to(device)\n\n    def forward(self, input_features):\n        inputs = input_features*2*np.pi\n        q_out = torch.Tensor(0, self.n_qubits).to(device)\n        # Apply the quantum circuit to each element of the batch and append to q_out\n        for elem in inputs:\n            q_out_elem = self.QNode(elem, self.weight).float().unsqueeze(0)\n            q_out = torch.cat((q_out, q_out_elem))\n        return q_out\n\nUsing this class in network raises this error:\n~\\Hahn_schickard\\quantencomputing\\jupyter\\pyTorch_utils.py in train(device, model, optimizer, criterion, epochs, training, testing)\n     35             correct += (predicted == labels).float().sum()\n     36             loss = criterion(outputs, labels)\n---> 37             loss.backward()\n     38             optimizer.step()\n     39             batch_percentage = i*20//number_batches\n\n~\\anaconda3\\envs\\quantum\\lib\\site-packages\\torch\\tensor.py in backward(self, gradient, retain_graph, create_graph, inputs)\n    243                 create_graph=create_graph,\n    244                 inputs=inputs)\n--> 245         torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n    246 \n    247     def register_hook(self, hook):\n\n~\\anaconda3\\envs\\quantum\\lib\\site-packages\\torch\\autograd\\__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\n    145     Variable._execution_engine.run_backward(\n    146         tensors, grad_tensors_, retain_graph, create_graph, inputs,\n--> 147         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n    148 \n    149 \n\n~\\anaconda3\\envs\\quantum\\lib\\site-packages\\torch\\autograd\\function.py in apply(self, *args)\n     87     def apply(self, *args):\n     88         # _forward_cls is defined by derived class\n---> 89         return self._forward_cls.backward(self, *args)  # type: ignore\n     90 \n     91 \n\n~\\anaconda3\\envs\\quantum\\lib\\site-packages\\pennylane\\interfaces\\torch.py in backward(ctx, dy)\n    173         \"\"\"Implements the backwards pass QNode vector-Jacobian product\"\"\"\n    174         ctx.dy = dy\n--> 175         vjp = dy.view(1, -1) @ ctx.jacobian.apply(ctx, *ctx.saved_tensors)\n    176         vjp = torch.unbind(vjp.view(-1))\n    177         return (None,) + tuple(vjp)\n\nRuntimeError: Tensor for argument #3 'mat2' is on CPU, but expected it to be on GPU (while checking arguments for addmm)\n\n", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/11"}, "11": {"author": "glassnotes", "date": "1625146391334", "content": "Hi @Daniel63656,\nJust this week we\u2019ve merged fix for this issue in the master branch of PennyLane. I recommend to try installing the development version (and please let us know if you are still running into trouble!)\nAlso just as a heads up, depending on your graphics card, you may experience (unrelated) errors of the form CUBLAS_STATUS_EXECUTION_FAILED. If you do, these should be solved by updating to pytorch 1.9", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/12"}, "12": {"author": "Daniel63656", "date": "1625147655242", "content": "I upgraded pennylane via\n pip install pennylane -U\n\nfrom 0.15.1 to 0.16.0\nError persists. Is this the merged version?", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/13"}, "13": {"author": "glassnotes", "date": "1625148670373", "content": "Hi @Daniel63656,\nVersion 0.16 is the current release version; the development version is 0.17. There are two ways to install it, the most straightforward is to use pip and grab the version directly from Github:\npip install git+https://github.com/PennyLaneAI/pennylane.git\n\nThe alternative is to actually clone the Github repo locally, and do pip install . from within the directory.", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/14"}, "14": {"author": "Daniel63656", "date": "1625148892118", "content": "Thank you.\nNow it works perfectly fine.", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/15"}, "15": {"author": "glassnotes", "date": "1625151427920", "content": "Fantastic, thanks for letting us know!", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/16"}, "16": {"author": "Daniel_Wang", "date": "1699137188158", "content": "Hi,\nI tried the following code which also gives errors. Could anyone help?\nclass QuantumLayer(nn.Module):\ndef __init__(self, n_qubits = 7, include_view = True):\n    super().__init__()\n    self.n_qubits = n_qubits\n    self.sim_dev = qml.device('default.qubit', wires=n_qubits)\n    self.include_view = include_view\n    self.weight1 = nn.Parameter(torch.randn(4, 3))\n    self.weight2 = nn.Parameter(torch.randn(3, 3))\n    self.weight3 = nn.Parameter(torch.randn(4, 3))\n\ndef circular_entanglement_layer(self, entangling_qubits):\n    # Circular entanglement\n    if len(entangling_qubits) > self.n_qubits:\n        raise Exception('Num of entangling qubits must be smaller than num of available qubits')\n    n = len(entangling_qubits)\n    for i in range(0, n):\n        qml.CNOT(wires=[entangling_qubits[i], entangling_qubits[(i+1)%n]])\n\ndef rotation_embedding(self, x, encoding_qubits):\n    # Perform rotation embedding\n    # x: (batch_size, 3 + 3)\n    if np.shape(x)[-1] != len(encoding_qubits):\n        raise Exception('lengths of data to be encoded and encoding qubits must be equal')\n    qml.AngleEmbedding(x, wires= encoding_qubits)\n\ndef variation_layer(self, params, var_qubits):\n    if len(params) != len(var_qubits):\n        raise Exception('lengths must be equal in variational layers')\n    for i in range(len(params)):\n        qml.Rot(params[i, 0], params[i, 1], params[i, 2], wires=var_qubits[i])\n\ndef QNode(self, inputs, weights1, weights2, weights3):\n\n    @qml.qnode(self.sim_dev, interface = 'torch')\n    def qnode(inputs, weights1, weights2, weights3):\n        # inputs: (batch_size, 3 + 3), weights: (4, 3)\n        self.rotation_embedding(inputs, list(range(3)) + list(range(3, 6)))\n        self.variation_layer(weights1, list(range(4)))\n        self.circular_entanglement_layer(list(range(4)))\n        self.variation_layer(weights3, list(range(4)))\n        self.circular_entanglement_layer(list(range(4)))\n\n        if self.include_view:\n          qml.CNOT(wires = [4, 0])\n          qml.CNOT(wires = [4, 1])\n          qml.CNOT(wires = [4, 2])\n          qml.CNOT(wires = [5, 0])\n          qml.CNOT(wires = [5, 1])\n          qml.CNOT(wires = [5, 2])\n          qml.CNOT(wires = [6, 0])\n          qml.CNOT(wires = [6, 1])\n          qml.CNOT(wires = [6, 2])\n          self.variation_layer(weights2, list(range(3)))\n\n        else:\n          pass\n\n        return [qml.expval(qml.PauliZ(i)) for i in range(4)] \n\n    return qnode(inputs, weights1, weights2, weights3)\n    \ndef forward(self, chunk_pos, chunk_view):\n    # chunk_pos: (batch_size, 3), chunk_view: (batch_size, 3)\n    inputs = torch.cat((chunk_pos, chunk_view), dim = -1)\n\n    for elem in inputs:\n        pdb.set_trace()\n        q_out_elem = self.QNode(elem, self.weight1, self.weight2, self.weight3).float().unsqueeze(0)\n        q_out = torch.cat((q_out, q_out_elem))\n    return q_out\n\nBut I got errors:\n/usr/local/lib/python3.10/dist-packages/pennylane/devices/default_qubit.py in (.0)\n473         if max_workers is None:\n474             results = tuple(\n \u2192 475                 simulate(\n476                     c,\n477                     rng=self._rng,\n/usr/local/lib/python3.10/dist-packages/pennylane/devices/qubit/simulate.py in simulate(circuit, rng, prng_key, debugger, interface)\n267\n268     \u201c\u201d\"\n \u2192 269     state, is_state_batched = get_final_state(circuit, debugger=debugger, interface=interface)\n270     return measure_final_state(circuit, state, is_state_batched, rng=rng, prng_key=prng_key)\n/usr/local/lib/python3.10/dist-packages/pennylane/devices/qubit/simulate.py in get_final_state(circuit, debugger, interface)\n159     is_state_batched = bool(prep and prep.batch_size is not None)\n160     for op in circuit.operations[bool(prep) :]:\n \u2192 161         state = apply_operation(op, state, is_state_batched=is_state_batched, debugger=debugger)\n162\n163         # Handle postselection on mid-circuit measurements\n/usr/lib/python3.10/functools.py in wrapper(*args, **kw)\n887                             \u20181 positional argument\u2019)\n888\n \u2192 889         return dispatch(args[0].class)(*args, **kw)\n890\n891     funcname = getattr(func, \u2018name\u2019, \u2018singledispatch function\u2019)\n/usr/local/lib/python3.10/dist-packages/pennylane/devices/qubit/apply_operation.py in apply_operation(op, state, is_state_batched, debugger)\n196\n197     \u201c\u201d\"\n \u2192 198     return _apply_operation_default(op, state, is_state_batched, debugger)\n199\n200\n/usr/local/lib/python3.10/dist-packages/pennylane/devices/qubit/apply_operation.py in _apply_operation_default(op, state, is_state_batched, debugger)\n206         and math.ndim(state) < EINSUM_STATE_WIRECOUNT_PERF_THRESHOLD\n207     ) or (op.batch_size and is_state_batched):\n \u2192 208         return apply_operation_einsum(op, state, is_state_batched=is_state_batched)\n209     return apply_operation_tensordot(op, state, is_state_batched=is_state_batched)\n210\n/usr/local/lib/python3.10/dist-packages/pennylane/devices/qubit/apply_operation.py in apply_operation_einsum(op, state, is_state_batched)\n98     reshaped_mat = math.reshape(mat, new_mat_shape)\n99\n \u2192 100     return math.einsum(einsum_indices, reshaped_mat, state)\n101\n102\n/usr/local/lib/python3.10/dist-packages/pennylane/math/multi_dispatch.py in einsum(indices, like, optimize, *operands)\n537     if like is None:\n538         like = get_interface(*operands)\n \u2192 539     operands = np.coerce(operands, like=like)\n540     if optimize is None or like == \u201ctorch\u201d:\n541         # torch einsum doesn\u2019t support the optimize keyword argument\n/usr/local/lib/python3.10/dist-packages/autoray/autoray.py in do(fn, like, *args, **kwargs)\n78     \u201c\u201d\"\n79     backend = choose_backend(fn, *args, like=like, **kwargs)\n\u2014> 80     return get_lib_fn(backend, fn)(*args, **kwargs)\n81\n82\n/usr/local/lib/python3.10/dist-packages/pennylane/math/single_dispatch.py in _coerce_types_torch(tensors)\n603         # GPU specific case\n604         device_names = \", \u201c.join(str(d) for d in device_set)\n \u2192 605         raise RuntimeError(\n606             f\"Expected all tensors to be on the same device, but found at least two devices, {device_names}!\u201d\n607         )\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0, cpu!\nDoes someone know how to fix this?", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/17"}, "17": {"author": "isaacdevlugt", "date": "1699315964249", "content": "Hey @Daniel_Wang! Welcome to the forum \nI can\u2019t see anything obvious in your code example, but there are things missing for me to be able to reproduce what you\u2019re getting. In any case, it looks like somewhere along the line your creating a torch tensor on a cpu device instead of a gpu device. You\u2019ll need to do something like this on your cpu-using tensors:\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ninput_tensor = input_tensor.to(device)\noutput_tensor = output_tensor.to(device)\n\nor you can set the default device like this (see here: torch.set_default_device \u2014 PyTorch 2.1 documentation 2)\n>>> torch.tensor([1.2, 3]).device\ndevice(type='cpu')\n>>> torch.set_default_device('cuda')  # current device is 0\n>>> torch.tensor([1.2, 3]).device\ndevice(type='cuda', index=0)\n>>> torch.set_default_device('cuda:1')\n>>> torch.tensor([1.2, 3]).device\ndevice(type='cuda', index=1)\n\nLet me know if either of these help!", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/18"}, "18": {"author": "Daniel_Wang", "date": "1699474122816", "content": "Hi,\nThank you for your info. I solved the problem by setting the device to default.qubit.torch and it works now.\nThe input tensor, output tensors and the model are all in GPU. It is just that using default.qubit always pops the error that something is inconsistent. Using default.qubit.torch solves it.1", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/19"}, "19": {"author": "Tom_Bromley", "date": "1699536973442", "content": "Hi @Daniel_Wang! Please could you let us know which version of PennyLane you are using?\nYou can get this by copying here the output of qml.about().", "link": "https://discuss.pennylane.ai//t/pennylane-and-pytorch-running-on-gpu/457/20"}}