{"0": {"author": "imakash", "date": "1690984884248", "content": "Hello, I am experimenting with the parameter broadcasting for quantum circuits in which the quantum circuit is created as a torch layer and I found some weird things happening. Following is the code I am using.\nimport pennylane as qml\nfrom pennylane import numpy as np\nimport time as time\nimport torch\nimport torch.nn as nn\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev, interface = 'torch')\ndef simple_qubit_circuit(theta, inputs):\n    qml.RX(inputs, wires=0)\n    qml.RY(theta, wires=0)\n    return qml.expval(qml.PauliZ(0))\nclass QNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        shapes = {\n            \"theta\": (1,)\n        }\n        self.q = qml.qnn.TorchLayer(simple_qubit_circuit, shapes)\n    \n    def forward(self, input_value):\n        return self.q(input_value)\n\n\nx_train = np.array([0.2, 0.1, 0.2, 0.14, 0.11, 0.41, 0.55, 0.3, 0.31, 0.6])\nx_train = torch.tensor(x_train).reshape(10,1)\n\n# Problem 1\n# x_train = torch.rand(10,1)\n# x_train = torch.atan(x_train)\n\nmodel = QNet()\nt1 = time.time()\nout = model(x_train)\nprint(\"time taken for batch operations: \", time.time()-t1)\nout2 = []\nt2 = time.time()\nfor x in x_train:\n    out2.append(model(x).item())\nprint(\"time taken for sequential operations: \", time.time()-t2)\n\nprint(out)\nprint(out2)\n\n\nProblem 1: If I use a tensor created using torch.rand() method, I get the following error. However, this error is not there when I used a tensor created with a numpy vector. I am not sure why this happens.\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel_12504\\1395714778.py in <cell line: 9>()\n      7 model = QNet()\n      8 t1 = time.time()\n----> 9 out = model(x_train)\n     10 print(\"time taken for batch operations: \", time.time()-t1)\n     11 out2 = []\n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\torch\\nn\\modules\\module.py in _call_impl(self, *input, **kwargs)\n   1192         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1193                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1194             return forward_call(*input, **kwargs)\n   1195         # Do not call functions when jit is used\n   1196         full_backward_hooks, non_full_backward_hooks = [], []\n\n~\\AppData\\Local\\Temp\\ipykernel_12504\\4054581433.py in forward(self, input_value)\n     15 \n     16     def forward(self, input_value):\n---> 17         return self.q(input_value)\n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\torch\\nn\\modules\\module.py in _call_impl(self, *input, **kwargs)\n   1192         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1193                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1194             return forward_call(*input, **kwargs)\n   1195         # Do not call functions when jit is used\n   1196         full_backward_hooks, non_full_backward_hooks = [], []\n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\qnn\\torch.py in forward(self, inputs)\n    307             # recursively call the forward pass on each of the yielded tensors, and then stack the\n    308             # outputs back into the correct shape\n--> 309             reconstructor = [self.forward(x) for x in torch.unbind(inputs)]\n    310             return torch.stack(reconstructor)\n    311 \n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\qnn\\torch.py in <listcomp>(.0)\n    307             # recursively call the forward pass on each of the yielded tensors, and then stack the\n    308             # outputs back into the correct shape\n--> 309             reconstructor = [self.forward(x) for x in torch.unbind(inputs)]\n    310             return torch.stack(reconstructor)\n    311 \n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\qnn\\torch.py in forward(self, inputs)\n    311 \n    312         # If the input is 1-dimensional, calculate the forward pass as usual\n--> 313         return self._evaluate_qnode(inputs)\n    314 \n    315     def _evaluate_qnode(self, x):\n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\qnn\\torch.py in _evaluate_qnode(self, x)\n    326             **{arg: weight.to(x) for arg, weight in self.qnode_weights.items()},\n    327         }\n--> 328         return self.qnode(**kwargs).type(x.dtype)\n    329 \n    330     def _init_weights(\n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\qnode.py in __call__(self, *args, **kwargs)\n    845             return res\n    846 \n--> 847         res = qml.execute(\n    848             [self.tape],\n    849             device=self.device,\n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\interfaces\\execution.py in execute(tapes, device, gradient_fn, interface, mode, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\n    722         ) from e\n    723 \n--> 724     res = _execute(\n    725         tapes, device, execute_fn, gradient_fn, gradient_kwargs, _n=1, max_diff=max_diff, mode=_mode\n    726     )\n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\interfaces\\torch.py in execute(tapes, device, execute_fn, gradient_fn, gradient_kwargs, _n, max_diff, mode)\n    256         max_diff=max_diff,\n    257     )\n--> 258     return ExecuteTapes.apply(kwargs, *parameters)\n    259 \n    260 \n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\interfaces\\torch.py in forward(ctx, kwargs, *parameters)\n     85 \n     86         with qml.tape.Unwrap(*ctx.tapes):\n---> 87             res, ctx.jacs = ctx.execute_fn(ctx.tapes, **ctx.gradient_kwargs)\n     88 \n     89         # if any input tensor uses the GPU, the output should as well\n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\interfaces\\execution.py in wrapper(tapes, **kwargs)\n    204         else:\n    205             # execute all unique tapes that do not exist in the cache\n--> 206             res = fn(execution_tapes.values(), **kwargs)\n    207 \n    208         final_res = []\n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\interfaces\\execution.py in fn(tapes, **kwargs)\n    129         def fn(tapes: Sequence[QuantumTape], **kwargs):  # pylint: disable=function-redefined\n    130             tapes = [expand_fn(tape) for tape in tapes]\n--> 131             return original_fn(tapes, **kwargs)\n    132 \n    133     @wraps(fn)\n\n~\\Miniconda3\\envs\\qns\\lib\\contextlib.py in inner(*args, **kwds)\n     73         def inner(*args, **kwds):\n     74             with self._recreate_cm():\n---> 75                 return func(*args, **kwds)\n     76         return inner\n     77 \n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\_qubit_device.py in batch_execute(self, circuits)\n    654 \n    655             # TODO: Insert control on value here\n--> 656             res = self.execute(circuit)\n    657             results.append(res)\n    658 \n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\_qubit_device.py in execute(self, circuit, **kwargs)\n    434         # generate computational basis samples\n    435         if self.shots is not None or circuit.is_sampled:\n--> 436             self._samples = self.generate_samples()\n    437 \n    438         measurements = circuit.measurements\n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\_qubit_device.py in generate_samples(self)\n   1216         rotated_prob = self.analytic_probability()\n   1217 \n-> 1218         samples = self.sample_basis_states(number_of_states, rotated_prob)\n   1219         return self.states_to_binary(samples, self.num_wires)\n   1220 \n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\_qubit_device.py in sample_basis_states(self, number_of_states, state_probability)\n   1244             # np.random.choice does not support broadcasting as needed here.\n   1245             return np.array(\n-> 1246                 [np.random.choice(basis_states, shots, p=prob) for prob in state_probability]\n   1247             )\n   1248 \n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\pennylane\\_qubit_device.py in <listcomp>(.0)\n   1244             # np.random.choice does not support broadcasting as needed here.\n   1245             return np.array(\n-> 1246                 [np.random.choice(basis_states, shots, p=prob) for prob in state_probability]\n   1247             )\n   1248 \n\nmtrand.pyx in numpy.random.mtrand.RandomState.choice()\n\nValueError: probabilities do not sum to 1\n\nProblem 2:\nThe time taken for batch operation is higher compared to the time taken for sequential operations. Is true parameter broadcasting yet not implemented in pennylane for qml.qnn.TorchLayer() ?\nProblem 3:\nThe output tensors calculated using batch operation vs sequential operation for the same input tensor and for the same weight is different which should not be the case. Again not sure what\u2019s wrong here.\nOutput of qml.about().\nqml.about()\nName: PennyLane\nVersion: 0.28.0\nSummary: PennyLane is a Python quantum machine learning library by Xanadu Inc.\nHome-page: https://github.com/XanaduAI/pennylane\nAuthor: \nAuthor-email: \nLicense: Apache License 2.0\nLocation: c:\\users\\aksi01\\miniconda3\\envs\\qns\\lib\\site-packages\nRequires: appdirs, autograd, autoray, cachetools, networkx, numpy, pennylane-lightning, requests, retworkx, scipy, semantic-version, toml\nRequired-by: PennyLane-Lightning, PennyLane-qiskit\nPlatform info:           Windows-10-10.0.19045-SP0\nPython version:          3.8.15\nNumpy version:           1.22.3\nScipy version:           1.7.3\nInstalled devices:\n- default.gaussian (PennyLane-0.28.0)\n- default.mixed (PennyLane-0.28.0)\n- default.qubit (PennyLane-0.28.0)\n- default.qubit.autograd (PennyLane-0.28.0)\n- default.qubit.jax (PennyLane-0.28.0)\n- default.qubit.tf (PennyLane-0.28.0)\n- default.qubit.torch (PennyLane-0.28.0)\n- default.qutrit (PennyLane-0.28.0)\n- null.qubit (PennyLane-0.28.0)\n- lightning.qubit (PennyLane-Lightning-0.28.1)\n- qiskit.aer (PennyLane-qiskit-0.29.0)\n- qiskit.basicaer (PennyLane-qiskit-0.29.0)\n- qiskit.ibmq (PennyLane-qiskit-0.29.0)\n- qiskit.ibmq.circuit_runner (PennyLane-qiskit-0.29.0)\n- qiskit.ibmq.sampler (PennyLane-qiskit-0.29.0)\n\n\n\n\n Solved by ludmilaaasb in post #15 \n\n\n                Hmmm, the latest stable version of torch is 2.0.1. Try updating it and see if the error persists. \nUpdate: I created a clean environment using torch=1.13.1 and the latest version of pennylane and tested your code with \nx_train = torch.rand(10)\nx_train = torch.atan(x_train)\n\nNo issues were found. So\u2026\n              \n", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/1"}, "1": {"author": "imakash", "date": "1690986377330", "content": "This thread 1 mentions that true broadcasting is not supported in Pennylane version 0.30 within qnn.TorchLayer. (\u201ctrue parameter broadcasting within qnn.TorchLayer isn\u2019t supported. I.e., you can still \u201cbroadcast\u201d, but what happens under the hood is a serial execution, not parallel. So, it looks like broadcasting is happening, but really isn\u2019t.\u201d)\nDoes this status still prevails or there are ways to perform true broadcasting in the latest versions of pennylane within qnn.TorchLayer?", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/2"}, "2": {"author": "ludmilaaasb", "date": "1691003484067", "content": "Hello @imakash !\nI\u2019ll return to you in a moment, but would you mind me sending a minimal code? I tried reproducing the problem, but the version you posted above has some problems and I got completely different errors. \nFor instance,\ndef simple_qubit_circuit(theta, inputs):\n    qml.RX(inputs, wires=0)\n    qml.RY(theta, wires=0)\n    return qml.expval(qml.PauliZ(0))\nclass QNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        shapes = {\n            \"theta\": (1,)\n        }\n        self.q = qml.qnn.TorchLayer(simple_qubit_circuit, shapes)\n    \n    def forward(self, input_value):\n        return self.q(input_value)\n\nThis is not passing the correct size input valid for RX.\nIf you have a minimal working example, that would be nice ", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/3"}, "3": {"author": "imakash", "date": "1691005323656", "content": "Thanks @ludmilaaasb for the response. Actually, the code I shared is the minimal code. The actual quantum circuit that I am using in my project is way more complicated than the one I shared.\nHowever, it does not give me the error you mentioned. Are you using the same Pennylane version that I am using?2 Replies", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/4"}, "4": {"author": "ludmilaaasb", "date": "1691006618140", "content": "Indeed, I am using the latest version. And I strongly advise you to update yours.\n\nDoes this status still prevails or there are ways to perform true broadcasting in the latest versions of pennylane within qnn.TorchLayer?\n\nYes! The latest version is performing true broadcasting! If you take a look at the release notes, you can see that now we have native support.\nDoes it help? 1", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/5"}, "5": {"author": "ludmilaaasb", "date": "1691007629618", "content": "\nProblem 1: If I use a tensor created using torch.rand() method, I get the following error. However, this error is not there when I used a tensor created with a numpy vector. I am not sure why this happens.\n\nSo, I did a minor modification on the code and it works fine for me! \nimport pennylane as qml\nfrom pennylane import numpy as np\nimport time as time\nimport torch\nimport torch.nn as nn\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev, interface = 'torch')\ndef simple_qubit_circuit(inputs, theta):\n    qml.RX(inputs, wires=0)\n    qml.RY(theta, wires=0)\n    return qml.expval(qml.PauliZ(0))\nclass QNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        shapes = {\n            \"theta\": ()\n        }\n        self.q = qml.qnn.TorchLayer(simple_qubit_circuit, shapes)\n    \n    def forward(self, input_value):\n        return self.q(input_value)\n\nx_train = torch.rand(10)\nx_train = torch.atan(x_train)\n\nmodel = QNet()\nt1 = time.time()\nout = model(x_train)\nprint(\"time taken for batch operations: \", time.time()-t1)\nout2 = []\nt2 = time.time()\nfor x in x_train:\n    out2.append(model(x).item())\nprint(\"time taken for sequential operations: \", time.time()-t2)\n\nprint(out)\nprint(out2)\n\nAnd the output:\ntime taken for batch operations:  0.001728057861328125\ntime taken for sequential operations:  0.00826883316040039\ntensor([0.3852, 0.4101, 0.4733, 0.4276, 0.5313, 0.5150, 0.4444, 0.4483, 0.5314,\n        0.5327], grad_fn=<ToCopyBackward0>)\n[0.3851933479309082, 0.41005653142929077, 0.4732654094696045, 0.42755088210105896, 0.5312792658805847, 0.5150039792060852, 0.4443522095680237, 0.4482826292514801, 0.5314198732376099, 0.5326558351516724]\n\n\nProblem 3:\nThe output tensors calculated using batch operation vs sequential operation for the same input tensor and for the same weight is different which should not be the case. Again not sure what\u2019s wrong here\n\nThey look the same for me. So I think the solution is just basically updating for the lastest version and it should be fine! ", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/6"}, "6": {"author": "imakash", "date": "1691008466963", "content": "Hey @ludmilaaasb , thanks for your response. I updated my pennylane version and used the same code you shared. However, I am getting the following error:\nValueError: RX: wrong number(s) of dimensions in parameters. Parameters with ndims (2,) passed, (0,) expected.\n\nI am not sure why I am getting this error when I am using the same pennylane version. Here is the output of qml.about()\nqml.about()\nName: PennyLane\nVersion: 0.31.1\nSummary: PennyLane is a Python quantum machine learning library by Xanadu Inc.\nHome-page: https://github.com/PennyLaneAI/pennylane\nAuthor: \nAuthor-email: \nLicense: Apache License 2.0\nLocation: c:\\users\\aksi01\\appdata\\roaming\\python\\python38\\site-packages\nRequires: appdirs, autograd, autoray, cachetools, networkx, numpy, pennylane-lightning, requests, rustworkx, scipy, semantic-version, toml, typing-extensions\nRequired-by: PennyLane-Lightning, PennyLane-qiskit\nPlatform info:           Windows-10-10.0.19045-SP0\nPython version:          3.8.15\nNumpy version:           1.23.5\nScipy version:           1.10.1\nInstalled devices:\n- default.gaussian (PennyLane-0.31.1)\n- default.mixed (PennyLane-0.31.1)\n- default.qubit (PennyLane-0.31.1)\n- default.qubit.autograd (PennyLane-0.31.1)\n- default.qubit.jax (PennyLane-0.31.1)\n- default.qubit.tf (PennyLane-0.31.1)\n- default.qubit.torch (PennyLane-0.31.1)\n- default.qutrit (PennyLane-0.31.1)\n- null.qubit (PennyLane-0.31.1)\n- lightning.qubit (PennyLane-Lightning-0.31.0)\n- qiskit.aer (PennyLane-qiskit-0.29.0)\n- qiskit.basicaer (PennyLane-qiskit-0.29.0)\n- qiskit.ibmq (PennyLane-qiskit-0.29.0)\n- qiskit.ibmq.circuit_runner (PennyLane-qiskit-0.29.0)\n- qiskit.ibmq.sampler (PennyLane-qiskit-0.29.0)\n\n", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/7"}, "7": {"author": "ludmilaaasb", "date": "1691009249068", "content": "Hmm, that\u2019s strange \n\nI am not sure why I am getting this error when I am using the same pennylane version.\n\nWould mind sharing how are you setting x_train? Check x_train.ndim(). If it returns 2, then you are going to get the error\nValueError: RX: wrong number(s) of dimensions in parameters. Parameters with ndims (2,) passed, (0,) expected.\n\nIt is complaining about the dimension of the parameters. RX is expecting a number and it is receiving a tensor with shape (2,),  that\u2019s why you got the error.", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/8"}, "8": {"author": "imakash", "date": "1691067598652", "content": "Hello @ludmilaaasb ,\nI am reposting the entire code that I am using. The updated pennylane version is behaving very weirdly sometimes.\nimport pennylane as qml\nfrom pennylane import numpy as np\nimport time as time\nimport torch\nimport torch.nn as nn\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev, interface = 'torch')\ndef simple_qubit_circuit(inputs, theta):\n    qml.RX(inputs, wires=0)\n    qml.RY(theta, wires=0)\n    return qml.expval(qml.PauliZ(0))\nclass QNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        quantum_weights = np.random.normal(0, np.pi)\n        self.quantum_weights = nn.parameter.Parameter(torch.tensor(quantum_weights,\\\n                                    dtype=torch.float32,requires_grad=True))\n        shapes = {\n            \"theta\": 1\n        }\n        self.q = qml.qnn.TorchLayer(simple_qubit_circuit, shapes)\n    \n    def forward(self, input_value):\n        return self.q(input_value)\n\n# x_train = np.array([0.2, 0.1, 0.2, 0.14, 0.11, 0.41, 0.55, 0.3, 0.31, 0.6])\n# x_train = torch.tensor(x_train).reshape(10,1)\n\nx_train = torch.rand(10)\nx_train = torch.atan(x_train)\nmodel = QNet()\nt1 = time.time()\nout = model(x_train)\nprint(\"time taken for batch operations: \", time.time()-t1)\nout2 = []\nt2 = time.time()\nfor x in x_train:\n    out2.append(model(x).item())\nprint(\"time taken for sequential operations: \", time.time()-t2)\n\nprint(out)\nprint(out2)\n\nI am getting the following error:\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel_22300\\3277396942.py in <cell line: 9>()\n      7 model = QNet()\n      8 t1 = time.time()\n----> 9 out = model(x_train)\n     10 print(\"time taken for batch operations: \", time.time()-t1)\n     11 out2 = []\n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\torch\\nn\\modules\\module.py in _call_impl(self, *input, **kwargs)\n   1192         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1193                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1194             return forward_call(*input, **kwargs)\n   1195         # Do not call functions when jit is used\n   1196         full_backward_hooks, non_full_backward_hooks = [], []\n\n~\\AppData\\Local\\Temp\\ipykernel_22300\\1881420835.py in forward(self, input_value)\n     23 \n     24     def forward(self, input_value):\n---> 25         return self.q(input_value)\n\n~\\Miniconda3\\envs\\qns\\lib\\site-packages\\torch\\nn\\modules\\module.py in _call_impl(self, *input, **kwargs)\n   1192         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n   1193                 or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1194             return forward_call(*input, **kwargs)\n   1195         # Do not call functions when jit is used\n   1196         full_backward_hooks, non_full_backward_hooks = [], []\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\qnn\\torch.py in forward(self, inputs)\n    406         else:\n    407             # calculate the forward pass as usual\n--> 408             results = self._evaluate_qnode(inputs)\n    409 \n    410         # reshape to the correct number of batch dims\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\qnn\\torch.py in _evaluate_qnode(self, x)\n    427             **{arg: weight.to(x) for arg, weight in self.qnode_weights.items()},\n    428         }\n--> 429         res = self.qnode(**kwargs)\n    430 \n    431         if isinstance(res, torch.Tensor):\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\qnode.py in __call__(self, *args, **kwargs)\n    948                 self.execute_kwargs.pop(\"mode\")\n    949             # pylint: disable=unexpected-keyword-arg\n--> 950             res = qml.execute(\n    951                 [self.tape],\n    952                 device=self.device,\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\interfaces\\execution.py in execute(tapes, device, gradient_fn, interface, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\n    640             _execute = _get_jax_execute_fn(interface, tapes)\n    641 \n--> 642         res = _execute(\n    643             tapes, device, execute_fn, gradient_fn, gradient_kwargs, _n=1, max_diff=max_diff\n    644         )\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\interfaces\\torch.py in execute(tapes, device, execute_fn, gradient_fn, gradient_kwargs, _n, max_diff)\n    496     }\n    497 \n--> 498     return ExecuteTapes.apply(kwargs, *parameters)\n    499 \n    500 \n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\interfaces\\torch.py in new_apply(*inp)\n    260         # Inputs already flat\n    261         out_struct_holder = []\n--> 262         flat_out = orig_apply(out_struct_holder, *inp)\n    263         return pytree.tree_unflatten(flat_out, out_struct_holder[0])\n    264 \n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\interfaces\\torch.py in new_forward(ctx, out_struct_holder, *inp)\n    264 \n    265     def new_forward(ctx, out_struct_holder, *inp):\n--> 266         out = orig_fw(ctx, *inp)\n    267         flat_out, out_struct = pytree.tree_flatten(out)\n    268         ctx._out_struct = out_struct\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\interfaces\\torch.py in forward(ctx, kwargs, *parameters)\n    341 \n    342         unwrapped_tapes = tuple(convert_to_numpy_parameters(t) for t in ctx.tapes)\n--> 343         res, ctx.jacs = ctx.execute_fn(unwrapped_tapes, **ctx.gradient_kwargs)\n    344 \n    345         # if any input tensor uses the GPU, the output should as well\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\interfaces\\execution.py in wrapper(tapes, **kwargs)\n    285             # execute all unique tapes that do not exist in the cache\n    286             # convert to list as new device interface returns a tuple\n--> 287             res = list(fn(execution_tapes.values(), **kwargs))\n    288 \n    289         final_res = []\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\interfaces\\execution.py in fn(tapes, **kwargs)\n    208         def fn(tapes: Sequence[QuantumTape], **kwargs):  # pylint: disable=function-redefined\n    209             tapes = [expand_fn(tape) for tape in tapes]\n--> 210             return original_fn(tapes, **kwargs)\n    211 \n    212     @wraps(fn)\n\n~\\Miniconda3\\envs\\qns\\lib\\contextlib.py in inner(*args, **kwds)\n     73         def inner(*args, **kwds):\n     74             with self._recreate_cm():\n---> 75                 return func(*args, **kwds)\n     76         return inner\n     77 \n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\_qubit_device.py in batch_execute(self, circuits)\n    601             self.reset()\n    602 \n--> 603             res = self.execute(circuit)\n    604             results.append(res)\n    605 \n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\_qubit_device.py in execute(self, circuit, **kwargs)\n    322         # generate computational basis samples\n    323         if self.shots is not None or circuit.is_sampled:\n--> 324             self._samples = self.generate_samples()\n    325 \n    326         # compute the required statistics\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\_qubit_device.py in generate_samples(self)\n   1158         rotated_prob = self.analytic_probability()\n   1159 \n-> 1160         samples = self.sample_basis_states(number_of_states, rotated_prob)\n   1161         return self.states_to_binary(samples, self.num_wires)\n   1162 \n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\_qubit_device.py in sample_basis_states(self, number_of_states, state_probability)\n   1186             # np.random.choice does not support broadcasting as needed here.\n   1187             return np.array(\n-> 1188                 [np.random.choice(basis_states, shots, p=prob) for prob in state_probability]\n   1189             )\n   1190 \n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pennylane\\_qubit_device.py in <listcomp>(.0)\n   1186             # np.random.choice does not support broadcasting as needed here.\n   1187             return np.array(\n-> 1188                 [np.random.choice(basis_states, shots, p=prob) for prob in state_probability]\n   1189             )\n   1190 \n\nmtrand.pyx in numpy.random.mtrand.RandomState.choice()\n\nValueError: probabilities do not sum to 1\n\nIt looks like that this is a bug with Pennylane which @Maria_Schuld had pointed in this 2 post.", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/9"}, "9": {"author": "ludmilaaasb", "date": "1691076863070", "content": "\n\n\n imakash:\n\nIt looks like that this is a bug with Pennylane which @Maria_Schuld had pointed in this  post.\n\n\nIndeed, that was happening in the previous versions of Pennylane. But as Maria pointed out in the same post:\n\n\n\nNumpy says \"probabilities do not sum to 1\"\n\nInterestingly, at least for the latest PL version I tested this with, assigning the training data point to a new variable seems to do the conversion automatically.\n\n\n\n\n\n imakash:\n\nThe updated pennylane version is behaving very weirdly sometimes.\n\n\nAnd we will be glad to help to fix the issue! But I couldn\u2019t reproduce the error with the code you sent. It runs with no errors here. Are you sure the code is running in the correct environment with the latest version of Pennylane installed?", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/10"}, "10": {"author": "imakash", "date": "1691078455587", "content": "Hello @ludmilaaasb - Yes, I am using the same environment where I have the new PL version installed. Can you check if there is a discrepancy in between the versions of other dependencies such as numpy?", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/11"}, "11": {"author": "ludmilaaasb", "date": "1691080143552", "content": "Your versions of Pennylane and Numpy are ok. Would you mind sharing your torch version and a minimal, self-contained working version of your code to reproduce the error? It\u2019s difficult to help without having the correct code to work on.\nFor instance, you can safely remove time, the printing statements, commented/unusead lines in general, and reduce the complexity of QNode\u2026 If you are having struggles to do that, I strongly recommend this video 1. It has some tips for how to make a post with proper code snippets and errors, so we can help you better!", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/12"}, "12": {"author": "imakash", "date": "1691081304718", "content": "Hello @ludmilaaasb\nMy torch version is 1.13.1+cpu.\nFollowing is the minimal working version of my code:\nimport pennylane as qml\nimport numpy as np\nimport torch\nimport torch.nn as nn\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev, interface = 'torch')\ndef simple_qubit_circuit(inputs, theta):\n    qml.RX(inputs, wires=0)\n    qml.RY(theta, wires=0)\n    return qml.expval(qml.PauliZ(0))\nclass QNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        shapes = {\n            \"theta\": 1\n        }\n        self.q = qml.qnn.TorchLayer(simple_qubit_circuit, shapes)\n    \n    def forward(self, input_value):\n        return self.q(input_value)\n\nx_train = np.array([0.2, 0.1, 0.2, 0.14, 0.11, 0.41, 0.55, 0.3, 0.31, 0.6])\nx_train = torch.tensor(x_train)\nmodel = QNet()\nout = model(x_train)\n\nThe issue arises only when I replace x_train with the following:\nx_train = torch.rand(10)\nx_train = torch.atan(x_train)\n", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/13"}, "13": {"author": "ludmilaaasb", "date": "1691084693164", "content": "\n\n\n imakash:\n\nMy torch version is 1.13.1+cpu.\n\n\nHmmm, the latest stable version of torch is 2.0.1. Try updating it and see if the error persists.\nUpdate: I created a clean environment using torch=1.13.1 and the latest version of pennylane and tested your code with\nx_train = torch.rand(10)\nx_train = torch.atan(x_train)\n\nNo issues were found. So, maybe you could try running it in a google colab notebook or making a clean install of your packages in a new environment.\nI hope this will help! Solution1", "link": "https://discuss.pennylane.ai//t/parameter-broadcasting-problem-with-torch-node/3269/14"}}