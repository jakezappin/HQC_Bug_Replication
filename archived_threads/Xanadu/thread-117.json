{"0": {"author": "shangshang_shi", "date": "1662601945649", "content": "Hello, every one. I am trying to construct a quantum convolutional nerural network with the article Hybrid Quantum-Classical Convolutional Neural Networks 7. In my codes,  I write a convolutional kernel, and like classical convolutional neural networks, sliding convolution kernels. I also use the maxpooling layers. After two quantum convolutional and two maxpooling layers,  adding the classical fully connections layers. But there is an error.\n\n\n-- coding: utf-8 --\n\nimport pennylane as qml\nfrom pennylane import numpy as np\nfrom pennylane.templates import RandomLayers\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport unitary\nn_epochs = 30   # Number of optimization epochs\nn_layers = 1    # Number of random layers\nn_train = 50    # Size of the train dataset\nn_test = 30     # Size of the test dataset\nPREPROCESS = True           # If False, skip quantum processing and load data from SAVE_PATH\nnp.random.seed(0)           # Seed for NumPy random number generator\ntf.random.set_seed(0)       # Seed for TensorFlow random number generator\n#\u8981\u60f3\u6d4b\u91cf\u51fa\u503c\u6765\uff0c\u5fc5\u987b\u52a0\u4e0a@qml.qnode(devl)\nmnist_dataset = keras.datasets.mnist\n(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\nReduce dataset size\ntrain_images = train_images[:n_train]\ntrain_labels = train_labels[:n_train]\ntest_images = test_images[:n_test]\ntest_labels = test_labels[:n_test]\nNormalize pixel values within 0 and 1\ntrain_images = train_images / 255\ntest_images = test_images / 255\nAdd extra dimension for convolution channels\ntrain_images = tf.reshape(train_images,[-1,784])\ntest_images = tf.reshape(test_images,[-1,784])\ntrain_images = tf.constant(train_images)\ntest_images = tf.constant(train_images)\ntrain_labels = tf.one_hot(train_labels, depth=10)\ntest_labels = tf.one_hot(test_labels, depth=10)\n#\u6570\u636e\u7f16\u7801\ndef embedding(x):\nindex=0\nfor i in range(2):\nfor j in range(2):\nqml.RY(np.pi * x[i][j], wires=index)\nindex = index+1\n#\u6ee4\u6ce2\u5668\ndef conv_filter1(U,params):\nU(params, wires=[0,1])\nU(params, wires=[2,3])\nU(params, wires=[1,2])\n#\u5377\u79ef\u6ee4\u6ce2\u5668\u7ebf\u8def\ndev1 = qml.device(\u201cdefault.qubit\u201d, wires = 4)\n@qml.qnode(dev1)\ndef circuit_block(x,U,params,U_params):\n# Encoding of 4 classical input values\nparam1 = params[0:U_params]\nparam2 = params[U_params: 2 * U_params]\nparam3 = params[2 * U_params: 3 * U_params]\nparam4 = params[3 * U_params: 4 * U_params]\n embedding(x)\n conv_filter1(U, param1)\n conv_filter1(U, param2)\n conv_filter1(U, param3)\n conv_filter1(U, param4)    \n# Measurement producing 4 classical output values\n return [qml.expval(qml.PauliZ(j)) for j in range(4)]\n\ndef qconv(images,conv_param,U,params,U_params):\nstride, pad = conv_param[\u2018stride\u2019], conv_param[\u2018pad\u2019]\nif(images.shape[1]=1):\nH, W = images.shape #N\u8868\u793a\u6570\u91cf\uff0cC\u8868\u793a\u901a\u9053\uff0cH\u8868\u793a\u56fe\u50cf\u9ad8\uff0cW\u8868\u793a\u56fe\u50cf\u5bbd\nx_padded = np.pad(images, (pad, pad), mode=\u2018constant\u2019)#\u586b\u5145\n#\u6ee4\u6ce2\u5668\u7684\u7ef4\u65702*2\nHH =2\nWW=2\nF=1\nH_new = 1 + (H + 2 * pad - HH) // stride\nW_new = 1 + (W + 2 * pad - WW) // stride\ns = stride\nout = np.zeros((H_new, W_new)) #\u5377\u79ef\u540e\u7684\u8f93\u51fa\u521d\u59cb\u5316\nfor j in range(H_new):\nfor k in range(W_new):\n#print x_padded[i, :, j*s:HH+j*s, k*s:WW+k*s].shape\n#print w[f].shape\n#print b.shape\n#print np.sum((x_padded[i, :, j*s:HH+j*s, k*s:WW+k*s] * w[f]))\nq_out = circuit_block(x_padded[js:HH+js, ks:WW+ks],U, params,U_params)\nq_sum = 0\nfor i in range(4):\nq_sum = q_sum + q_out[i]\nout[j, k] = q_sum\nreturn out\ndef qmaxpool(x,pool_param):\nHH, WW = pool_param[\u2018pool_height\u2019], pool_param[\u2018pool_width\u2019]\ns = pool_param[\u2018stride\u2019]\nH, W = x.shape\nH_new = 1 + (H - HH) // s\nW_new = 1 + (W - WW) // s\nout = np.zeros((H_new, W_new))\nfor k in range(H_new):\nfor l in range(W_new):\nwindow = x[ks:HH+ks, ls:WW+ls]\nout[k, l] = np.max(window)\nreturn out\ndev = qml.device(\u201cdefault.qubit\u201d, wires = 4)\n@qml.qnode(dev)\ndef qnode(inputs,params):\n# filter_size = 2 #\u6ee4\u6ce2\u5668\u7684\u5927\u5c0f2*2\n#conv_param = {\u2018stride\u2019: 1, \u2018pad\u2019: (filter_size - 1) // 2}\nconv_param = {\u2018stride\u2019: 1, \u2018pad\u2019: 1}\npool_param = {\u2018pool_height\u2019: 2, \u2018pool_width\u2019: 2, \u2018stride\u2019: 2}\nif(inputs.shape[0]==784):\ninputs = tf.reshape(inputs,[28,28])\nqconv1 = qconv(inputs, conv_param, unitary.U_TTN, params[0:8], U_params = 2)\nqmaxpool1 = qmaxpool(qconv1, pool_param)\nqconv2 = qconv(qmaxpool1, conv_param, unitary.U_TTN, params[8:16], U_params = 2)\nqmaxpool2 = qmaxpool(qconv2, pool_param)\nqmaxpool2 = tf.reshape(qmaxpool2,[49])\nreturn qmaxpool2\nweight_shapes = {\u201cparams\u201d: (16,1)}    #\u53c2\u6570\u540d\u5fc5\u987b\u548cqnode\u4e2d\u7684\u53c2\u6570\u540d\u4e00\u81f4\nqlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim = 10)\nclayer1 = tf.keras.layers.Dense(10)\nclayer2 = tf.keras.layers.Dense(10, activation=\u201csoftmax\u201d)\nq_model = tf.keras.models.Sequential([qlayer, clayer1, clayer2])\nopt = tf.keras.optimizers.SGD(learning_rate=0.5)\nq_model.compile(\noptimizer=\u2018adam\u2019,\nloss=\u201csparse_categorical_crossentropy\u201d,\nmetrics=[\u201caccuracy\u201d],\n) #model.compile()\u65b9\u6cd5\u7528\u4e8e\u5728\u914d\u7f6e\u8bad\u7ec3\u65b9\u6cd5\u65f6\uff0c\u544a\u77e5\u8bad\u7ec3\u65f6\u7528\u7684\u4f18\u5316\u5668\u3001\u635f\u5931\u51fd\u6570\u548c\u51c6\u786e\u7387\u8bc4\u6d4b\u6807\u51c6\nq_history = q_model.fit( #\u6570\u636e\u96c6\u6570\u636e\u7c7b\u578b\u5fc5\u987b\u662f\u5f20\u91cf,\u5c06\u8bad\u7ec3\u6570\u636e\u5728\u6a21\u578b\u4e2d\u8bad\u7ec3\u4e00\u5b9a\u6b21\u6570\uff0c\u8fd4\u56deloss\u548c\u6d4b\u91cf\u6307\u6807\ntrain_images,\ntrain_labels,\nvalidation_data=(test_images,test_labels),\nbatch_size=4,\nepochs=2,\nverbose=2,\n)\nCan you give me some advice ? thank you", "link": "https://discuss.pennylane.ai//t/quantum-convolutional-neural-network-convolution-kernels/2138/1"}, "1": {"author": "CatalinaAlbornoz", "date": "1662672996721", "content": "Hi @shangshang_shi, thank you for your question!\nUnfortunately your code is very long and not very well formatted so it\u2019s very hard for me to help you. Could you please share the following information so that I can help you better?\n1 - A minimal working example: the minimal version of your code that I can run and that reproduces the error. This means stripping your code of any non-essential parts, but including all of the essential ones such as the data. This process can help you debug yourself too. When you share this code make sure it\u2019s well formatted with only english characters so that I can try to reproduce your error too.\n2 - The output of qml.about(). Very often errors arise because you\u2019re not using the latest PennyLane version.\n3 - If the problem persists please share your full error traceback.\nThese 3 pieces of information are very important for us to help you!", "link": "https://discuss.pennylane.ai//t/quantum-convolutional-neural-network-convolution-kernels/2138/2"}, "2": {"author": "shangshang_shi", "date": "1662601945649", "content": "Hello, every one. I am trying to construct a quantum convolutional nerural network with the article Hybrid Quantum-Classical Convolutional Neural Networks 7. In my codes,  I write a convolutional kernel, and like classical convolutional neural networks, sliding convolution kernels. I also use the maxpooling layers. After two quantum convolutional and two maxpooling layers,  adding the classical fully connections layers. But there is an error.\n\n\n-- coding: utf-8 --\n\nimport pennylane as qml\nfrom pennylane import numpy as np\nfrom pennylane.templates import RandomLayers\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport unitary\nn_epochs = 30   # Number of optimization epochs\nn_layers = 1    # Number of random layers\nn_train = 50    # Size of the train dataset\nn_test = 30     # Size of the test dataset\nPREPROCESS = True           # If False, skip quantum processing and load data from SAVE_PATH\nnp.random.seed(0)           # Seed for NumPy random number generator\ntf.random.set_seed(0)       # Seed for TensorFlow random number generator\n#\u8981\u60f3\u6d4b\u91cf\u51fa\u503c\u6765\uff0c\u5fc5\u987b\u52a0\u4e0a@qml.qnode(devl)\nmnist_dataset = keras.datasets.mnist\n(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\nReduce dataset size\ntrain_images = train_images[:n_train]\ntrain_labels = train_labels[:n_train]\ntest_images = test_images[:n_test]\ntest_labels = test_labels[:n_test]\nNormalize pixel values within 0 and 1\ntrain_images = train_images / 255\ntest_images = test_images / 255\nAdd extra dimension for convolution channels\ntrain_images = tf.reshape(train_images,[-1,784])\ntest_images = tf.reshape(test_images,[-1,784])\ntrain_images = tf.constant(train_images)\ntest_images = tf.constant(train_images)\ntrain_labels = tf.one_hot(train_labels, depth=10)\ntest_labels = tf.one_hot(test_labels, depth=10)\n#\u6570\u636e\u7f16\u7801\ndef embedding(x):\nindex=0\nfor i in range(2):\nfor j in range(2):\nqml.RY(np.pi * x[i][j], wires=index)\nindex = index+1\n#\u6ee4\u6ce2\u5668\ndef conv_filter1(U,params):\nU(params, wires=[0,1])\nU(params, wires=[2,3])\nU(params, wires=[1,2])\n#\u5377\u79ef\u6ee4\u6ce2\u5668\u7ebf\u8def\ndev1 = qml.device(\u201cdefault.qubit\u201d, wires = 4)\n@qml.qnode(dev1)\ndef circuit_block(x,U,params,U_params):\n# Encoding of 4 classical input values\nparam1 = params[0:U_params]\nparam2 = params[U_params: 2 * U_params]\nparam3 = params[2 * U_params: 3 * U_params]\nparam4 = params[3 * U_params: 4 * U_params]\n embedding(x)\n conv_filter1(U, param1)\n conv_filter1(U, param2)\n conv_filter1(U, param3)\n conv_filter1(U, param4)    \n# Measurement producing 4 classical output values\n return [qml.expval(qml.PauliZ(j)) for j in range(4)]\n\ndef qconv(images,conv_param,U,params,U_params):\nstride, pad = conv_param[\u2018stride\u2019], conv_param[\u2018pad\u2019]\nif(images.shape[1]=1):\nH, W = images.shape #N\u8868\u793a\u6570\u91cf\uff0cC\u8868\u793a\u901a\u9053\uff0cH\u8868\u793a\u56fe\u50cf\u9ad8\uff0cW\u8868\u793a\u56fe\u50cf\u5bbd\nx_padded = np.pad(images, (pad, pad), mode=\u2018constant\u2019)#\u586b\u5145\n#\u6ee4\u6ce2\u5668\u7684\u7ef4\u65702*2\nHH =2\nWW=2\nF=1\nH_new = 1 + (H + 2 * pad - HH) // stride\nW_new = 1 + (W + 2 * pad - WW) // stride\ns = stride\nout = np.zeros((H_new, W_new)) #\u5377\u79ef\u540e\u7684\u8f93\u51fa\u521d\u59cb\u5316\nfor j in range(H_new):\nfor k in range(W_new):\n#print x_padded[i, :, j*s:HH+j*s, k*s:WW+k*s].shape\n#print w[f].shape\n#print b.shape\n#print np.sum((x_padded[i, :, j*s:HH+j*s, k*s:WW+k*s] * w[f]))\nq_out = circuit_block(x_padded[js:HH+js, ks:WW+ks],U, params,U_params)\nq_sum = 0\nfor i in range(4):\nq_sum = q_sum + q_out[i]\nout[j, k] = q_sum\nreturn out\ndef qmaxpool(x,pool_param):\nHH, WW = pool_param[\u2018pool_height\u2019], pool_param[\u2018pool_width\u2019]\ns = pool_param[\u2018stride\u2019]\nH, W = x.shape\nH_new = 1 + (H - HH) // s\nW_new = 1 + (W - WW) // s\nout = np.zeros((H_new, W_new))\nfor k in range(H_new):\nfor l in range(W_new):\nwindow = x[ks:HH+ks, ls:WW+ls]\nout[k, l] = np.max(window)\nreturn out\ndev = qml.device(\u201cdefault.qubit\u201d, wires = 4)\n@qml.qnode(dev)\ndef qnode(inputs,params):\n# filter_size = 2 #\u6ee4\u6ce2\u5668\u7684\u5927\u5c0f2*2\n#conv_param = {\u2018stride\u2019: 1, \u2018pad\u2019: (filter_size - 1) // 2}\nconv_param = {\u2018stride\u2019: 1, \u2018pad\u2019: 1}\npool_param = {\u2018pool_height\u2019: 2, \u2018pool_width\u2019: 2, \u2018stride\u2019: 2}\nif(inputs.shape[0]==784):\ninputs = tf.reshape(inputs,[28,28])\nqconv1 = qconv(inputs, conv_param, unitary.U_TTN, params[0:8], U_params = 2)\nqmaxpool1 = qmaxpool(qconv1, pool_param)\nqconv2 = qconv(qmaxpool1, conv_param, unitary.U_TTN, params[8:16], U_params = 2)\nqmaxpool2 = qmaxpool(qconv2, pool_param)\nqmaxpool2 = tf.reshape(qmaxpool2,[49])\nreturn qmaxpool2\nweight_shapes = {\u201cparams\u201d: (16,1)}    #\u53c2\u6570\u540d\u5fc5\u987b\u548cqnode\u4e2d\u7684\u53c2\u6570\u540d\u4e00\u81f4\nqlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim = 10)\nclayer1 = tf.keras.layers.Dense(10)\nclayer2 = tf.keras.layers.Dense(10, activation=\u201csoftmax\u201d)\nq_model = tf.keras.models.Sequential([qlayer, clayer1, clayer2])\nopt = tf.keras.optimizers.SGD(learning_rate=0.5)\nq_model.compile(\noptimizer=\u2018adam\u2019,\nloss=\u201csparse_categorical_crossentropy\u201d,\nmetrics=[\u201caccuracy\u201d],\n) #model.compile()\u65b9\u6cd5\u7528\u4e8e\u5728\u914d\u7f6e\u8bad\u7ec3\u65b9\u6cd5\u65f6\uff0c\u544a\u77e5\u8bad\u7ec3\u65f6\u7528\u7684\u4f18\u5316\u5668\u3001\u635f\u5931\u51fd\u6570\u548c\u51c6\u786e\u7387\u8bc4\u6d4b\u6807\u51c6\nq_history = q_model.fit( #\u6570\u636e\u96c6\u6570\u636e\u7c7b\u578b\u5fc5\u987b\u662f\u5f20\u91cf,\u5c06\u8bad\u7ec3\u6570\u636e\u5728\u6a21\u578b\u4e2d\u8bad\u7ec3\u4e00\u5b9a\u6b21\u6570\uff0c\u8fd4\u56deloss\u548c\u6d4b\u91cf\u6307\u6807\ntrain_images,\ntrain_labels,\nvalidation_data=(test_images,test_labels),\nbatch_size=4,\nepochs=2,\nverbose=2,\n)\nCan you give me some advice ? thank you", "link": "https://discuss.pennylane.ai//t/quantum-convolutional-neural-network-convolution-kernels/2138/3"}}