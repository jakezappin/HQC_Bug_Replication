{"0": {"author": "Amandeep", "date": "1679495070686", "content": "I am using qml.ttn with keras layer. But it throws an error TypeError: QNode must include an argument with name inputs for inputting data. It might be due to weights shape.\ndef block(weights, wires):\nqml.CNOT(wires=[wires[0],wires[1]])\nqml.RY(weights[0], wires=wires[0])\nqml.RY(weights[1], wires=wires[1])\nn_wires = 4\nn_block_wires = 2\nn_params_block = 2\nn_blocks = qml.TTN.get_n_blocks(range(n_wires),n_block_wires)\ndev = qml.device(\u201cdefault.qubit.tf\u201d, wires=4)\n@qml.qnode(dev, interface=\u201ctf\u201d, diff_method=\u201cbackprop\u201d)\ndef circuit(x, weights):\nqml.AngleEmbedding(x, wires=range(4))\nfor w in weights:\n\n    qml.TTN(range(n_wires),n_block_wires,block, n_params_block, w)\n  \nreturn qml.expval(qml.PauliZ(3))\n\nweights_shape={\u201cweights\u201d: (3,2)}\ninput_m = tf.keras.layers.Input(shape=(4,))\nkeras_1 = qml.qnn.KerasLayer(circuit, weights_shape, output_dim=1, name = \u201ckeras_1\u201d)(input_m)\noutput = tf.keras.layers.Dense(1, activation=\u2018softmax\u2019, name = \u201cdense_1\u201d)(keras_1)\n\nModel creation\nmodel = tf.keras.Model(inputs=input_m, outputs=output)", "link": "https://discuss.pennylane.ai//t/ttn-with-qnode-using-keras-layer/2753/1"}, "1": {"author": "CatalinaAlbornoz", "date": "1679691226971", "content": "Hi @Amandeep!\nThis is actually not about the weights\u2019 shape. What this error means is that your x argument in your circuit should actually be called inputs. So if you change the following 2 lines in your code it should run properly.\ndef circuit(inputs, weights):\n  qml.AngleEmbedding(inputs, wires=range(4))\n\nPlease let me know if this works for you!", "link": "https://discuss.pennylane.ai//t/ttn-with-qnode-using-keras-layer/2753/2"}, "2": {"author": "Amandeep", "date": "1679787376311", "content": "@CatalinaAlbornoz\nThank you for your prompt response. It worked fine. But, when i compiled the above code after making changes (as suggested), it throws now error of a shape\nclass BinaryTruePositives(tf.keras.metrics.Metric):\ndef __init__(self, name='Results', **kwargs):\n    super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n   \n    self.true_positives = self.add_weight(name='tp', initializer='zeros')\n\ndef update_state(self, y_true, y_pred, sample_weight=None):\n    \n   \n    y_true=tf.cast(y_true, dtype=tf.float32)\n    y_pred=tf.cast(y_pred, dtype=tf.float32)\n    \n    y_true = tf.squeeze(y_true)\n    \n    y_pred = tf.map_fn(lambda x: 1.0 if x >= 0.0 else -1.0, y_pred)\n    \n    z=tf.keras.backend.mean(tf.keras.backend.equal(y_true, y_pred))\n    \n   \n    self.true_positives.assign_add(z)\n\n\n\ndef result(self):\n    return self.true_positives\n\ndef reset_states(self):\n  \n    self.true_positives.assign(0.)\n\ninput_m = tf.keras.layers.Input(shape=(4,))\nkeras_1 = qml.qnn.KerasLayer(circuit, weights_shape, output_dim=1, name = \u201ckeras_1\u201d)(input_m)\noutput = tf.keras.layers.Dense(1, activation=\u2018softmax\u2019, name = \u201cdense_1\u201d)(keras_1)\n\nModel creation\nmodel = tf.keras.Model(inputs=input_m, outputs=output)\n\nModel compilation\nmodel.compile(\nloss=tf.keras.losses.MeanSquaredError(),\noptimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\nmetrics=[BinaryTruePositives()])\nhistory=model.fit(x_train, y_train, epochs=10, batch_size=3)\nValueError: Exception encountered when calling layer \u201ckeras_1\u201d (type KerasLayer).\nWeights tensor must have first dimension of length 3; got 2\nCall arguments received:\n\u2022 inputs=tf.Tensor(shape=(3, 4), dtype=float32)", "link": "https://discuss.pennylane.ai//t/ttn-with-qnode-using-keras-layer/2753/3"}, "3": {"author": "CatalinaAlbornoz", "date": "1680123779875", "content": "Hi @Amandeep,\nThank you for sharing your code. I\u2019m taking a look at it and will be back soon with an answer.", "link": "https://discuss.pennylane.ai//t/ttn-with-qnode-using-keras-layer/2753/4"}, "4": {"author": "CatalinaAlbornoz", "date": "1680191861624", "content": "Hi @Amandeep,\nAs the error mentions it seems that your weights don\u2019t have the right dimensions. Unfortunately your code is not very clear to me so I cannot find any specific suggestions on how to solve this issue.\nIf you provide a minimal working (or non-working) example I can try to help you more. A minimal example will be self-contained so that I can try to reproduce the problem, but it will be a simplified version of your code, so it should not include anything that doesn\u2019t strictly need to be there.\nThe process of creating the minimal non-working example can also be very beneficial to you in finding the solution yourself ", "link": "https://discuss.pennylane.ai//t/ttn-with-qnode-using-keras-layer/2753/5"}, "5": {"author": "Amandeep", "date": "1680203995725", "content": "Hi @CatalinaAlbornoz ,\nThank you for your response. Yes, the issue is with the shape of weights.\nCode is\nmnist = fetch_openml(\u2018mnist_784\u2019, version=1, cache=True)\ndata = mnist[\u2018data\u2019]\nlabels = np.array(mnist[\u2018target\u2019], dtype=np.int8)\nlabels_zero = labels[labels==0] + 1\nlabels_one = labels[labels==1] - 2\nbinary_labels = np.hstack((labels_zero, labels_one))\ndigits_zero = data[labels==0]\ndigits_one = data[labels==1]\ndata = np.vstack((digits_zero, digits_one))\ndata=data.reshape(data.shape[0], 28,28,1)\ndata=tf.image.resize(data[:], (2,2)).numpy()\ndata=data.reshape(data.shape[0], 4)\nsc = StandardScaler()\ndata = sc.fit_transform(data)\ndata = (data-np.min(data))/(np.max(data)-np.min(data))\ndata = np.mod(data, np.pi*0.5)\ndata.shape\nx_train, x_test, y_train, y_test = train_test_split(data, binary_labels, test_size=0.2)\ndef block(weights, wires):\nqml.CNOT(wires=[wires[0],wires[1]])\nqml.RY(weights[0], wires=wires[0])\nqml.RY(weights[1], wires=wires[1])\nn_wires = 4\nn_block_wires = 2\nn_params_block = 2\nn_blocks = qml.TTN.get_n_blocks(range(n_wires),n_block_wires)\nn_blocks\ndev = qml.device(\u201cdefault.qubit.tf\u201d, wires=4)\n@qml.qnode(dev, interface=\u201ctf\u201d, diff_method=\u201cbackprop\u201d)\ndef circuit(inputs, weights):\nqml.AngleEmbedding(inputs, wires=range(4))\nfor w in weights:\n\n    qml.TTN(range(n_wires),n_block_wires,block, n_params_block, w)\n  \nreturn qml.expval(qml.PauliZ(3))\n\nweights_shape={\u201cweights\u201d: (3,2)}\ninput_m = tf.keras.layers.Input(shape=(4,))\nkeras_1 = qml.qnn.KerasLayer(circuit, weights_shape, output_dim=1, name = \u201ckeras_1\u201d)(input_m)\noutput = tf.keras.layers.Dense(1, activation=\u2018softmax\u2019, name = \u201cdense_1\u201d)(keras_1)\n\nModel creation\nmodel = tf.keras.Model(inputs=input_m, outputs=output)\n\nModel compilation\nmodel.compile(\nloss=tf.keras.losses.MeanSquaredError(),\noptimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\nmetrics=[BinaryTruePositives()])\nhistory=model.fit(x_train, y_train, epochs=10, batch_size=3)\nThe idea is to combine tf layer at the end of TTN.", "link": "https://discuss.pennylane.ai//t/ttn-with-qnode-using-keras-layer/2753/6"}, "6": {"author": "isaacdevlugt", "date": "1680536486901", "content": "Hey @Amandeep! There\u2019s quite a bit missing from your code (e.g., imports and functions you\u2019ve defined) in order for us to replicate your issue. Are you able to attach a more minimal example that reproduces the error?", "link": "https://discuss.pennylane.ai//t/ttn-with-qnode-using-keras-layer/2753/7"}, "7": {"author": "Amandeep", "date": "1680633449217", "content": "Hi @isaacdevlugt @CatalinaAlbornoz\ncode:\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport pennylane as qml\nfrom pennylane import numpy as np\nfrom pennylane.templates.state_preparations import MottonenStatePreparation\nfrom pennylane.templates.layers import StronglyEntanglingLayers\nclass BinaryTruePositives(tf.keras.metrics.Metric):\ndef __init__(self, name='Results', **kwargs):\n    super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n   \n    self.true_positives = self.add_weight(name='tp', initializer='zeros')\n\ndef update_state(self, y_true, y_pred, sample_weight=None):\n    \n   \n    y_true=tf.cast(y_true, dtype=tf.float32)\n    y_pred=tf.cast(y_pred, dtype=tf.float32)\n    \n    y_true = tf.squeeze(y_true)\n    \n    y_pred = tf.map_fn(lambda x: 1.0 if x >= 0.0 else -1.0, y_pred)\n    \n    z=tf.keras.backend.mean(tf.keras.backend.equal(y_true, y_pred))\n    \n   \n    self.true_positives.assign_add(z)\n\n\n\ndef result(self):\n    return self.true_positives\n\ndef reset_states(self):\n  \n    self.true_positives.assign(0.)\n\nRest of the code is same.\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nmnist = fetch_openml(\u2018mnist_784\u2019, version=1, cache=True)\ndata = mnist[\u2018data\u2019]\nlabels = np.array(mnist[\u2018target\u2019], dtype=np.int8)\nlabels_zero = labels[labels==0] + 1\nlabels_one = labels[labels==1] - 2\nbinary_labels = np.hstack((labels_zero, labels_one))\ndigits_zero = data[labels==0]\ndigits_one = data[labels==1]\ndata = np.vstack((digits_zero, digits_one))\ndata=data.reshape(data.shape[0], 28,28,1)\ndata=tf.image.resize(data[:], (2,2)).numpy()\ndata=data.reshape(data.shape[0], 4)\nsc = StandardScaler()\ndata = sc.fit_transform(data)\ndata = (data-np.min(data))/(np.max(data)-np.min(data))\ndata = np.mod(data, np.pi*0.5)\ndata.shape", "link": "https://discuss.pennylane.ai//t/ttn-with-qnode-using-keras-layer/2753/8"}, "8": {"author": "isaacdevlugt", "date": "1680644264654", "content": "Hmmm, I\u2019m not able to reproduce your error. Here is the code I\u2019m running just to be sure:\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport pennylane as qml\nfrom pennylane import numpy as np\n\n\nclass BinaryTruePositives(tf.keras.metrics.Metric):\n    def __init__(self, name=\"Results\", **kwargs):\n        super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n\n        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n\n        y_true = tf.cast(y_true, dtype=tf.float32)\n        y_pred = tf.cast(y_pred, dtype=tf.float32)\n\n        y_true = tf.squeeze(y_true)\n\n        y_pred = tf.map_fn(lambda x: 1.0 if x >= 0.0 else -1.0, y_pred)\n\n        z = tf.keras.backend.mean(tf.keras.backend.equal(y_true, y_pred))\n\n        self.true_positives.assign_add(z)\n\n    def result(self):\n        return self.true_positives\n\n    def reset_states(self):\n        self.true_positives.assign(0.0)\n\n\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nmnist = fetch_openml(\"mnist_784\", version=1, cache=True)\ndata = mnist[\"data\"]\nlabels = np.array(mnist[\"target\"], dtype=np.int8)\n\nlabels_zero = labels[labels == 0] + 1\nlabels_one = labels[labels == 1] - 2\nbinary_labels = np.hstack((labels_zero, labels_one))\ndigits_zero = data[labels == 0]\ndigits_one = data[labels == 1]\ndata = np.vstack((digits_zero, digits_one))\ndata = data.reshape(data.shape[0], 28, 28, 1)\ndata = tf.image.resize(data[:], (2, 2)).numpy()\ndata = data.reshape(data.shape[0], 4)\nsc = StandardScaler()\ndata = sc.fit_transform(data)\n\ndata = (data - np.min(data)) / (np.max(data) - np.min(data))\ndata = np.mod(data, np.pi * 0.5)\ndata.shape\n\nx_train, x_test, y_train, y_test = train_test_split(data, binary_labels, test_size=0.2)\n\n\ndef block(weights, wires):\n    qml.CNOT(wires=[wires[0], wires[1]])\n    qml.RY(weights[0], wires=wires[0])\n    qml.RY(weights[1], wires=wires[1])\n\n\nn_wires = 4\nn_block_wires = 2\nn_params_block = 2\nn_blocks = qml.TTN.get_n_blocks(range(n_wires), n_block_wires)\n\ndev = qml.device(\"default.qubit.tf\", wires=4)\n\n\n@qml.qnode(dev, interface=\"tf\", diff_method=\"backprop\")\ndef circuit(inputs, weights):\n    qml.AngleEmbedding(inputs, wires=range(4))\n\n    for w in weights:\n\n        qml.TTN(range(n_wires), n_block_wires, block, n_params_block, w)\n\n    return qml.expval(qml.PauliZ(3))\n\n\nweights_shape = {\"weights\": (3, 2)}\n\ninput_m = tf.keras.layers.Input(shape=(4,))\nkeras_1 = qml.qnn.KerasLayer(circuit, weights_shape, output_dim=1, name=\"keras_1\")(\n    input_m\n)\noutput = tf.keras.layers.Dense(4, activation=\"softmax\", name=\"dense_1\")(input_m)\n\nmodel = tf.keras.Model(inputs=input_m, outputs=output)\n\nmodel.compile(\n    loss=tf.keras.losses.MeanSquaredError(),\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n)\n\nhistory = model.fit(x_train, y_train, epochs=10, batch_size=3)\n\n'''output:\nEpoch 1/10\n3942/3942 [==============================] - 2s 546us/step - loss: 1.0963\nEpoch 2/10\n3942/3942 [==============================] - 2s 550us/step - loss: 1.0963\nEpoch 3/10\n3942/3942 [==============================] - 2s 566us/step - loss: 1.0963\nEpoch 4/10\n3942/3942 [==============================] - 2s 551us/step - loss: 1.0963\nEpoch 5/10\n3942/3942 [==============================] - 2s 548us/step - loss: 1.0963\nEpoch 6/10\n3942/3942 [==============================] - 2s 549us/step - loss: 1.0963\nEpoch 7/10\n3942/3942 [==============================] - 2s 551us/step - loss: 1.0963\nEpoch 8/10\n3942/3942 [==============================] - 2s 552us/step - loss: 1.0963\nEpoch 9/10\n3942/3942 [==============================] - 2s 560us/step - loss: 1.0963\nEpoch 10/10\n3942/3942 [==============================] - 2s 616us/step - loss: 1.0963\n'''\n\nMaybe there is an issue with your version of PennyLane, tensorflow, etc. Are you using the most up-to-date versions of everything?", "link": "https://discuss.pennylane.ai//t/ttn-with-qnode-using-keras-layer/2753/9"}, "9": {"author": "Amandeep", "date": "1680645770585", "content": "@isaacdevlugt can you check\ninput_m = tf.keras.layers.Input(shape=(4,))\nkeras_1 = qml.qnn.KerasLayer(circuit, weights_shape, output_dim=1, name = \u201ckeras_1\u201d)(input_m)\noutput = tf.keras.layers.Dense(1, activation=\u2018softmax\u2019, name = \u201cdense_1\u201d)(keras_1)\nIt did not work. In your code, kera_1 layer is missed in execution.", "link": "https://discuss.pennylane.ai//t/ttn-with-qnode-using-keras-layer/2753/10"}, "10": {"author": "isaacdevlugt", "date": "1680705103761", "content": "Woops! You\u2019re right. One thing that was incorrectly defined was the shape of your weights. See template_weights in the code below.\nAfter changing the weight dimensions, there is still an error that has something to do with the fact that the output dimension of your quantum layer is only 1. If I change it to output a 2-dimensional array and change the input dimension of the output layer accordingly, then everything seems to work. I also used Sequential instead of Model to create the entire hybrid model for clarity.\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport pennylane as qml\nfrom pennylane import numpy as np\n\n\nclass BinaryTruePositives(tf.keras.metrics.Metric):\n    def __init__(self, name=\"Results\", **kwargs):\n        super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n\n        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n\n        y_true = tf.cast(y_true, dtype=tf.float32)\n        y_pred = tf.cast(y_pred, dtype=tf.float32)\n\n        y_true = tf.squeeze(y_true)\n\n        y_pred = tf.map_fn(lambda x: 1.0 if x >= 0.0 else -1.0, y_pred)\n\n        z = tf.keras.backend.mean(tf.keras.backend.equal(y_true, y_pred))\n\n        self.true_positives.assign_add(z)\n\n    def result(self):\n        return self.true_positives\n\n    def reset_states(self):\n        self.true_positives.assign(0.0)\n\n\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nmnist = fetch_openml(\"mnist_784\", version=1, cache=True)\ndata = mnist[\"data\"]\nlabels = np.array(mnist[\"target\"], dtype=np.int8)\n\nlabels_zero = labels[labels == 0] + 1\nlabels_one = labels[labels == 1] - 2\nbinary_labels = np.hstack((labels_zero, labels_one))\ndigits_zero = data[labels == 0]\ndigits_one = data[labels == 1]\ndata = np.vstack((digits_zero, digits_one))\ndata = data.reshape(data.shape[0], 28, 28, 1)\ndata = tf.image.resize(data[:], (2, 2)).numpy()\ndata = data.reshape(data.shape[0], 4)\nsc = StandardScaler()\ndata = sc.fit_transform(data)\n\ndata = (data - np.min(data)) / (np.max(data) - np.min(data))\ndata = np.mod(data, np.pi * 0.5)\ndata.shape\n\nx_train, x_test, y_train, y_test = train_test_split(data, binary_labels, test_size=0.2)\n\nprint(x_train.shape)\nprint(x_train[0])\n\ndef block(weights, wires):\n    qml.CNOT(wires=[wires[0], wires[1]])\n    qml.RY(weights[0], wires=wires[0])\n    qml.RY(weights[1], wires=wires[1])\n\n\nn_wires = 4\nn_block_wires = 2\nn_params_block = 2\nn_blocks = qml.TTN.get_n_blocks(range(n_wires), n_block_wires)\n\ndev = qml.device(\"default.qubit.tf\", wires=n_wires)\n\n@qml.qnode(dev, interface=\"tf\", diff_method=\"backprop\")\ndef circuit(inputs, weights):\n    qml.AngleEmbedding(inputs, wires=range(4))\n    qml.TTN(range(n_wires), n_block_wires, block, n_params_block, weights)\n    return [qml.expval(qml.PauliZ(3)), qml.expval(qml.PauliZ(2))]\n\ntemplate_weights = np.random.uniform(size=(n_blocks, 2))\nweights_shape = {\"weights\": template_weights.shape}\n\nkeras_1 = qml.qnn.KerasLayer(circuit, weights_shape, output_dim=2, name=\"keras_1\")\noutput = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"dense_1\")\n\nmodel = tf.keras.models.Sequential([keras_1, output])\n\nqlayer_out = circuit(x_train[0], template_weights)\nprint(circuit(x_train[0], template_weights))\n\nmodel.compile(\n    loss=tf.keras.losses.MeanSquaredError(),\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n)\n\nhistory = model.fit(x_train, y_train, epochs=2, batch_size=2)\n", "link": "https://discuss.pennylane.ai//t/ttn-with-qnode-using-keras-layer/2753/11"}}