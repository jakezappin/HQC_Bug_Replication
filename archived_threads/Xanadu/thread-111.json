{"0": {"author": "Prabhat_Kumar", "date": "1690890693647", "content": "I am working on a toy problem of regression using QNN circuit given in strawberry fields\u2019 website. There, we have used tensorflow\u2019s apply_gradient method, that follows your parameter in the forward pass (from 10th line to 7th).\nfor i in range(1000):\n    # reset the engine if it has already been executed\n    if eng.run_progs:\n        eng.reset()\n\n    with tf.GradientTape() as tape:\n        loss, fid, ket, trace = cost(weights)\n\n    # one repetition of the optimization\n    gradients = tape.gradient(loss, weights)\n    opt.apply_gradients(zip([gradients], [weights]))\n\n\nwhere cost function is\ndef cost(weights):\n    # Create a dictionary mapping from the names of the Strawberry Fields\n    # symbolic gate parameters to the TensorFlow weight values.\n    mapping = {p.name: w for p, w in zip(sf_params.flatten(), tf.reshape(weights, [-1]))}\n\n    # run the engine\n    state = eng.run(qnn, args=mapping).state\n    ket = state.ket()\n\n    difference = tf.reduce_sum(tf.abs(ket - target_state))\n    fidelity = tf.abs(tf.reduce_sum(tf.math.conj(ket) * target_state)) ** 2\n    return difference, fidelity, ket, tf.math.real(state.trace())\n\nWe can see that weights are given in the circuit as arg in eng.run(). This works well and good until I have to add X values (regression AX=Y) as parameters to the circuit. But I don\u2019t want the gradients with respect to those X values.\nI have done the following for encoding of X values into the circuit\nwith qnn.context as q:\n  for i in range(N):\n    ops.Dgate(x[0][i],0) | q[i]  # this is where I am encoding.\n\n  for k in range(layers):\n      layer(sf_params[k], q)\n\nand a little tweaking in the cost function as follows\n\ndef cost(param): # X_target should be scalar and X 1-D\n\n  #mapping = {p.name: w for p, w in zip(sf_params.flatten(), tf.reshape(params[i], [-1]))}\n\n  a=np.concatenate([sf_params.flatten(),x.flatten()])\n  b=tf.convert_to_tensor(np.concatenate([ np.reshape(param, [-1]),X[0]]))\n  mapping = {p.name: w for p, w in zip(a,b)}\n\n # all of this is just to include x values in mapping.\n  pred = eng.run(qnn, args=mapping).state\n  Y = pred.quad_expectation(0,phi=0.)[0]\n  diff = tf.abs(tf.cast(Y,dtype=tf.float64)-y[0])\n\n  return diff\n\nand main looks like\nopt = tf.keras.optimizers.Adam(learning_rate = lr)\n\ncost_progress = []\nbest_fid = 0\n\n# same old thing\n\neng = sf.Engine(backend='tf',backend_options={\"cutoff_dim\":cutoff})\nqnn = sf.Program(N)\n\nsf_params = np.arange(num_params).reshape(params.shape).astype(str)\nsf_params = np.array([qnn.params(*i) for i in sf_params])\n\n# a mere modification\nx= np.arange(num_params,N+num_params).astype(str)\nx= np.array([qnn.params(*i) for i in [x]])\ny = tf.constant(y)\nX = tf.constant(X)\n\n\n\nwith qnn.context as q:\n  for i in range(N):\n    ops.Dgate(x[0][i],0) | q[i]\n\n  for k in range(layers):\n      layer(sf_params[k], q)\n\n  #ops.MeasureX | q[0],q[1]\n\ncost_progress=[]\nfor i in range(reps):\n  \n\n  if eng.run_progs:\n    eng.reset()\n\n  with tf.GradientTape() as tape:\n    tape.watch(params)\n    loss = cost(params)\n        \n\n  # one repetition of the optimization\n  gradients = tape.gradient(loss, params)\n  print(i, loss ,params, gradients)\n  opt.apply_gradients(zip([gradients], [params]))\n\n  cost_progress.append(loss)\n\nThis code is unable to calculate the gradients, it gives gradients= NONE, when I print them. And I think, it is only due to the above complexity of the code. So, what is the efficient way to do all this, so that my optimizer can understand my cost function.\nExact error is the following\nValueError: No gradients provided for any variable: ([\u2018Variable:0\u2019],). Provided grads_and_vars is ((None, <tf.Variable \u2018Variable:0\u2019 shape=(1, 14) dtype=float32, numpy=\narray([[ 1.6708091e-02,  2.2838793e-05, -5.2734390e-03, -6.9317231e-03,\n-3.0103172e-03,  3.6114827e-03, -1.0168127e-02,  6.7833858e-03,\n1.1122092e-02,  1.8201470e-02, -8.2193566e-03, -6.1826045e-03,\n1.2012760e-02,  1.0526734e-02]], dtype=float32)>),).\n\n\n Solved by Prabhat_Kumar in post #2 \n\n\n                I guess since I have got the problem solved, I\u2019ll put it here. I don\u2019t understand the significance of the current syntax of using mapping instead of good old pennylane format, that is why I still prefer a better and efficient way to use quantum circuits. \nBut the whole problem was not from strawberr\u2026\n              \n", "link": "https://discuss.pennylane.ai//t/how-to-do-encoding-in-qnn-efficiently-in-strawberryfields-so-that-optimizers-can-work-easily-in-variational-setting/3257/1"}, "1": {"author": "Prabhat_Kumar", "date": "1690986620763", "content": "I guess since I have got the problem solved, I\u2019ll put it here. I don\u2019t understand the significance of the current syntax of using mapping instead of good old pennylane format, that is why I still prefer a better and efficient way to use quantum circuits.\nBut the whole problem was not from strawberryfields\u2019 front. It was a problem from tensorflow front that I broke the graph by using convert_to_tensor in the cost function. All I did was to start all my variables as tensors and use tf function solely and it worked. For example, params and x were made tf.Variable and tf.concat helped me to join them both in cost function.Solution", "link": "https://discuss.pennylane.ai//t/how-to-do-encoding-in-qnn-efficiently-in-strawberryfields-so-that-optimizers-can-work-easily-in-variational-setting/3257/2"}, "2": {"author": "isaacdevlugt", "date": "1690987362250", "content": "Hey @Prabhat_Kumar! Welcome back to the forum \nI was in the middle of writing back to you but you responded with a solution!\n\nIt was a problem from tensorflow front that I broke the graph by using convert_to_tensor in the cost function\n\nThis is a good point in that whenever you\u2019re doing machine learning, it\u2019s best practice to always stay within the data types of the machine learning language you are using. In this case, using TF-native functions to manipulate tensors to your liking is the way to do it, as jumping in and out of TF via NumPy can be problematic in some cases.\nI\u2019m glad you found a solution though! If you don\u2019t mind, can you share the full code example just for anyone looking at this thread in the future?1", "link": "https://discuss.pennylane.ai//t/how-to-do-encoding-in-qnn-efficiently-in-strawberryfields-so-that-optimizers-can-work-easily-in-variational-setting/3257/3"}, "3": {"author": "Prabhat_Kumar", "date": "1690890693647", "content": "I am working on a toy problem of regression using QNN circuit given in strawberry fields\u2019 website. There, we have used tensorflow\u2019s apply_gradient method, that follows your parameter in the forward pass (from 10th line to 7th).\nfor i in range(1000):\n    # reset the engine if it has already been executed\n    if eng.run_progs:\n        eng.reset()\n\n    with tf.GradientTape() as tape:\n        loss, fid, ket, trace = cost(weights)\n\n    # one repetition of the optimization\n    gradients = tape.gradient(loss, weights)\n    opt.apply_gradients(zip([gradients], [weights]))\n\n\nwhere cost function is\ndef cost(weights):\n    # Create a dictionary mapping from the names of the Strawberry Fields\n    # symbolic gate parameters to the TensorFlow weight values.\n    mapping = {p.name: w for p, w in zip(sf_params.flatten(), tf.reshape(weights, [-1]))}\n\n    # run the engine\n    state = eng.run(qnn, args=mapping).state\n    ket = state.ket()\n\n    difference = tf.reduce_sum(tf.abs(ket - target_state))\n    fidelity = tf.abs(tf.reduce_sum(tf.math.conj(ket) * target_state)) ** 2\n    return difference, fidelity, ket, tf.math.real(state.trace())\n\nWe can see that weights are given in the circuit as arg in eng.run(). This works well and good until I have to add X values (regression AX=Y) as parameters to the circuit. But I don\u2019t want the gradients with respect to those X values.\nI have done the following for encoding of X values into the circuit\nwith qnn.context as q:\n  for i in range(N):\n    ops.Dgate(x[0][i],0) | q[i]  # this is where I am encoding.\n\n  for k in range(layers):\n      layer(sf_params[k], q)\n\nand a little tweaking in the cost function as follows\n\ndef cost(param): # X_target should be scalar and X 1-D\n\n  #mapping = {p.name: w for p, w in zip(sf_params.flatten(), tf.reshape(params[i], [-1]))}\n\n  a=np.concatenate([sf_params.flatten(),x.flatten()])\n  b=tf.convert_to_tensor(np.concatenate([ np.reshape(param, [-1]),X[0]]))\n  mapping = {p.name: w for p, w in zip(a,b)}\n\n # all of this is just to include x values in mapping.\n  pred = eng.run(qnn, args=mapping).state\n  Y = pred.quad_expectation(0,phi=0.)[0]\n  diff = tf.abs(tf.cast(Y,dtype=tf.float64)-y[0])\n\n  return diff\n\nand main looks like\nopt = tf.keras.optimizers.Adam(learning_rate = lr)\n\ncost_progress = []\nbest_fid = 0\n\n# same old thing\n\neng = sf.Engine(backend='tf',backend_options={\"cutoff_dim\":cutoff})\nqnn = sf.Program(N)\n\nsf_params = np.arange(num_params).reshape(params.shape).astype(str)\nsf_params = np.array([qnn.params(*i) for i in sf_params])\n\n# a mere modification\nx= np.arange(num_params,N+num_params).astype(str)\nx= np.array([qnn.params(*i) for i in [x]])\ny = tf.constant(y)\nX = tf.constant(X)\n\n\n\nwith qnn.context as q:\n  for i in range(N):\n    ops.Dgate(x[0][i],0) | q[i]\n\n  for k in range(layers):\n      layer(sf_params[k], q)\n\n  #ops.MeasureX | q[0],q[1]\n\ncost_progress=[]\nfor i in range(reps):\n  \n\n  if eng.run_progs:\n    eng.reset()\n\n  with tf.GradientTape() as tape:\n    tape.watch(params)\n    loss = cost(params)\n        \n\n  # one repetition of the optimization\n  gradients = tape.gradient(loss, params)\n  print(i, loss ,params, gradients)\n  opt.apply_gradients(zip([gradients], [params]))\n\n  cost_progress.append(loss)\n\nThis code is unable to calculate the gradients, it gives gradients= NONE, when I print them. And I think, it is only due to the above complexity of the code. So, what is the efficient way to do all this, so that my optimizer can understand my cost function.\nExact error is the following\nValueError: No gradients provided for any variable: ([\u2018Variable:0\u2019],). Provided grads_and_vars is ((None, <tf.Variable \u2018Variable:0\u2019 shape=(1, 14) dtype=float32, numpy=\narray([[ 1.6708091e-02,  2.2838793e-05, -5.2734390e-03, -6.9317231e-03,\n-3.0103172e-03,  3.6114827e-03, -1.0168127e-02,  6.7833858e-03,\n1.1122092e-02,  1.8201470e-02, -8.2193566e-03, -6.1826045e-03,\n1.2012760e-02,  1.0526734e-02]], dtype=float32)>),).\n\n\n Solved by Prabhat_Kumar in post #2 \n\n\n                I guess since I have got the problem solved, I\u2019ll put it here. I don\u2019t understand the significance of the current syntax of using mapping instead of good old pennylane format, that is why I still prefer a better and efficient way to use quantum circuits. \nBut the whole problem was not from strawberr\u2026\n              \n", "link": "https://discuss.pennylane.ai//t/how-to-do-encoding-in-qnn-efficiently-in-strawberryfields-so-that-optimizers-can-work-easily-in-variational-setting/3257/4"}}