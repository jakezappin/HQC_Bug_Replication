{"0": {"author": "vabelis", "date": "1647347202119", "content": "Hi everyone. I have run some tests with the following simple hybrid network, using PyTorch and treating the qnode as a TorchLayer. The code is the following (as a new user I cannot upload a file):\nimport numpy as np\nfrom sklearn.datasets import make_moons\nimport torch\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport pennylane as qml\nimport sys\nfrom time import perf_counter\n\nclass Model(nn.Module):\n    def __init__(self, dev, diff_method=\"backprop\"):\n        super().__init__()\n\n        self.cnet_in = self.cnet()\n        self.qcircuit = qml.qnode(dev, interface=\"torch\", \n                                  diff_method=diff_method)(self.qnode)\n        \n        weight_shape = {\"weights\":(2,)}\n        self.qlayer = qml.qnn.TorchLayer(self.qcircuit, weight_shape)\n        self.cnet_out = self.cnet()\n\n    def cnet(self):\n        layers = [nn.Linear(2,10), nn.ReLU(True), nn.Linear(10,2), nn.Tanh()]\n        return nn.Sequential(*layers)   \n\n    def qnode(self, inputs, weights):\n        # Data encoding:\n        for x in range(len(inputs)):\n            qml.Hadamard(x)\n            qml.RZ(2.0 * inputs[x], wires=x)\n        # Trainable part:\n        qml.CNOT(wires=[0,1])\n        qml.RY(weights[0], wires=0)\n        qml.RY(weights[1], wires=1)\n        return [qml.expval(qml.PauliZ(wires=0)), qml.expval(qml.PauliZ(wires=1))]\n\n    def forward(self, x):\n        x1 = self.cnet_in(x)\n        x2 = self.qlayer(x1)\n        x_output = self.cnet_out(x2)\n        return x_output\n\ndef train(X, y_hot, dev_name, diff_method):\n    \n    dev = qml.device(dev_name, wires=2, shots=None)\n    model  = Model(dev, diff_method)\n    \n    # Train the model\n    opt = torch.optim.SGD(model.parameters(), lr=0.2)\n    loss = torch.nn.L1Loss()\n\n    X = torch.tensor(X, requires_grad=False).float()\n    y_hot = y_hot.float()\n\n    batch_size = 5\n    batches = 200 // batch_size\n\n    data_loader = torch.utils.data.DataLoader(\n        list(zip(X, y_hot)), batch_size=batch_size, shuffle=True, drop_last=True\n    )\n\n    epochs = 6\n\n    for epoch in range(epochs):\n\n        running_loss = 0\n\n        for xs, ys in data_loader:\n            opt.zero_grad()\n\n            loss_evaluated = loss(model(xs), ys)\n            loss_evaluated.backward()\n\n            opt.step()\n\n            running_loss += loss_evaluated\n\n        avg_loss = running_loss / batches\n        print(\"Average loss over epoch {}: {:.4f}\".format(epoch + 1, avg_loss))\n\n    y_pred = model(X)\n    predictions = torch.argmax(y_pred, axis=1).detach().numpy()\n\n    correct = [1 if p == p_true else 0 for p, p_true in zip(predictions, y)]\n    accuracy = sum(correct) / len(correct)\n    print(f\"Accuracy: {accuracy * 100}%\")\n\nif __name__ == \"__main__\":\n    torch.manual_seed(42)\n    np.random.seed(42)\n    X, y = make_moons(n_samples=200, noise=0.1)\n    y_ = torch.unsqueeze(torch.tensor(y), 1)  # used for one-hot encoded labels\n    y_hot = torch.scatter(torch.zeros((200, 2)), 1, y_, 1)\n    begin_time = perf_counter()\n    train(X, y_hot, str(sys.argv[1]), str(sys.argv[2]))\n    end_time = perf_counter()\n    runtime = end_time-begin_time\n    print(f'Runtime: {runtime:.2e} s or {(runtime/60):.2e} min.')\n\nThe conda environment contains:\n\npytorch=1.10.2\npennylane=0.21.0\nnumpy=1.22.2\n\n\nObservations\nI ran tests with different combinations of devices and differentiation methods. Of course, not all of the combinations are possible, e.g., lightning.qubit does not support backprop at the time of writing this post. Measuring each time the runtime, and monitoring the usage of memory and number of cores that are utilised. The results can be reproduced with the code above, but have been consistent with other tests on larger and more complex hybrid networks.\n\nadjoint differenatiation method (vs. backprop) has always been faster for my tests. For both lightning.qubit and default.qubit.\nadjoint method consumed significantly less memory than backprop.\nFor lightning.qubit + adjoint, I observe that many sub-procceses are created and run in parallel. However for default.qubit + adjoint, only one core is utilised.\nWhen using backprop + default.qubit I get the following warning:\n\n/work/vabelis/miniconda3/envs/ae_qml_pnl/lib/python3.8/site-packages/torch/autograd/__init__.py:154: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811757556/work/aten/src/ATen/native/Copy.cpp:244.)\n Variable._execution_engine.run_backward(\n\nAs mentione also in this post.\n\nQuestions\na. Do you think that the above observations are universal for hybrid networks? For example, will the adjoint method always be faster compared to backprop for larger networks and different measurement operators (e.g. 1 qubit measurements)? Is there some threshold after/before which backprop is better?\nb. When one uses the adjoint method, is the classical part of the network still trained with backprop in PyTorch? If that is true, I find observations 2. and 3. counterintuitive. That is, when using backprop PyTorch utilises more cores via multithreading. Hovewer, with default.qubit and adjoint only one core was used (less memory too), and it still performed better than backprop + default.qubit, which consumed significantly more memory and number of cores. I would be grateful for any insights on this matter \nc. If we are interested in the best possible balance between training time and resources required, is the recommended option always lightning.qubit + adjoint?", "link": "https://discuss.pennylane.ai//t/pytorch-benchmarks-different-devices-and-computing-resources/1727/1"}, "1": {"author": "CatalinaAlbornoz", "date": "1647376953609", "content": "Hi @vabelis, great questions!\na. Adjoint differentiation should always be better. The problem with adjoint differentiation is that it can only be used on simulators (same as backprop) and not on real hardware. I recommend that you take a look at the graphs at the end of this demo 4 to get an idea on how the different methods compare in time performance.\nb. The same demo 4 on Adjoint differentiation will give you some insight on how it works and why it\u2019s so efficient. For your specific question you should notice that adjoint diff is defined as the differentiation method for a particular qnode. Anything outside from the qnode will not be differentiated with the adjoint method.\nc. Yes, lightning.qubit  +  adjoint is the recommended combination if you need better performance.\nI hope this helps!", "link": "https://discuss.pennylane.ai//t/pytorch-benchmarks-different-devices-and-computing-resources/1727/2"}, "2": {"author": "vabelis", "date": "1647347202119", "content": "Hi everyone. I have run some tests with the following simple hybrid network, using PyTorch and treating the qnode as a TorchLayer. The code is the following (as a new user I cannot upload a file):\nimport numpy as np\nfrom sklearn.datasets import make_moons\nimport torch\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport pennylane as qml\nimport sys\nfrom time import perf_counter\n\nclass Model(nn.Module):\n    def __init__(self, dev, diff_method=\"backprop\"):\n        super().__init__()\n\n        self.cnet_in = self.cnet()\n        self.qcircuit = qml.qnode(dev, interface=\"torch\", \n                                  diff_method=diff_method)(self.qnode)\n        \n        weight_shape = {\"weights\":(2,)}\n        self.qlayer = qml.qnn.TorchLayer(self.qcircuit, weight_shape)\n        self.cnet_out = self.cnet()\n\n    def cnet(self):\n        layers = [nn.Linear(2,10), nn.ReLU(True), nn.Linear(10,2), nn.Tanh()]\n        return nn.Sequential(*layers)   \n\n    def qnode(self, inputs, weights):\n        # Data encoding:\n        for x in range(len(inputs)):\n            qml.Hadamard(x)\n            qml.RZ(2.0 * inputs[x], wires=x)\n        # Trainable part:\n        qml.CNOT(wires=[0,1])\n        qml.RY(weights[0], wires=0)\n        qml.RY(weights[1], wires=1)\n        return [qml.expval(qml.PauliZ(wires=0)), qml.expval(qml.PauliZ(wires=1))]\n\n    def forward(self, x):\n        x1 = self.cnet_in(x)\n        x2 = self.qlayer(x1)\n        x_output = self.cnet_out(x2)\n        return x_output\n\ndef train(X, y_hot, dev_name, diff_method):\n    \n    dev = qml.device(dev_name, wires=2, shots=None)\n    model  = Model(dev, diff_method)\n    \n    # Train the model\n    opt = torch.optim.SGD(model.parameters(), lr=0.2)\n    loss = torch.nn.L1Loss()\n\n    X = torch.tensor(X, requires_grad=False).float()\n    y_hot = y_hot.float()\n\n    batch_size = 5\n    batches = 200 // batch_size\n\n    data_loader = torch.utils.data.DataLoader(\n        list(zip(X, y_hot)), batch_size=batch_size, shuffle=True, drop_last=True\n    )\n\n    epochs = 6\n\n    for epoch in range(epochs):\n\n        running_loss = 0\n\n        for xs, ys in data_loader:\n            opt.zero_grad()\n\n            loss_evaluated = loss(model(xs), ys)\n            loss_evaluated.backward()\n\n            opt.step()\n\n            running_loss += loss_evaluated\n\n        avg_loss = running_loss / batches\n        print(\"Average loss over epoch {}: {:.4f}\".format(epoch + 1, avg_loss))\n\n    y_pred = model(X)\n    predictions = torch.argmax(y_pred, axis=1).detach().numpy()\n\n    correct = [1 if p == p_true else 0 for p, p_true in zip(predictions, y)]\n    accuracy = sum(correct) / len(correct)\n    print(f\"Accuracy: {accuracy * 100}%\")\n\nif __name__ == \"__main__\":\n    torch.manual_seed(42)\n    np.random.seed(42)\n    X, y = make_moons(n_samples=200, noise=0.1)\n    y_ = torch.unsqueeze(torch.tensor(y), 1)  # used for one-hot encoded labels\n    y_hot = torch.scatter(torch.zeros((200, 2)), 1, y_, 1)\n    begin_time = perf_counter()\n    train(X, y_hot, str(sys.argv[1]), str(sys.argv[2]))\n    end_time = perf_counter()\n    runtime = end_time-begin_time\n    print(f'Runtime: {runtime:.2e} s or {(runtime/60):.2e} min.')\n\nThe conda environment contains:\n\npytorch=1.10.2\npennylane=0.21.0\nnumpy=1.22.2\n\n\nObservations\nI ran tests with different combinations of devices and differentiation methods. Of course, not all of the combinations are possible, e.g., lightning.qubit does not support backprop at the time of writing this post. Measuring each time the runtime, and monitoring the usage of memory and number of cores that are utilised. The results can be reproduced with the code above, but have been consistent with other tests on larger and more complex hybrid networks.\n\nadjoint differenatiation method (vs. backprop) has always been faster for my tests. For both lightning.qubit and default.qubit.\nadjoint method consumed significantly less memory than backprop.\nFor lightning.qubit + adjoint, I observe that many sub-procceses are created and run in parallel. However for default.qubit + adjoint, only one core is utilised.\nWhen using backprop + default.qubit I get the following warning:\n\n/work/vabelis/miniconda3/envs/ae_qml_pnl/lib/python3.8/site-packages/torch/autograd/__init__.py:154: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811757556/work/aten/src/ATen/native/Copy.cpp:244.)\n Variable._execution_engine.run_backward(\n\nAs mentione also in this post.\n\nQuestions\na. Do you think that the above observations are universal for hybrid networks? For example, will the adjoint method always be faster compared to backprop for larger networks and different measurement operators (e.g. 1 qubit measurements)? Is there some threshold after/before which backprop is better?\nb. When one uses the adjoint method, is the classical part of the network still trained with backprop in PyTorch? If that is true, I find observations 2. and 3. counterintuitive. That is, when using backprop PyTorch utilises more cores via multithreading. Hovewer, with default.qubit and adjoint only one core was used (less memory too), and it still performed better than backprop + default.qubit, which consumed significantly more memory and number of cores. I would be grateful for any insights on this matter \nc. If we are interested in the best possible balance between training time and resources required, is the recommended option always lightning.qubit + adjoint?", "link": "https://discuss.pennylane.ai//t/pytorch-benchmarks-different-devices-and-computing-resources/1727/3"}}