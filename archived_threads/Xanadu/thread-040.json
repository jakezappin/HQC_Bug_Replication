{"0": {"author": "Andre_Sequeira", "date": "1632356632179", "content": "Hello guys,\nI\u2019m using a TorchLayer to use the new support for native backpropagation using PyTorch. However, the torchlayer trains much more slowly compared to a simple torch fully connected layer, for the same problem. I was wondering if batching inputs is occurring under the hood and if it\u2019s not, what can I do to speed up training?\nBest regards.", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/1"}, "1": {"author": "Tom_Bromley", "date": "1632397461545", "content": "Hey @Andre_Sequeira!\nAlthough the TorchLayer accepts batched inputs, no batch-level optimization is going on under the hood. You can check out how things work in the forward 5 method of TorchLayer.\nThere might be a couple of reasons why the hybrid model you are using is taking longer to train than a simple fully connected classical layer. From a fundamental perspective, we do expect the training times to increase exponentially on a simulator as we scale the number of qubits. This is what provides the nice motivation to construct the quantum hardware.\nOn the other hand, for a small number of qubits we can still try a couple of things to extract more performance. One approach is to optimize the way we differentiate the circuit. In older versions of PennyLane, the diff_method=\"parameter-shift\" method was used for Torch, you can check out more details here 1. Luckily, in the new version of PennyLane 1 released a few days ago, we added support for backpropagation in the Torch interface. This simulator-only approach can provide a big speedup! In fact, I just tried running this 5 tutorial and it took 8 seconds to train in the latest version of PennyLane and 44 seconds with an older version \nSo in summary, although there are some fundamental reasons why we might expect training to be tough on quantum simulators, you could try upgrading your PennyLane version and you might get a speedup without having to change any code!1", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/2"}, "2": {"author": "Andre_Sequeira", "date": "1632399919347", "content": "Hey @Tom_Bromley,\nthank you for your support.\n\nThere might be a couple of reasons why the hybrid model you are using is taking longer to train than a simple fully connected classical layer. From a fundamental perspective, we do expect the training times to increase exponentially on a simulator as we scale the number of qubits. This is what provides the nice motivation to construct the quantum hardware.\n\nThe problem that i\u2019m working on is relatively small though, only 4 qubits and 3 layers , each with 8 parameters to train, so 24 trainable parameters. The backpropagation from the new version of pennylane provided indeed a massive speedup, however, i have a big batch of data to feed into the quantum neural network. This is where i see the quantum model taking longer to train.\n\nAlthough the  TorchLayer  accepts batched inputs, no batch-level optimization is going on under the hood.\n\nIs there anything that i can do with respect to data in order to speed up things a little bit? Is it possible to do batch-level optimization?", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/3"}, "3": {"author": "Tom_Bromley", "date": "1632434541056", "content": "Hi @Andre_Sequeira,\nI\u2019m glad the PennyLane update provided some speedup! Unfortunately there is not a lot that we can do in terms of optimizing iteration over a batch dimension in incoming tensors. This is not a feature we have prioritized so far, partly due to the limitations of quantum hardware.\nHowever, it\u2019s useful feedback to know that you\u2019re interested in more efficient tensor batching. We have recently been working on a batch_transform 6 decorator, which is helpful for things like supporting differentiability and submitting multiple circuit executions to hardware as one job. This functionality may eventually help us allow batching over a tensor dimension on supported devices.\nThanks,\nTom2 Replies", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/4"}, "4": {"author": "Andre_Sequeira", "date": "1632434885853", "content": "Hey @Tom_Bromley,\nok, that is unfortunate, but keep up the good work !!\nThank you for your help.1", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/5"}, "5": {"author": "Hevish_Cowlessur", "date": "1691111694535", "content": "Hi,\nI have updated my version of Pennylane from 0.29.0 to 0.31.0. However, it looks like I am getting errors while running Batches of Input on a torchlayer in a hybrid set-up. The same code works fine on V0.29.0 but getting dimension error along the line of \u201cInput size [batch_number,-1] not valid for n_wires\u201d when I upgraded my version to 0.31.0. Is that a common problem for the latest version?\nThank you\nHevish1 Reply", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/6"}, "6": {"author": "kevinkawchak", "date": "1691127987402", "content": "Hello @Tom_Bromley,\nIs it now possible to get back propagation for both ResNet and VQC for the QTL model? Best regards.\nSource:\n\n\npennylane.ai\n\n\n\nQuantum transfer learning 5\nCombine PyTorch and PennyLane to train a hybrid quantum-classical image classifier using transfer learning.\n\n\n\n\n\n1 Reply", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/7"}, "7": {"author": "isaacdevlugt", "date": "1691158656000", "content": "Hey @Hevish_Cowlessur! Welcome to the forum \nIt\u2019s tough to say what\u2019s going on without seeing a code example. Can you respond with something minimal that replicates the behaviour you\u2019re seeing?", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/8"}, "8": {"author": "isaacdevlugt", "date": "1691158863420", "content": "@kevinkawchak\n\nIs it now possible to get back propagation for both ResNet and VQC for the QTL model?\n\nHybrid classical-quantum models with PennyLane will use backprop when optimizing parameters. Here is a good article: Hybrid computation \u2014 PennyLane 2\n\n\u2026 hybrid computations are compatible with techniques like the famous backpropagation algorithm (also known as reverse-mode automatic differentiation), the workhorse algorithm for training deep learning models. This means that we can differentiate end-to-end through hybrid quantum-classical computations. Quantum algorithms can thus be trained the same way as classical deep learning models.\n\nHope this helps!", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/9"}, "9": {"author": "kevinkawchak", "date": "1691212120291", "content": "Hello @isaacdevlugt,\nWhen keeping the default param.requires_grad = False to only update the quantum circuit parameters, the model runs correctly for training and validation.\nWhen changing to param.requires_grad = True to update both ResNet and quantum circuit parameters, the training results are identical to the prior scenario, and does not complete validation.\nName: PennyLane\nVersion: 0.31.1\nSummary: PennyLane is a Python quantum machine learning library by Xanadu Inc.\nHome-page: GitHub - PennyLaneAI/pennylane: PennyLane is a cross-platform Python library for differentiable programming of quantum computers. Train a quantum computer the same way as a neural network. 1\nAuthor:\nAuthor-email:\nLicense: Apache License 2.0\nLocation: /usr/local/lib/python3.10/dist-packages\nRequires: appdirs, autograd, autoray, cachetools, networkx, numpy, pennylane-lightning, requests, rustworkx, scipy, semantic-version, toml, typing-extensions\nRequired-by: PennyLane-Lightning\nPlatform info:           Linux-5.15.109\u00b1x86_64-with-glibc2.35\nPython version:          3.10.12\nNumpy version:           1.22.4\nScipy version:           1.10.1\nInstalled devices:2 Replies", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/10"}, "10": {"author": "Ivana_at_Xanadu", "date": "1691402251605", "content": "Hey @kevinkawchak , could I ask you to share a minimal self-contained code example that shows the behavior you\u2019re trying to solve?", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/11"}, "11": {"author": "kevinkawchak", "date": "1691475282945", "content": "Hello @Ivana_at_Xanadu, are you able to run the QTL model with param.requires_grad = True? Best regards.", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/12"}, "12": {"author": "Ivana_at_Xanadu", "date": "1691485288984", "content": "Hi @kevinkawchak , which code would that be?  I don\u2019t think you included anything in your post. If you could share a standalone (minimal) code example, that would be a great first step.1 Reply", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/13"}, "13": {"author": "isaacdevlugt", "date": "1691500984680", "content": "Hey @kevinkawchak,\n\nWhen keeping the default param.requires_grad = False to only update the quantum circuit parameters, the model runs correctly for training and validation. When changing to param.requires_grad = True to update both ResNet and quantum circuit parameters, the training results are identical to the prior scenario, and does not complete validation.\n\nIn the transfer learning demo, the ResNet18 model used is pretrained.\n\nWe focus on the CQ transfer learning scheme discussed in the previous section and we give a specific example.\n\n\nAs pre-trained network A, we use ResNet18, a deep residual neural network introduced by Microsoft in Ref. [3], which is pre-trained on the ImageNet dataset.\n\nSo, the behaviour you see seems to make sense .", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/14"}, "14": {"author": "kevinkawchak", "date": "1691530488145", "content": "Hello, ResNet is used twice:\n\nFor pretrained model\nFor user dataset\nI am trying to have both trainable weights from 2) and Quantum circuit trainable weights be updated throughout the run in the same model. This may be possible by setting param.requires_grad = True. Best regards.\n\n\n\n\npennylane.ai\n\n\n\nQuantum transfer learning 1\nCombine PyTorch and PennyLane to train a hybrid quantum-classical image classifier using transfer learning.\n\n\n\n\n\n", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/15"}, "15": {"author": "isaacdevlugt", "date": "1691591832822", "content": "Hey @kevinkawchak,\nI ran the quantum transfer learning demo and changed this:\nmodel_hybrid = torchvision.models.resnet18(pretrained=True)\n\nfor param in model_hybrid.parameters():\n    param.requires_grad = True\n\nThe training went like this:\nTraining started:\nPhase: train Epoch: 1/3 Loss: 0.7073 Acc: 0.5000        \nPhase: validation   Epoch: 1/3 Loss: 0.6457 Acc: 0.6732        \nPhase: train Epoch: 2/3 Loss: 0.6230 Acc: 0.6885        \nPhase: validation   Epoch: 2/3 Loss: 0.5425 Acc: 0.7908        \nPhase: train Epoch: 3/3 Loss: 0.5700 Acc: 0.7869        \nPhase: validation   Epoch: 3/3 Loss: 0.4972 Acc: 0.8954        \nTraining completed in 2m 41s\nBest test loss: 0.4972 | Best test accuracy: 0.8954\n\nIs this the behaviour you\u2019re seeing as well? You mentioned this:\n\nWhen changing to param.requires_grad = True to update both ResNet and quantum circuit parameters, the training results are identical to the prior scenario, and does not complete validation.\n\nFor fun, if I change pretrained to be False, then I get this:\nTraining started:\nPhase: train Epoch: 1/3 Loss: 0.7102 Acc: 0.5000        \nPhase: validation   Epoch: 1/3 Loss: 0.6813 Acc: 0.5621        \nPhase: train Epoch: 2/3 Loss: 0.6970 Acc: 0.5164        \nPhase: validation   Epoch: 2/3 Loss: 0.6783 Acc: 0.6209        \nPhase: train Epoch: 3/3 Loss: 0.6945 Acc: 0.5287        \nPhase: validation   Epoch: 3/3 Loss: 0.6897 Acc: 0.4837        \nTraining completed in 2m 40s\nBest test loss: 0.6783 | Best test accuracy: 0.6209\n\nThis kind of goes against the spirit of transfer learning, though.\n\nTransfer learning is a well-established technique for training artificial neural networks (see e.g., Ref. [2]), which is based on the general intuition that if a pre-trained network is good at solving a given problem, then, with just a bit of additional training, it can be used to also solve a different but related problem.\n", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/16"}, "16": {"author": "kevinkawchak", "date": "1691691162986", "content": "Thank you for running the model. This worked for this dataset.1", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/17"}, "17": {"author": "isaacdevlugt", "date": "1691692086144", "content": "Awesome! Glad to hear 1 Reply", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/18"}, "18": {"author": "kieran_mcdowall", "date": "1695831921722", "content": "Hello,\nI\u2019m experiencing issues when changing the batch_size to some greater than one while using the pennylane pytorch interface.\nI keep getting the error:\nRuntimeError: shape \u2018[10, -1]\u2019 is invalid for input of size 1\nBut I have checked that the q_node is getting input of size [batch_size, num_qubits] ([10,2]) for me.\nIs this an issue with the current version of Pennylane?\nHere\u2019s some of my code. Any help would be greatly appreciated:\nTrain Dataset\n-------------\nSet train shuffle seed (for reproducibility)\nmanual_seed(42)\nbatch_size = 10\nn_samples = 500  # We will concentrate on the first 100 samples\nUse pre-defined torchvision function to load MNIST train data\nX_train = datasets.MNIST(\nroot=\u201c./data\u201d, train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])\n)\nFilter out labels (originally 0-9), leaving only labels 0 and 1\nidx = np.append(\nnp.where(X_train.targets == 0)[0][:n_samples], np.where(X_train.targets == 1)[0][:n_samples]\n)\nX_train.data = X_train.data[idx]\nX_train.targets = X_train.targets[idx]\nDefine torch dataloader with filtered data\ntrain_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)\nTest Dataset\n-------------\nSet test shuffle seed (for reproducibility)\nmanual_seed(5)\nn_samples = 250 # was 50\nUse pre-defined torchvision function to load MNIST test data\nX_test = datasets.MNIST(\nroot=\u201c./data\u201d, train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])\n)\nFilter out labels (originally 0-9), leaving only labels 0 and 1\nidx = np.append(\nnp.where(X_test.targets == 0)[0][:n_samples], np.where(X_test.targets == 1)[0][:n_samples]\n)\nX_test.data = X_test.data[idx]\nX_test.targets = X_test.targets[idx]\nDefine torch dataloader with filtered data\ntest_loader = DataLoader(X_test, batch_size=batch_size, shuffle=True)\nimport pennylane as qml\nfrom pennylane.templates import AngleEmbedding, BasicEntanglerLayers\nimport torch\nn_qubits = 2\ndev = qml.device(\u201cdefault.qubit\u201d, wires=n_qubits)\nSimple circuit based off Pennylane example\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n# Feature map (Manually defined ZZFeatureMap-like circuit)\nfor i in range(n_qubits):\n    qml.RX(weights[i],wires=i)\n    qml.RX(weights[i+2],wires=i)\nqml.CNOT(wires=[0, 1])\n\nreturn [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\nn_layers = 1  # Set the number of ansatz layers as needed\nn_params = 4\nweight_shapes = {\u201cweights\u201d: (n_params,)}  # Single parameter tuple\nprint(weight_shapes)\nqlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\nVisualize the circuit\nprint(qml.draw(qlayer, expansion_strategy=\u201cdevice\u201d)(torch.tensor([0.1, 0.2])))\nDefine torch NN module\nclass Net(Module):\ndef init(self):\nsuper().init()\nself.conv1 = Conv2d(1, 2, kernel_size=5)\nself.conv2 = Conv2d(2, 16, kernel_size=5)\nself.dropout = Dropout2d()\nself.fc1 = Linear(256, 64)\nself.fc2 = Linear(64, 2)  # 2-dimensional input to QNN\nself.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n# No need for self.fc3 in this context\ndef forward(self, x):\n    x = F.relu(self.conv1(x))\n    x = F.max_pool2d(x, 2)\n    x = F.relu(self.conv2(x))\n    x = F.max_pool2d(x, 2)\n    x = self.dropout(x)\n    x = x.view(x.shape[0], -1)\n    x = F.relu(self.fc1(x))\n    x = self.fc2(x)\n\n\n    # print(\"Shape of x:\", x.shape)  # Debugging line\n\n    quantum_output = self.qlayer_1(x)\n\n    # print(\"Shape of quantum_output:\", quantum_output.shape)  # Debugging line\n    \n    # Concatenate quantum_output with the original x\n    concatenated_output = torch.cat((x, quantum_output), dim=1)\n    \n    return concatenated_output\n\nmodel4 = Net()\nstart = timeit.default_timer()\nDefine model, optimizer, and loss function\noptimizer = optim.Adam(model4.parameters(), lr=0.001)\nloss_func = CrossEntropyLoss() # CHANGE ??? change back???\nStart training\nepochs = 10  # Set number of epochs\nloss_list =   # Store loss history\nmodel4.train()  # Set model to training mode\nfor epoch in range(epochs):\ntotal_loss = \nfor batch_idx, (data, target) in enumerate(train_loader):\noptimizer.zero_grad(set_to_none=True)  # Initialize gradient\noutput = model4(data)  # Forward pass, ???\nloss = loss_func(output, target)  # Calculate loss. MIGHT NEED TO SWITCH AS WAS BINARY\nloss.backward()  # Backward pass\noptimizer.step()  # Optimize weights\ntotal_loss.append(loss.item())  # Store loss\nloss_list.append(sum(total_loss) / len(total_loss))\nprint(\u201cTraining [{:.0f}%]\\tLoss: {:.4f}\u201d.format(100.0 * (epoch + 1) / epochs, loss_list[-1]))\nStop timer\nstop = timeit.default_timer()\nprint('Time: ', stop - start)", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/19"}, "19": {"author": "Ivana_at_Xanadu", "date": "1695915484227", "content": "Hey @kieran_mcdowall , welcome to the forum!\nDo you mind sharing the shortest version of your code that reproduces the problem? If we\u2019re able to run a simplified version of your code directly, we can help you much quicker. 1 Reply1", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/20"}, "20": {"author": "kieran_mcdowall", "date": "1695918927682", "content": "Hi Ivana, thanks for the welcome. Sorry about the messy code, I\u2019m not sure how best to format things for this forum. I\u2019ve tidied it up a bit and removed some things but there isn\u2019t a whole lot more that I can remove as the problem is quite specific:\n\u201c\u201d\"\nPennylane QCNN example on MNIST\nTrying to compare performance vs qiskit (qiskit implementation in seperate script)\n\u201c\u201d\"\nNecessary imports\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch import Tensor\nfrom torch.nn import Linear, CrossEntropyLoss, MSELoss\nfrom torch.optim import LBFGS\nimport torch\nfrom torchsummary import summary\nfrom torch import cat, no_grad, manual_seed\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nimport torch.optim as optim\nfrom torch.nn import (\nModule,\nConv2d,\nLinear,\nDropout2d,\nNLLLoss,\nMaxPool2d,\nFlatten,\nSequential,\nReLU,\n)\nimport torch.nn.functional as F\nimport pennylane as qml\nfrom pennylane.templates import AngleEmbedding, BasicEntanglerLayers\nTrain Dataset\n-------------\nmanual_seed(42)\nbatch_size = 10\nn_samples = 500\nX_train = datasets.MNIST(\nroot=\u201c./data\u201d, train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])\n)\nidx = np.append(\nnp.where(X_train.targets == 0)[0][:n_samples], np.where(X_train.targets == 1)[0][:n_samples]\n)\nX_train.data = X_train.data[idx]\nX_train.targets = X_train.targets[idx]\ntrain_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)\nTest Dataset\n-------------\nn_samples = 250\nX_test = datasets.MNIST(\nroot=\u201c./data\u201d, train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])\n)\nidx = np.append(\nnp.where(X_test.targets == 0)[0][:n_samples], np.where(X_test.targets == 1)[0][:n_samples]\n)\nX_test.data = X_test.data[idx]\nX_test.targets = X_test.targets[idx]\ntest_loader = DataLoader(X_test, batch_size=batch_size, shuffle=True)\nn_qubits = 2\ndev = qml.device(\u201cdefault.qubit\u201d, wires=n_qubits)\nSimple parameterized circuit\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n\u2018\u2019\u2018for i in range(n_qubits):\n\u2018\u2019\u2019\u2018\u2019\u2018qml.RX(weights[i],wires=i)\n\u2018\u2019\u2019\u2018\u2019'qml.RX(weights[i+2],wires=i)\n\u2018\u2019'qml.CNOT(wires=[0, 1])\n\u2018\u2019'return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\nn_layers = 1\nn_params = 4\nweight_shapes = {\u201cweights\u201d: (n_params,)}\nqlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\nDefine torch NN module\nclass Net(Module):\ndef init(self):\nsuper().init()\nself.conv1 = Conv2d(1, 2, kernel_size=5)\nself.conv2 = Conv2d(2, 16, kernel_size=5)\nself.dropout = Dropout2d()\nself.fc1 = Linear(256, 64)\nself.fc2 = Linear(64, 2)\nself.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\ndef forward(self, x):\nx = F.relu(self.conv1(x))\nx = F.max_pool2d(x, 2)\nx = F.relu(self.conv2(x))\nx = F.max_pool2d(x, 2)\nx = self.dropout(x)\nx = x.view(x.shape[0], -1)\nx = F.relu(self.fc1(x))\nx = self.fc2(x)\nquantum_output = self.qlayer_1(x)\nconcatenated_output = torch.cat((x, quantum_output), dim=1)\nreturn concatenated_output\nmodel4 = Net()\nDefine model, optimizer, and loss function\noptimizer = optim.Adam(model4.parameters(), lr=0.001)\nloss_func = CrossEntropyLoss()\nStart training\nepochs = 10\nloss_list = [  ]\nmodel4.train()\nfor epoch in range(epochs):\n\u2018\u2019\u2018total_loss = [  ]\n\u2018\u2019\u2018for batch_idx, (data, target) in enumerate(train_loader):\n\u2018\u2019\u2019\u2019\u2018\u2018optimizer.zero_grad(set_to_none=True)\n\u2018\u2019\u2019\u2019\u2018\u2018output = model4(data)\n\u2018\u2019\u2019\u2019\u2018\u2018loss = loss_func(output, target)\n\u2018\u2019\u2019\u2019\u2018\u2018loss.backward()\n\u2018\u2019\u2019\u2019\u2018\u2018optimizer.step()\n\u2018\u2019\u2019\u2019''total_loss.append(loss.item())\n\u2018\u2019'loss_list.append(sum(total_loss) / len(total_loss))\n\u2018\u2019'print(\u201cTraining [{:.0f}%]\\tLoss: {:.4f}\u201d.format(100.0 * (epoch + 1) / epochs, loss_list[-1]))", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/21"}, "21": {"author": "Ivana_at_Xanadu", "date": "1695980191059", "content": "Hey @kieran_mcdowall , thanks!\nThere\u2019s a lot going on here.  First, let me format this as code \u2014 you can press the  button right above the text editor when you\u2019re writing a post to get into the right environment.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torch import Tensor\nfrom torch.nn import Linear, CrossEntropyLoss, MSELoss\nfrom torch.optim import LBFGS\n\nimport torch\nfrom torchsummary import summary\nfrom torch import cat, no_grad, manual_seed\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nimport torch.optim as optim\nfrom torch.nn import (\nModule,\nConv2d,\nLinear,\nDropout2d,\nNLLLoss,\nMaxPool2d,\nFlatten,\nSequential,\nReLU,\n)\nimport torch.nn.functional as F\n\nimport pennylane as qml\nfrom pennylane.templates import AngleEmbedding, BasicEntanglerLayers\n\nmanual_seed(42)\n\nbatch_size = 10\nn_samples = 500\n\nX_train = datasets.MNIST(\nroot='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])\n)\n\nidx = np.append(\nnp.where(X_train.targets == 0)[0][:n_samples], np.where(X_train.targets == 1)[0][:n_samples]\n)\nX_train.data = X_train.data[idx]\nX_train.targets = X_train.targets[idx]\n\ntrain_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)\n\nn_samples = 250\n\nX_test = datasets.MNIST(\nroot='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])\n)\n\nidx = np.append(\nnp.where(X_test.targets == 0)[0][:n_samples], np.where(X_test.targets == 1)[0][:n_samples]\n)\nX_test.data = X_test.data[idx]\nX_test.targets = X_test.targets[idx]\n\ntest_loader = DataLoader(X_test, batch_size=batch_size, shuffle=True)\n\nn_qubits = 2\ndev = qml.device('default.qubit', wires=n_qubits)\n\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n    for i in range(n_qubits):\n        qml.RX(weights[i],wires=i)\n        qml.RX(weights[i+2],wires=i)\n        qml.CNOT(wires=[0, 1])\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\nn_layers = 1\nn_params = 4\nweight_shapes = {'weights': (n_params,)}\n\nqlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n\nclass Net(Module):\n    def init(self):\n        super().init()\n        self.conv1 = Conv2d(1, 2, kernel_size=5)\n        self.conv2 = Conv2d(2, 16, kernel_size=5)\n        self.dropout = Dropout2d()\n        self.fc1 = Linear(256, 64)\n        self.fc2 = Linear(64, 2)\n        self.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n\ndef forward(self, x):\n    x = F.relu(self.conv1(x))\n    x = F.max_pool2d(x, 2)\n    x = F.relu(self.conv2(x))\n    x = F.max_pool2d(x, 2)\n    x = self.dropout(x)\n    x = x.view(x.shape[0], -1)\n    x = F.relu(self.fc1(x))\n    x = self.fc2(x)\n    quantum_output = self.qlayer_1(x)\n    concatenated_output = torch.cat((x, quantum_output), dim=1)\n    return concatenated_output\n\nmodel4 = Net()\n\noptimizer = optim.Adam(model4.parameters(), lr=0.001)\nloss_func = CrossEntropyLoss()\n\nepochs = 10\nloss_list = [ ]\nmodel4.train()\n\nfor epoch in range(epochs):\n    total_loss = [ ]\n    for batch_idx, (data, target) in enumerate(train_loader):\n        optimizer.zero_grad(set_to_none=True)\n        output = model4(data)\n        loss = loss_func(output, target)\n        loss.backward()\n        optimizer.step()\n        total_loss.append(loss.item())\n    loss_list.append(sum(total_loss) / len(total_loss))\n    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(100.0 * (epoch + 1) / epochs, loss_list[-1]))\n\nI can\u2019t seem to run your code as it is because model4.parameters() doesn\u2019t seem to be defined right, so I can\u2019t help you right away.\nBut if I understand your question a bit better now, you say you\u2019re getting an error when you\u2019re running the training? At first glance, I can\u2019t parse the issue. Any chance you could check if there\u2019s an error with the code transcription, and also include the output you get from qml.about? Thanks! ", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/22"}, "22": {"author": "kieran_mcdowall", "date": "1695983648092", "content": "Hi Ivana, yeh thank you there was a problem in the formatting. Here is the correct format:\n\"\"\"\n\nPennylane QCNN example on MNIST\n\nTrying to compare performance vs qiskit (qiskit implementation in seperate script)\n\n\"\"\"\n\n# Necessary imports\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torch import Tensor\nfrom torch.nn import Linear, CrossEntropyLoss, MSELoss\nfrom torch.optim import LBFGS\n\nimport torch\nfrom torchsummary import summary\nfrom torch import cat, no_grad, manual_seed\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nimport torch.optim as optim\nfrom torch.nn import (\n    Module,\n    Conv2d,\n    Linear,\n    Dropout2d,\n    NLLLoss,\n    MaxPool2d,\n    Flatten,\n    Sequential,\n    ReLU,\n)\nimport torch.nn.functional as F\n\nimport pennylane as qml\nfrom pennylane.templates import AngleEmbedding, BasicEntanglerLayers\n\n# Train Dataset\n# -------------\nmanual_seed(42)\n\nbatch_size = 10\nn_samples = 500  \n\nX_train = datasets.MNIST(\n    root=\"./data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])\n)\n\n\nidx = np.append(\n    np.where(X_train.targets == 0)[0][:n_samples], np.where(X_train.targets == 1)[0][:n_samples]\n)\nX_train.data = X_train.data[idx]\nX_train.targets = X_train.targets[idx]\n\ntrain_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)\n\n\n# Test Dataset\n# -------------\nn_samples = 250 \n\nX_test = datasets.MNIST(\n    root=\"./data\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])\n)\n\nidx = np.append(\n    np.where(X_test.targets == 0)[0][:n_samples], np.where(X_test.targets == 1)[0][:n_samples]\n)\nX_test.data = X_test.data[idx]\nX_test.targets = X_test.targets[idx]\n\ntest_loader = DataLoader(X_test, batch_size=batch_size, shuffle=True)\n\n\nn_qubits = 2\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n# Simple parameterized circuit\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n    for i in range(n_qubits):\n        qml.RX(weights[i],wires=i)\n        qml.RX(weights[i+2],wires=i)\n    qml.CNOT(wires=[0, 1])\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\nn_layers = 1 \nn_params = 4\nweight_shapes = {\"weights\": (n_params,)} \n\nqlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n\n\n\n# Define torch NN module\nclass Net(Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = Conv2d(1, 2, kernel_size=5)\n        self.conv2 = Conv2d(2, 16, kernel_size=5)\n        self.dropout = Dropout2d()\n        self.fc1 = Linear(256, 64)\n        self.fc2 = Linear(64, 2)  \n        self.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = self.dropout(x)\n        x = x.view(x.shape[0], -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        quantum_output = self.qlayer_1(x)\n\n        concatenated_output = torch.cat((x, quantum_output), dim=1)\n        \n        return concatenated_output\n\nmodel4 = Net()\n\n\n# Define model, optimizer, and loss function\noptimizer = optim.Adam(model4.parameters(), lr=0.001)\nloss_func = CrossEntropyLoss()\n\n# Start training\nepochs = 10  \nloss_list = []  \nmodel4.train()  \n\nfor epoch in range(epochs):\n    total_loss = []\n    for batch_idx, (data, target) in enumerate(train_loader):\n        optimizer.zero_grad(set_to_none=True)  \n        output = model4(data) \n        loss = loss_func(output, target) \n        loss.backward()  \n        optimizer.step() \n        total_loss.append(loss.item())  \n    loss_list.append(sum(total_loss) / len(total_loss))\n    print(\"Training [{:.0f}%]\\tLoss: {:.4f}\".format(100.0 * (epoch + 1) / epochs, loss_list[-1]))\n\n\nAnd yes the error occurs when running training. This all works when the batch_size =1 but when increasing this I get this error:\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[15], line 14\n     12 for batch_idx, (data, target) in enumerate(train_loader):\n     13     optimizer.zero_grad(set_to_none=True)  \n---> 14     output = model4(data) \n     15     loss = loss_func(output, target) \n     16     loss.backward()  \n\nFile ~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n\nCell In[14], line 22, in Net.forward(self, x)\n     19 x = F.relu(self.fc1(x))\n     20 x = self.fc2(x)\n---> 22 quantum_output = self.qlayer_1(x)\n     24 concatenated_output = torch.cat((x, quantum_output), dim=1)\n     26 return concatenated_output\n\nFile ~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n\nFile ~/.local/lib/python3.8/site-packages/pennylane/qnn/torch.py:408, in TorchLayer.forward(self, inputs)\n    405     results = torch.stack(reconstructor)\n    406 else:\n    407     # calculate the forward pass as usual\n--> 408     results = self._evaluate_qnode(inputs)\n    410 # reshape to the correct number of batch dims\n    411 if has_batch_dim:\n\nFile ~/.local/lib/python3.8/site-packages/pennylane/qnn/torch.py:435, in TorchLayer._evaluate_qnode(self, x)\n    432     return res.type(x.dtype)\n    434 if len(x.shape) > 1:\n--> 435     res = [torch.reshape(r, (x.shape[0], -1)) for r in res]\n    437 return torch.hstack(res).type(x.dtype)\n\nFile ~/.local/lib/python3.8/site-packages/pennylane/qnn/torch.py:435, in <listcomp>(.0)\n    432     return res.type(x.dtype)\n    434 if len(x.shape) > 1:\n--> 435     res = [torch.reshape(r, (x.shape[0], -1)) for r in res]\n    437 return torch.hstack(res).type(x.dtype)\n\nRuntimeError: shape '[10, -1]' is invalid for input of size 1\n", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/23"}, "23": {"author": "Ivana_at_Xanadu", "date": "1696240485264", "content": "Hey @kieran_mcdowall, I think I\u2019ve figured out your problem. You\u2019re implementing parameter broadcasting (see here) and this is how you define the QNode:\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n    for i in range(n_qubits):\n        qml.RX(weights[i],wires=i)\n        qml.RX(weights[i],wires=i)\n    qml.CNOT(wires=[0, 1])\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\nBut you end up not actually using the inputs parameter in the definition.\nSo you end up telling the QNode to batch inputs/results, but you don\u2019t actually use the parameter that\u2019s supposed to do the batching for you.\nTo see what I mean, you could reproduce the same error if you use the example code from qml.qnn.TorchLayer \u2014 PennyLane 0.32.0 documentation and comment out the lines that use inputs:\nimport numpy as np\nimport pennylane as qml\nimport torch\nimport sklearn.datasets\n\nn_qubits = 2\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n#    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1))\n\nweight_shapes = {\"weights\": (3, n_qubits, 3)}\n\nqlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\nclayer1 = torch.nn.Linear(2, 2)\nclayer2 = torch.nn.Linear(2, 2)\nsoftmax = torch.nn.Softmax(dim=1)\nmodel = torch.nn.Sequential(clayer1, qlayer, clayer2, softmax)\n\nsamples = 100\nx, y = sklearn.datasets.make_moons(samples)\ny_hot = np.zeros((samples, 2))\ny_hot[np.arange(samples), y] = 1\n\nX = torch.tensor(x).float()\nY = torch.tensor(y_hot).float()\n\nopt = torch.optim.SGD(model.parameters(), lr=0.5)\nloss = torch.nn.L1Loss()\n\nepochs = 8\nbatch_size = 5\nbatches = samples // batch_size\n\ndata_loader = torch.utils.data.DataLoader(list(zip(X, Y)), batch_size=batch_size,\n                                          shuffle=True, drop_last=True)\n\nfor epoch in range(epochs):\n\n    running_loss = 0\n\n    for x, y in data_loader:\n        opt.zero_grad()\n\n        loss_evaluated = loss(model(x), y)\n        loss_evaluated.backward()\n\n        opt.step()\n\n        running_loss += loss_evaluated\n\n    avg_loss = running_loss / batches\n    print(\"Average loss over epoch {}: {:.4f}\".format(epoch + 1, avg_loss))\n\nI\u2019m not sure what you\u2019re trying to do with your code, but this doesn\u2019t seem to be the \u2018expected\u2019 way of using this functionality. I think it might be worth it if you tried to map our your algorithm sybmolically and see where the gaps might be. \nAnd we\u2019d love to hear from you about how you are using PennyLane. We have a very short survey for PennyLane v0.32, if you could take a minute to give back and help our team keep improving PennyLane. Thank you! 2 Replies", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/24"}, "24": {"author": "Solomon", "date": "1696246207905", "content": "I\u2019ve noticed a fair number of individuals are leveraging the Transfer Learning example as a basis for their projects. While it\u2019s great to see enthusiasm for combining quantum and classical techniques, there are some nuances that should not be overlooked.\nThe first misconception some might have is that the demo somehow proves that Quantum Neural Networks (QNNs) are superior to traditional deep learning models. This is not accurate. In reality, the heavy lifting in the demonstration is done by the classical neural network that has been pre-trained on the ImageNet dataset. This network acts as a feature extractor, a role it performs exceedingly well, given the breadth and depth of ImageNet. This method of feature extraction is a common and effective strategy in a variety of tasks, such as classification or unsupervised clustering, and much of the demo\u2019s effectiveness is attributable to this.\nThe quantum circuit that follows this feature extraction is rather simplistic. The point to emphasise here is that you could quite easily replace this quantum circuit with another simple classical model (Logistic Regression), or even a different type of quantum circuit, and the results would likely remain largely unchanged. This reveals that the quantum component is not the primary driver of the model\u2019s performance.\nAdditionally, if you were to swap out the pre-trained neural network for a more sophisticated model, say ResNext101, you would probably see an improvement in performance. This would be true irrespective of the quantum circuit you\u2019ve attached to it, further underscoring the point that the classical neural network is the main contributor to the efficacy of the entire setup.\nSo, if you\u2019re looking to demonstrate some form of \u201csupremacy\u201d of quantum computing in neural networks, you\u2019ll need to do more than just tack a simple quantum circuit onto a classical neural network. A more compelling approach would be to utilise a fully quantum neural network for encoding the image using a quantum Conv2D, not the classical Conv2D.\nThere are plenty of academic papers that have explored these more advanced configurations, and it would be beneficial for tutorials to make this clear. Especially for those who are new to the field, understanding these nuances can make all the difference in how they approach their own projects.1", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/25"}, "25": {"author": "isaacdevlugt", "date": "1696263849498", "content": "Thanks @Solomon! Interesting points and we appreciate your feedback . A lot of things in QML are nuanced, so it\u2019s good to be aware of this ", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/26"}, "26": {"author": "kieran_mcdowall", "date": "1696322595968", "content": "Hi Ivana, thanks for pointing that out! This fixed the issue after changing my circuit to:\n@qml.qnode(dev)\ndef qnode(inputs,weights): # \n    qml.RX(inputs[0],wires=0)\n    qml.RX(inputs[0],wires=1)\n    qml.RX(weights[0],wires=0)\n    qml.RX(weights[1],wires=1)\n    qml.CNOT(wires=[0, 1])\n    \n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\nAnd adjusting the layer before my quantum layer to have output equal to the batch size ( self.fc2 = Linear(64, batch_size) ):\n# Define torch NN module\nclass Net(Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = Conv2d(1, 2, kernel_size=5)\n        self.conv2 = Conv2d(2, 16, kernel_size=5)\n        self.dropout = Dropout2d()\n        self.fc1 = Linear(256, 64)\n        self.fc2 = Linear(64, batch_size) \n        self.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n        # No need for self.fc3 in this context\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = self.dropout(x)\n        x = x.view(x.shape[0], -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n\n        # print(\"Shape of x:\", x.shape)  # Debugging line\n\n        quantum_output = self.qlayer_1(x)\n\n        # print(\"Shape of quantum_output:\", quantum_output.shape)  # Debugging line\n        \n        # Concatenate quantum_output with the original x\n        concatenated_output = torch.cat((x, quantum_output), dim=1) \n        \n        return concatenated_output\n\n2", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/27"}, "27": {"author": "Ivana_at_Xanadu", "date": "1696398057195", "content": "That\u2019s great to hear, glad we could find a workaround. \nBest of luck with your project!1", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/28"}, "28": {"author": "kevinkawchak", "date": "1699754298044", "content": "Hello, What has been the best QML/QiML results using both classical trainable parameters and quantum trainable parameters?", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/29"}, "29": {"author": "isaacdevlugt", "date": "1699977549256", "content": "Hey @kevinkawchak!\nI think by \u201cclassical / quantum trainable parameters\u201d you mean parameters that are part of classical / quantum layers. There are no \u201cclassical / quantum trainable parameters\u201d per se, since all parameters in a quantum / classical / hybrid ML model are updated classically \u2014 you can think of quantum neural networks as black boxes that behave very similarly to classical networks in terms of what goes in, what comes out, and how their parameters are updated at a high level \nFor best results from QML models, that\u2019s a tough one to answer . There\u2019s a ton of literature and studies out there!2", "link": "https://discuss.pennylane.ai//t/batching-in-torchlayer/1373/30"}}