{"0": {"author": "Shawn", "date": "1598978526703", "content": "If I use the pennylane.qnn.keras layer and use the loss function in tensorflow for this layer:\nwires = 2\nn_quantum_layers = 1\n\ndev = qml.device(\"strawberryfields.fock\", wires=wires, cutoff_dim=15)\n\n@qml.qnode(dev)\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    qml.templates.DisplacementEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10, wires=range(wires))\n    return [qml.expval(qml.X(wires=i)) for i in range(wires)]\n\nweights = qml.init.cvqnn_layers_all(n_quantum_layers, wires, seed=None)\nweight_shapes = {\"w{}\".format(i): w.shape for i, w in enumerate(weights)}#{\"x\": wires}\nn_actions = env.action_space.n\ninput_dim = env.observation_space.n\nqlayer = qml.qnn.KerasLayer(layer, weight_shapes, output_dim=wires)\nclayer_in = tf.keras.layers.Dense(wires,input_dim=input_dim)\nclayer_out = tf.keras.layers.Dense(n_actions, activation = 'linear')\nmodel = tf.keras.models.Sequential([clayer_in,qlayer,clayer_out])\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss = 'mse'\n\nHow are the weights actually being trained using a classical tool like the loss function for classical input? Is there more to this training of the parameters? More embedding or something?\nFor fun here is a visual presentation of the entire layer (input is a 9-dim vector and output is a 4-dim vector):\n\nquanlayer1856\u00d7445 64.1 KB\n1", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/1"}, "1": {"author": "theodor", "date": "1598988471457", "content": "Hi @Shawn,\nAfter creating the qml.qnn.KerasLayer, which simply wraps a QNode into a layer that\u2019s compatible with TensorFlow and Keras, TensorFlow is able to classically optimize the network as if the layer was a classical one, similar to e.g. a tf.keras.layers.Dense layer. The gradient for the quantum part of the network is supplied by the QNode and is calculated by different means depending on the device used (in the strawberryfields.fock case it\u2019s calculated by finite differences), while all other gradients are calculated classically by TensorFlow.\nSo, in short, training the weights is handled by TensorFlow as if it was all classically, while the QNode handles all the \u201cquantum stuff\u201d and returns classical outputs and gradients to the optimizer.", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/2"}, "2": {"author": "Shawn", "date": "1598993880536", "content": "Thanks @theodor! I\u2019m a little confused \u2013 you say the parameters are calculated by Tensorflow but the gradient for the quantum part is supplied by the QNode\u2026isn\u2019t that contradictory? There should only be one way to update the parameters, right?\n\nreturns classical outputs and gradients to the optimizer.\n\nOptimizer as in the optimizer I provide for the tf layer?", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/3"}, "3": {"author": "theodor", "date": "1598998751137", "content": "Hi @Shawn. So, what TensorFlow does is that it calculates the output of the network by calculating the outputs of each layer and feeds it forward into the next layer. For the qlayer it gets these values from the QNode (which is responsible for calculating them in that specific context).\nSimilarly for the gradients, each layer has a gradient that either TensorFlow can calculate itself (e.g. by using automatic differentiation) or, in the case of the quantum circuit, only collects the gradient from the QNode, which again does all the heavy lifting.\nWhat happens inside the QNode (the \u201cquantum stuff\u201d) isn\u2019t known by TensorFlow, which only sees the output, i.e. the measured values which have been transformed into classical data (which is what happens when a measurement occurs). So, for TensorFlow to be able to optimize this network, it simply attempt to minimize the cost function using the classical data it gets from the QNode (supplied via the qml.qnn.KerasLayer), without caring about how it was calculated, along with any other TensorFlow specific parts of the network.\n\nOptimizer as in the optimizer I provide for the tf layer?\n\nYes, that would be the optimizer=tf.keras.optimizers.Adam() that you\u2019ve defined in the model.compile() call.\nI hope this makes sense. ", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/4"}, "4": {"author": "Shawn", "date": "1598999638696", "content": "Hi @theodor thank you for the insight. From the tf side that makes sense. But I am more curious about the actual quantum parameters and how they get trained. How do those get trained exactly?\nYou wrote early that tf trains those but now I\u2019m under the impression that that\u2019s not the case.2 Replies", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/5"}, "5": {"author": "theodor", "date": "1599000984298", "content": "Hi @Shawn. TensorFlow trains those parameters/weights in the sense that it varies them according to the gradient (i.e. the gradient with respect to those specific weights), that is supplied by the QNode, in an attempt to minimize the specified cost function.\nSince the input weights are classical and the output is classical TensorFlow can attempt to find the best weights for minimizing this cost no matter what actually happens internally in the QNode.", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/6"}, "6": {"author": "theodor", "date": "1599001181975", "content": "A simple way to understand this would be to imagine a random function f(x) and, by hand, trying to minimize it (perhaps just by trial-and-error; the more inputs/weights x you try, the closer you would get to a minimum). You could still optimize and \u201ctrain\u201d the weights without ever knowing anything about what happens inside the function, although if the function would give you some hints as to where the minimum could be, you could use that to your advantage and find the optimal weights (i.e. train the function) quicker. This is what the QNode does by handing over the gradients, allowing faster and better optimization methods (e.g. the Adam optimization algorithm you\u2019re using above).1 Reply", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/7"}, "7": {"author": "Shawn", "date": "1599002193393", "content": "Hi @theodor  yea I get that but I\u2019m more stuck on the fact that in the classical neural network, backpropagation is used to train the network. This is obviously not the case for the quantum neural network. I get what you are explaining but it\u2019s a bit unsatisfactory because tf is indirectly updating the weights, not directly. And there seems to be something peculiar happening inside the qnode that is actually doing the dirty work to update the weights. Tf is just taking the results and optimizing that. That\u2019s an added benefit but the Qnode is actually updating the weights. Or am I wrong here?1 Reply", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/8"}, "8": {"author": "Shawn", "date": "1599002758600", "content": "I\u2019m referencing what you meant regarding the strawberryfields.fock  statement. Is that what is updating the weights inside the qnode or how exactly do the weights inside the qnode get updated? It\u2019s still not clear to me. Apologies if this is cumbersome.", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/9"}, "9": {"author": "theodor", "date": "1599054931091", "content": "Hi @Shawn. Backpropagation can still be used even if there are quantum layers in the network. It simply works by calculating the gradient for one layer at a time, starting with the last one. When reaching the qlayer the algorithm simply gets handed the gradient rather than doing the calculations itself.\nTensorFlow is updating the weights by supplying the QNode function with the new weights (which are in turn simply applied to the circuit which you have defined and either simulated, e.g. by using heavy matrix/tensor calculations, or run on hardware, where the weights are translated into physical hardware parameters).\nExactly how the weights are applied to the quantum circuit depends on the device and the quantum operations. For example, the CVNeuralNetLayer would use the weights as phase, transmittivity and rotation angles for a set of interferometers along with displacement and kerr values that are needed (please read the docs 1 for more details).\nSo what\u2019s happening here is basically:\n\n\nThe weights are updated (classically) and supplied to the QNode function\n\n\nThe QNode uses these exact values as parameters for applying whatever operations that are used in the circuit (e.g. CVNeuralNetLayer)\n\n\nThe QNode returns an output (after applying the circuit operations) along with a calculated gradient (by e.g. using finite differences or the parameter shift rule 2)\n\n\nThere\u2019s nothing more peculiar happening inside the QNodes. ", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/10"}, "10": {"author": "Shawn", "date": "1599055703895", "content": "@theodor You\u2019re the man! Thank you. One part that is still confusing me \u2013 how does the qnode calculate the gradient? And how via finite differences? I haven\u2019t seen any docs or any info on this in the source code.", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/11"}, "11": {"author": "theodor", "date": "1599063954816", "content": "@Shawn I\u2019m glad I could be of help. As I mentioned above, there are several different ways to calculate the gradient of a QNode with respect to its parameters; the method depends on the device used. Some devices support exact gradient calculations using automatic differentiation (only simulators) or by using the parameter shift rule 1, while other devices use numerical methods like finite differences, which always works but might be unstable and inexact. Both parameter shift and finite differences work by running and measuring the QNode twice, using the results to calculate the gradient (see references for details).\nIf you want to know exactly how this is done by the QNode decorator, as well as which methods the devices use/support, you could have a look in the pennylane/qnodes/decorator.py file here 1, as well as in the specific devices device.capabilities methods.", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/12"}, "12": {"author": "Shawn", "date": "1599121530174", "content": "Thanks @theodor. That makes sense now. I just read about the sampling of a qnode to get the derivative. I checked how many times my qlayer is sampled and it shows 500 times per call of the qlayer. Is the purpose of the 500 times just to create the finite-difference gradient? Why is it called so many times?\nAnd is that what we expect to do on hardware or is this just a simulation procedure to calculate the gradient?\nEdit: Why does the sf.fock device only support finite-difference? From this post 2 my usecase could support automatic differentiation i.e. parameter shift-rule since the Kerr gate is at the end of the layer.", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/13"}, "13": {"author": "theodor", "date": "1599178246207", "content": "Hi @Shawn. That seems a bit strange. It might be because of the finite differences calculation, although 500 times seems a bit excessive. The hardware would also use finite differences unless it fully supports the parameter shift rule (which is seldom the case).\nThe strawberryfields.fock device could actually support using the parameter shift rule if all potential non-Gaussian gates in the circuit precedes the differentiated gate. In your case, the Kerr gate is at the end of the circuit, thus the parameter shift rule is not supported.", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/14"}, "14": {"author": "Shawn", "date": "1599195359634", "content": "@theodor  yea I find it also strange especially since my program would run much faster if it wasn\u2019t called so many times. I also asked this question in slack and am waiting for a response. Not even sure what the sampling is needed for the finite difference  case when just an infinitesimal small step of the parameters would work.\nDo you know if sampling would be needed with hardware or is this just a simulation need?", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/15"}, "15": {"author": "theodor", "date": "1599239775777", "content": "How did you get the number of samples/calls? Would you mind sharing where you got that number from? Regarding the hardware, as far as I know it should work in pretty much the same way, by sampling and then calculating the gradient via the finite differences. Since the hardware generally needs more samples to get a good estimate of the expectation value (since it\u2019s stochastic), there might be even more calls than for the simulator. Exactly how many I cannot say.", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/16"}, "16": {"author": "Shawn", "date": "1599256653434", "content": "Hi @theodor. So would then the quantum speed up of a photonic quantum computer be misconstrued here since the quantum gates first needs to create the gradient before sending information to the next layer? Even if the gates take 0,1ns, if they need to be ran many times, then the speed up would be much lower, especially if my simulation is running 500 times and you say for hardware could need more samples.\nWhat I did to find this out:\n@qml.qnode(dev)\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    global g\n    g+=1\n    print(g)\n    qml.templates.DisplacementEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10, wires=range(wires))\n    return [qml.expval(qml.X(wires=i)) for i in range(wires)]\n\nAnd there is a while loop where a step is taken in my use case until a certain step ends the while. Within every step a single call to the neural network is done. g=0 outside of the while loop.", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/17"}, "17": {"author": "theodor", "date": "1599598341651", "content": "Hi @Shawn. Even if the quantum hardware would need to be sampled many times there could still be a quantum speed-up, since it doesn\u2019t necessarily come from just performing operations faster; rather it performs the computations in a different way that, in a sense, parallelizes the calculations. Though, at the moment, we\u2019re not sure how great this speed-up could be, and it\u2019ll probably take some time before we get to the point when artificial neural networks, such as the one in your example, will be able to benefit from this.", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/18"}, "18": {"author": "Shawn", "date": "1599603626104", "content": "@theodor of course there should be a speed up\u2026I just wrote it would be much lower due to the sampling. Do you know what is up with the 500 runs of the layer?", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/19"}, "19": {"author": "theodor", "date": "1599662981139", "content": "Why there are 500 calls I cannot really say. It depends on the number of parameters you\u2019re using, as well as your batch size. It might also be something that Keras is doing behind the scenes, since it\u2019s handling the optimizations, although I\u2019m not sure exactly why that many calls are being made.", "link": "https://discuss.pennylane.ai//t/how-does-this-hybrid-layer-learn/547/20"}}