{"0": {"author": "jogi_suda", "date": "1643926838400", "content": "Hey guys!\nI\u2019ve been trying to run some experiments on QNNs, but I wanted to know wheter it\u2019s possible do have varying layer widths. For example, let\u2019s say I have a dataset of 10 features and 4 classes, and I wanted to build a quantum architecture of 5 layers, each of size (10, 5, 5, 5, 4). Would it be possible to do without relying on classical layers?\nI\u2019ve been working with the following code, taken from the hybrid transfer-learning paper (please, if there\u2019s a better way to do it, let me know):\n\nquantum_device = qml.device(\"default.qubit\", wires=n_qubits)\n\ndef H_layer(nqubits):\n    #Layer of single-qubit Hadamard gates.\n\n    for idx in range(nqubits):\n        qml.Hadamard(wires=idx)\n\n\ndef RY_layer(w):\n    \"\"\"Layer of parametrized qubit rotations around the y axis.\n    \"\"\"\n    for idx, element in enumerate(w):\n        qml.RY(element, wires=idx)\n\n\n\ndef entangling_layer(nqubits):\n    \"\"\"Layer of CNOTs followed by another shifted layer of CNOT.\n    \"\"\"\n    # In other words it should apply something like :\n    # CNOT  CNOT  CNOT  CNOT...  CNOT\n    #   CNOT  CNOT  CNOT...  CNOT\n    for i in range(0, nqubits - 1, 2):  # Loop over even indices: i=0,2,...N-2\n        qml.CNOT(wires=[i, i + 1])\n    for i in range(1, nqubits - 1, 2):  # Loop over odd indices:  i=1,3,...N-3\n        qml.CNOT(wires=[i, i + 1])\n\n    \n\n\n@qml.qnode(quantum_device, interface=\"torch\")\ndef quantum_net(q_input_features, q_weights_flat, q_depth, q_width):\n    \"\"\"\n    The variational quantum circuit.\n    \"\"\"\n\n    # Reshape weights\n    q_weights = q_weights_flat.reshape(q_depth, q_width)\n\n    # Start from state |+> , unbiased w.r.t. |0> and |1>\n    H_layer(q_width)\n\n    # Embed features in the quantum node\n    RY_layer(q_input_features)\n    # Sequence of trainable variational layers\n    for k in range(q_depth):\n        entangling_layer(q_width)\n        RY_layer(q_weights[k])\n\n    # Expectation values in the Z basis\n    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(q_width)]\n    return tuple(exp_vals)\n\n\nand for my class QNN, I have:\n\nclass DressedQuantumNet(nn.Module):\n    \"\"\"\n    Torch module implementing the *dressed* quantum net.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Definition of the *dressed* layout.\n        \"\"\"\n\n        super().__init__()\n        self.pre_net = nn.Linear(512, n_qubits)\n        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n        self.post_net = nn.Linear(n_qubits, 2)\n\n    def forward(self, input_features):\n        \"\"\"\n        Defining how tensors are supposed to move through the *dressed* quantum net.\n        \"\"\"\n\n        # obtain the input features for the quantum circuit\n        # by reducing the feature dimension from 512 to 4\n        pre_out = self.pre_net(input_features)\n        q_in = torch.tanh(pre_out) * np.pi / 2.0\n\n        # Apply the quantum circuit to each element of the batch and append to q_out\n        q_out = torch.Tensor(0, n_qubits)\n        q_out = q_out.to(device)\n        for elem in q_in:\n            q_out_elem = quantum_net(elem, self.q_params).float().unsqueeze(0)\n            q_out = torch.cat((q_out, q_out_elem))\n\n        # return the two-dimensional prediction from the postprocessing layer\n        return self.post_net(q_out)\n\n\nSo, from my understanding, self.q_params is the quantum net itself. How could I have different layer widths in this context? I also wanted to eliminate the post_net, that is, make the middle and final part of the network fully quantum. Is it possible, or do I necessarily need equal layer sizes?\nI saw this similar post where Tom Bronley talks how it can be achieved, but it\u2019s for Continuous-variable quantum neural networks: (Possible to create a QNN like classical one?)", "link": "https://discuss.pennylane.ai//t/qnn-with-varying-layer-width/1648/1"}, "1": {"author": "CatalinaAlbornoz", "date": "1643999566160", "content": "Hi @jogi_suda, welcome to the PennyLane forum!\nYou can have different layer sizes, however they tend to be the same because with more parametrized gates you can get more expressivity of your quantum circuit to represent your model. Maybe the conversation here 1 can be helpful.\nPlease let me know if this answers your question or if you have further questions!", "link": "https://discuss.pennylane.ai//t/qnn-with-varying-layer-width/1648/2"}, "2": {"author": "jogi_suda", "date": "1644016248937", "content": "Thanks, @CatalinaAlbornoz  ! Very helpful insight.\nSo, for example, say I have 5 features, and 3 classes. I want a variational circuit of depth = 4. The qnn layer sizes should be [5,5,5,3] (where this final layer of size = 3 is achieved by the post_net downprojection); if I wanted to achieve this without the classical post_net step (I want a fully quantum model), I just have to declare an architecture of sizes [5,5,5,5], and in the last layer, instead of measuring all 5 qubits, I can choose any subset of 3 qubits as my output, and then train on it?\nSo, for example, the code above was returning the expected values for all qubits (q_width = 5):\n\n# Expectation values in the Z basis\nexp_vals = [qml.expval(qml.PauliZ(position)) for position in range(q_width)]\n\n\nInstead of returning all measurements, I\u2019d just return the first three:\n\n# Expectation values in the Z basis\nexp_vals = [qml.expval(qml.PauliZ(position)) for position in range(3)]\n\n\nAm I in the right path?", "link": "https://discuss.pennylane.ai//t/qnn-with-varying-layer-width/1648/3"}, "3": {"author": "CatalinaAlbornoz", "date": "1644280736792", "content": "Hi @jogi_suda,\nI\u2019m not familiar with post_net downprojection but what you propose does sound reasonable.\nYou might also find some inspiration from this ensemble classification demo. The problem at hand is different but it does include the case of measuring only a subset of the qubits. I hope you can find it insightful.\nPlease let me know if this helps!", "link": "https://discuss.pennylane.ai//t/qnn-with-varying-layer-width/1648/4"}, "4": {"author": "jogi_suda", "date": "1644462385254", "content": "\nHi @jogi_suda,\nI\u2019m not familiar with post_net downprojection but what you propose does sound reasonable.\nYou might also find some inspiration from this ensemble classification demo. The problem at hand is different but it does include the case of measuring only a subset of the qubits. I hope you can find it insightful.\nPlease let me know if this helps!\n\nThx! Very insightful indeed. One last question that I had: if instead of having a sequence of N layers of 5 qubits, and measuring only 3 qubits at the end, would it be possible to add another \u201cblock\u201d with more qubits? For example: instead of [5,5,5,3], have [5,5,5,8].", "link": "https://discuss.pennylane.ai//t/qnn-with-varying-layer-width/1648/5"}, "5": {"author": "CatalinaAlbornoz", "date": "1644546084333", "content": "Hi @jogi_suda,\nI\u2019m not sure I understand the question.\nDo you want to have a quantum node, then classical post-processing and then a new quantum node with more qubits? If this is the case then yes, you can do this. You will simply need to define a new device with a larger number of qubits, and a new quantum circuit where you use those extra qubits.\nIf your question is if you can grow the number of qubits from one iteration to the next one, the answer is no. Your qnode is defined for a specific device, and that device has a fixed number of qubits.\nIf I got your question totally wrong please let me know.\nI hope this helps!", "link": "https://discuss.pennylane.ai//t/qnn-with-varying-layer-width/1648/6"}, "6": {"author": "jogi_suda", "date": "1644616849554", "content": "I think what I wanted to do was have a different number of qubits from one layer to another (without the need for a classical layer in-between). Since I need a fixed number of qubits, now I know what I should do; thank you for the help!", "link": "https://discuss.pennylane.ai//t/qnn-with-varying-layer-width/1648/7"}, "7": {"author": "CatalinaAlbornoz", "date": "1644624637405", "content": "I\u2019m glad I could help @jogi_suda!\nThe classical layer is not really necessary, but you will need different qnodes attached to different devices in order to change the number of qubits.\nEnjoy using PennyLane and see you at QHack!", "link": "https://discuss.pennylane.ai//t/qnn-with-varying-layer-width/1648/8"}, "8": {"author": "jogi_suda", "date": "1643926838400", "content": "Hey guys!\nI\u2019ve been trying to run some experiments on QNNs, but I wanted to know wheter it\u2019s possible do have varying layer widths. For example, let\u2019s say I have a dataset of 10 features and 4 classes, and I wanted to build a quantum architecture of 5 layers, each of size (10, 5, 5, 5, 4). Would it be possible to do without relying on classical layers?\nI\u2019ve been working with the following code, taken from the hybrid transfer-learning paper (please, if there\u2019s a better way to do it, let me know):\n\nquantum_device = qml.device(\"default.qubit\", wires=n_qubits)\n\ndef H_layer(nqubits):\n    #Layer of single-qubit Hadamard gates.\n\n    for idx in range(nqubits):\n        qml.Hadamard(wires=idx)\n\n\ndef RY_layer(w):\n    \"\"\"Layer of parametrized qubit rotations around the y axis.\n    \"\"\"\n    for idx, element in enumerate(w):\n        qml.RY(element, wires=idx)\n\n\n\ndef entangling_layer(nqubits):\n    \"\"\"Layer of CNOTs followed by another shifted layer of CNOT.\n    \"\"\"\n    # In other words it should apply something like :\n    # CNOT  CNOT  CNOT  CNOT...  CNOT\n    #   CNOT  CNOT  CNOT...  CNOT\n    for i in range(0, nqubits - 1, 2):  # Loop over even indices: i=0,2,...N-2\n        qml.CNOT(wires=[i, i + 1])\n    for i in range(1, nqubits - 1, 2):  # Loop over odd indices:  i=1,3,...N-3\n        qml.CNOT(wires=[i, i + 1])\n\n    \n\n\n@qml.qnode(quantum_device, interface=\"torch\")\ndef quantum_net(q_input_features, q_weights_flat, q_depth, q_width):\n    \"\"\"\n    The variational quantum circuit.\n    \"\"\"\n\n    # Reshape weights\n    q_weights = q_weights_flat.reshape(q_depth, q_width)\n\n    # Start from state |+> , unbiased w.r.t. |0> and |1>\n    H_layer(q_width)\n\n    # Embed features in the quantum node\n    RY_layer(q_input_features)\n    # Sequence of trainable variational layers\n    for k in range(q_depth):\n        entangling_layer(q_width)\n        RY_layer(q_weights[k])\n\n    # Expectation values in the Z basis\n    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(q_width)]\n    return tuple(exp_vals)\n\n\nand for my class QNN, I have:\n\nclass DressedQuantumNet(nn.Module):\n    \"\"\"\n    Torch module implementing the *dressed* quantum net.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Definition of the *dressed* layout.\n        \"\"\"\n\n        super().__init__()\n        self.pre_net = nn.Linear(512, n_qubits)\n        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n        self.post_net = nn.Linear(n_qubits, 2)\n\n    def forward(self, input_features):\n        \"\"\"\n        Defining how tensors are supposed to move through the *dressed* quantum net.\n        \"\"\"\n\n        # obtain the input features for the quantum circuit\n        # by reducing the feature dimension from 512 to 4\n        pre_out = self.pre_net(input_features)\n        q_in = torch.tanh(pre_out) * np.pi / 2.0\n\n        # Apply the quantum circuit to each element of the batch and append to q_out\n        q_out = torch.Tensor(0, n_qubits)\n        q_out = q_out.to(device)\n        for elem in q_in:\n            q_out_elem = quantum_net(elem, self.q_params).float().unsqueeze(0)\n            q_out = torch.cat((q_out, q_out_elem))\n\n        # return the two-dimensional prediction from the postprocessing layer\n        return self.post_net(q_out)\n\n\nSo, from my understanding, self.q_params is the quantum net itself. How could I have different layer widths in this context? I also wanted to eliminate the post_net, that is, make the middle and final part of the network fully quantum. Is it possible, or do I necessarily need equal layer sizes?\nI saw this similar post where Tom Bronley talks how it can be achieved, but it\u2019s for Continuous-variable quantum neural networks: (Possible to create a QNN like classical one?)", "link": "https://discuss.pennylane.ai//t/qnn-with-varying-layer-width/1648/9"}}