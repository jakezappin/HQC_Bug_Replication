{"0": {"author": "davidefrr", "date": "1571651072472", "content": "Hi, I was wondering if the state preparation (feature embedding) used in the example below, could be proven or conjectured to be hard to simulate classically, i.e. providinig some degree of quantum advantage.\n\n\ngithub.com\n\n\nXanaduAI/pennylane/blob/5bce2a09ae8a6b13d8d31e8e91579a59ea1dc4d1/examples/pennylane_run_variational_classifier.py#L269\n\n\n\n    beta0 = 2 * np.arcsin(np.sqrt(x[1]) ** 2 / np.sqrt(x[0] ** 2 + x[1] ** 2 + 1e-12))\n    beta1 = 2 * np.arcsin(np.sqrt(x[3]) ** 2 / np.sqrt(x[2] ** 2 + x[3] ** 2 + 1e-12))\n    beta2 = 2 * np.arcsin(\n        np.sqrt(x[2] ** 2 + x[3] ** 2) / np.sqrt(x[0] ** 2 + x[1] ** 2 + x[2] ** 2 + x[3] ** 2)\n    )\n\n\n    return np.array([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2])\n\n\n\n\ndef statepreparation(a):\n    qml.RY(a[0], wires=0)\n\n\n    qml.CNOT(wires=[0, 1])\n    qml.RY(a[1], wires=1)\n    qml.CNOT(wires=[0, 1])\n    qml.RY(a[2], wires=1)\n\n\n    qml.PauliX(wires=0)\n    qml.CNOT(wires=[0, 1])\n    qml.RY(a[3], wires=1)\n\n\n\n\n\n\nI also noticed that the Iris data set used (iris_classes1and2_scaled.txt 6) has already undergone some preprocessing, I would like to know what kind of preprocessing was applied to the data set.", "link": "https://discuss.pennylane.ai//t/inquiries-on-state-preparation-in-variaitonal-classifier-example/248/1"}, "1": {"author": "Maria_Schuld", "date": "1571950882525", "content": "Hey davidefrr,\nThis is amplitude encoding, which literally means you prepare an amplitude vector that resembles your data input. This is of course not classically hard. In fact, it is a rather complex procedure for a quantum circuit as you can see, while classically, you would not have to do anything.\nThe Iris dataset is scaled (by putting zero mean and unit deviation), and classes 1 and 2 were selected.\nHope this helps.", "link": "https://discuss.pennylane.ai//t/inquiries-on-state-preparation-in-variaitonal-classifier-example/248/2"}, "2": {"author": "RicardoGaGu", "date": "1572455551320", "content": "Hi @davidefrr and @Maria_Schuld,\nI\u2019ve been reading the paper https://arxiv.org/pdf/1804.11326.pdf 7 \" \u201cSupervised learning with quantum enhanced feature spaces\u201d where they implement a quantum feature map based on quantum circuits that are conjectured to be hard to simulate classically. Specifically, the second order expansion feature map. Does Pennylane contemplate to implement this feature map in its roadmap?\nI\u2019ve been playing with the available feature-embedding circuits such as basis , amplitude encoding circuits that are available in the library, but I haven\u2019't found this specific class of feature maps\nThanks!", "link": "https://discuss.pennylane.ai//t/inquiries-on-state-preparation-in-variaitonal-classifier-example/248/3"}, "3": {"author": "Maria_Schuld", "date": "1572534008797", "content": "Yes, we want to significantly extend the library of embeddings, and this would be one of the first ones to add. But in the meantime, feel free to code this up yourself and make a pull request  .", "link": "https://discuss.pennylane.ai//t/inquiries-on-state-preparation-in-variaitonal-classifier-example/248/4"}, "4": {"author": "Bayaniblues", "date": "1594922919413", "content": "Is this the right method for Amplitude embedding? 5\nI only found This documentation 4 that explains it.\nSince amplitude embedding the first step for quantum data wrangling, are there any tutorials on how to convert my dataset into an amplitude?", "link": "https://discuss.pennylane.ai//t/inquiries-on-state-preparation-in-variaitonal-classifier-example/248/5"}, "5": {"author": "nathan", "date": "1594931657352", "content": "Hi @Bayaniblues,\nThanks for your question. If you plan to use AmplitudeEmbedding as a way to input data to your quantum circuit, that is the correct function to use, yes \nIf your dataset is already in a vector/array form (e.g., a numpy array), then that should be sufficient for the input to AmplitudeEmbedding function. If it\u2019s not in numerical form, you\u2019ll have to do that \u201cdata wrangling\u201d beforehand, just like you would with any classical ML dataset.\nNote that this embedding assumes a vector of dimension 2^N for N qubits; if your data dimension is not a multiple of two, you can use the pad option to \u201cfill in\u201d any missing entries with a numeric value of your choice (likely 0). Be mindful also of the normalize option, which should be used if you want your embedded data to be a properly normalized quantum state.\nAs hinted in the documentation page you linked, there are also other possible choices for embedding classical data into a quantum computer. Depending on your needs, you might want to experiment with different options.\nA final note: as indicated in the docs, AmplitudeEmbedding is currently not differentiable. This is no issue if your input is truly \u201cdata\u201d, but if the input features are coming directly via some upstream model (e.g., in pytorch or tensorflow) that you want to train, this constraint would prevent those upstream layers from being trainable).", "link": "https://discuss.pennylane.ai//t/inquiries-on-state-preparation-in-variaitonal-classifier-example/248/6"}, "6": {"author": "davidefrr", "date": "1571651072472", "content": "Hi, I was wondering if the state preparation (feature embedding) used in the example below, could be proven or conjectured to be hard to simulate classically, i.e. providinig some degree of quantum advantage.\n\n\ngithub.com\n\n\nXanaduAI/pennylane/blob/5bce2a09ae8a6b13d8d31e8e91579a59ea1dc4d1/examples/pennylane_run_variational_classifier.py#L269\n\n\n\n    beta0 = 2 * np.arcsin(np.sqrt(x[1]) ** 2 / np.sqrt(x[0] ** 2 + x[1] ** 2 + 1e-12))\n    beta1 = 2 * np.arcsin(np.sqrt(x[3]) ** 2 / np.sqrt(x[2] ** 2 + x[3] ** 2 + 1e-12))\n    beta2 = 2 * np.arcsin(\n        np.sqrt(x[2] ** 2 + x[3] ** 2) / np.sqrt(x[0] ** 2 + x[1] ** 2 + x[2] ** 2 + x[3] ** 2)\n    )\n\n\n    return np.array([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2])\n\n\n\n\ndef statepreparation(a):\n    qml.RY(a[0], wires=0)\n\n\n    qml.CNOT(wires=[0, 1])\n    qml.RY(a[1], wires=1)\n    qml.CNOT(wires=[0, 1])\n    qml.RY(a[2], wires=1)\n\n\n    qml.PauliX(wires=0)\n    qml.CNOT(wires=[0, 1])\n    qml.RY(a[3], wires=1)\n\n\n\n\n\n\nI also noticed that the Iris data set used (iris_classes1and2_scaled.txt 6) has already undergone some preprocessing, I would like to know what kind of preprocessing was applied to the data set.", "link": "https://discuss.pennylane.ai//t/inquiries-on-state-preparation-in-variaitonal-classifier-example/248/7"}}