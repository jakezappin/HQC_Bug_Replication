{"0": {"author": "Andre_Sequeira", "date": "1603236715557", "content": "Hi, I am trying to train a simple hybrid network with a quantum layer composed of 3 strongly entangling layers on 4 qubits connected to a classical layer with 2 output neurons. I am using pytorch. The problem is that it is really slow to obtain gradients of this network and I am using the simulator, not quantum hardware, so i suppose that backpropagation is being used.\nIf I just use the quantum layer and the pennylane optimizers, the training is fast and i notice a big difference in using default.qubit.autograd rather than default.qubit. In the hybrid network however, i didn\u2019t notice any difference. When i use the qulacs simulator, instead of faster results, it gets even worse.\nAny suggestions would be appreciated.\nThanks for your help!\nclass Hybrid_Network(nn.Module):\n    def __init__(self, nqubits, nlayers ,  output_size):\n        super(Hybrid_Network, self).__init__()\n\n        device = qml.device('default.qubit', wires=nqubits)\n\n        @qml.qnode(device)\n        def qnode(inputs,weights):\n\n            qml.templates.AngleEmbedding(inputs, wires=range(nqubits))\n           \n            #strongly entangling layer - weights = {(n_layers , n_qubits, n_parameters)}\n            qml.templates.StronglyEntanglingLayers(weights,wires=range(nqubits))\n\n            #return expectation value\n            return [qml.expval(qml.PauliZ(i)) for i in range(nqubits)]\n\n        # weights of the quantum layer are randomly initialized by PyTorch using the uniform distribution over [0,2pi]\n        #{(n_layers , n_qubits, n_parameters)}\n        weight_shapes = {\"weights\":(nlayers,N,3)}\n        self.qlayer = qml.qnn.TorchLayer(qnode,weight_shapes)\n\n        self.clayer = nn.Linear(4,output_size)\n        self.hybrid_network = nn.Sequential(\n            self.qlayer,\n            self.clayer\n        )\n\n    def forward(self, input):\n        return self.hybrid_network(input)", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/1"}, "1": {"author": "Tom_Bromley", "date": "1603294346937", "content": "Hey @Andre_Sequeira, welcome to the forum!\nThis sounds like a setting where backpropagation is outperforming the parameter shift rule, which we expect as the number of trainable parameters increases (see this 12 tutorial).\nThe code you shared is evaluating the gradient using the parameter shift rule, so this might explain why you are seeing the slow down. We do not currently have a default.qubit.torch device to support backpropagation in Torch. This is something we\u2019d like to add soon, as complex support 4 makes its way into torch. Unfortunately, we also do not yet support backpropagation as a differentiation method in the qnn module, but this will likely be fixed soon.\nFor now, you may have to stick with using TensorFlow and the default.qubit.tf device for backpropagation support, as well as using core TF functionality to make a hybrid rather than Keras. I had a go at prototyping what this might look like:\nimport pennylane as qml\nimport tensorflow as tf\nfrom pennylane import numpy as np\n\nnqubits = 4\nn_layers = 3\noutput_size = 2\nbatches = 10\n\n# Define backprop-compatible device\ndevice = qml.device('default.qubit.tf', wires=nqubits)\n\n# Define QNode\n@qml.qnode(device, interface=\"tf\")\ndef qnode(inputs, weights):\n    qml.templates.AngleEmbedding(inputs, wires=range(nqubits))\n    qml.templates.StronglyEntanglingLayers(weights, wires=range(nqubits))\n    return [qml.expval(qml.PauliZ(i)) for i in range(nqubits)]\n\n# Define inputs and qnode trainable weights\ninputs = tf.ones(nqubits)\nweights = tf.Variable(qml.init.strong_ent_layers_uniform(n_layers, nqubits))\nclayer_matrix = tf.Variable(np.random.random((output_size, nqubits)))\nclayer_bias = tf.Variable(np.random.random((output_size, 1)))\n\n# Define hybrid function\ndef hybrid(inputs):\n    x = qnode(inputs, weights)\n    x = tf.expand_dims(x, axis=1)\n    x = clayer_matrix @ x\n    x = x + clayer_bias\n    # Could optionally add a nonlinearity here\n    return tf.squeeze(x)\n\n# Define optimizer\nopt = tf.keras.optimizers.SGD(learning_rate=0.1)\n\n# Begin optimization\nsteps = 5\n\nfor i in range(steps):\n    opt.minimize(lambda: hybrid(inputs), [weights, clayer_matrix, clayer_bias])\n", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/2"}, "2": {"author": "Andre_Sequeira", "date": "1603301882167", "content": "Hi @Tom_Bromley, first of all, thank you so much for your answer. Secondly, congratulations on the forum, I\u2019ve been following other users questions for a few weeks and you guys are awesome.\nIf you don\u2019t mind, I have a couple more questions. I am trying to minimize the cross-entropy loss function and I\u2019m not used to TensorFlow, could you give me a simple example of how to use softmax and the optimizer?\nAnother question, can I run the PyTorch version in a Qiskit quantum machine? or there\u2019s not compatibility?", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/3"}, "3": {"author": "Tom_Bromley", "date": "1603314859204", "content": "No problem!\n\ncan I run the PyTorch version in a Qiskit quantum machine? or there\u2019s not compatibility?\n\nYes the choice of interface (Autograd/NumPy, Torch, or TensorFlow) is independent of the choice of device, so this should not be a problem. Let us know if you need a hand.\n\nI am trying to minimize the cross-entropy loss function and I\u2019m not used to TensorFlow, could you give me a simple example of how to use softmax and the optimizer?\n\nFollowing from the code I shared above, you could have something like\ndef cost(inputs, outputs_expected):\n    x = hybrid(inputs)\n    return tf.nn.softmax_cross_entropy_with_logits(logits=x, labels=outputs_expected)\n\n# Define optimizer\nopt = tf.keras.optimizers.SGD(learning_rate=0.1)\n\n# Begin optimization\nsteps = 5\n\nfor i in range(steps):\n    opt.minimize(lambda: cost(inputs, outputs), [weights, clayer_matrix, clayer_bias])\n\nIt could also be done using Keras if we use parameter-shift differentiation rather than backprop:\nimport pennylane as qml\nimport tensorflow as tf\nfrom pennylane import numpy as np\n\nnqubits = 4\nn_layers = 3\noutput_size = 2\nbatches = 10\n\ndevice = qml.device('default.qubit', wires=nqubits)\n\n# Define QNode\n@qml.qnode(device)\ndef qnode(inputs, weights):\n    qml.templates.AngleEmbedding(inputs, wires=range(nqubits))\n    qml.templates.StronglyEntanglingLayers(weights, wires=range(nqubits))\n    return [qml.expval(qml.PauliZ(i)) for i in range(nqubits)]\n\n# Define inputs and qnode trainable weights\ninputs = tf.constant(np.random.random((batches, nqubits)), dtype=tf.float32)\n\n# output_size is the number of classes\noutputs = tf.one_hot(np.random.randint(output_size, size=batches), depth=output_size)\n\n# define weight_shapes\nweight_shapes = {\"weights\": (n_layers, nqubits, 3)}\n\nqlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=nqubits)\nclayer = tf.keras.layers.Dense(output_size)\n\nmodel = tf.keras.Sequential([qlayer, clayer])\nopt = tf.keras.optimizers.SGD(learning_rate=0.05)\nmodel.compile(opt, loss=tf.keras.losses.CategoricalCrossentropy())\n\nmodel.fit(inputs, outputs, epochs=8, batch_size=5)\n\nNote that these examples probably still need a bit of work, prototyping and testing before I expect a model to train successfully!1", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/4"}, "4": {"author": "Andre_Sequeira", "date": "1603469297189", "content": "Hi @Tom_Bromley, thank you very much, you have been a huge help.1", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/5"}, "5": {"author": "NikSchet", "date": "1603545849215", "content": "Hello, are you using a specific template about this?\nI am trying to do the same thing (differences are that i want to try with 2 qubits first) . The goal is to benchmark the variational classifier and the one qubit re-uploading vs this hybrid QC network using Iris dataset.", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/6"}, "6": {"author": "Andre_Sequeira", "date": "1603645722503", "content": "Hi @NikSchet, i do not follow if you want to do it in tensorflow also, but if you want to use pytorch maybe you could take a look at the \\href{https://pennylane.ai/qml/demos/tutorial_quantum_transfer_learning.html}{Quantum\\ Transfer\\ Learning} demo.2 Replies", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/7"}, "7": {"author": "NikSchet", "date": "1603648020204", "content": "Thank you very much, I am already trying to implement this demo but for a different classical neural network for my iris dataset.", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/8"}, "8": {"author": "NikSchet", "date": "1603726572845", "content": "I am now trying the codes above. My problem is in the data transformation part to create the input. My dataset is typical Iris dataset. I guess i need to transform my dataset in a tensorflow accepted form. Are there any tutorials on that?  Thanks in advance (sorry if it is a basic question)", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/9"}, "9": {"author": "Tom_Bromley", "date": "1603727909993", "content": "Hey @NikSchet and thanks @Andre_Sequeira,\nYou could load Iris data like this:\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nds = tfds.load('iris', split='train')\nds = ds.shuffle(1024).batch(32)\n\nfor datapoint in ds.take(1):\n    features = datapoint[\"features\"]\n    labels = datapoint[\"label\"]\n    \n    labels_one_hot = tf.one_hot(labels, 3)\n\nThis is done using the TensorFlow Datasets package.1", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/10"}, "10": {"author": "Andre_Sequeira", "date": "1604144571554", "content": "Hi @Tom_Bromley, the goal of the hybrid network is to train a reinforcement learning agent. The network produced interesting results, but I was wondering, the classical layer is used just for the output of a probability distribution over the possible actions to take, which in this case is binary. Now, is it possible to remove the classical layer and obtaining the probability distribution directly from the qnn? The quantum circuit has 4 qubits, so I would need to narrow the output to a single qubit and thereafter normalize the output to be between 0 and 1.\nI also have perhaps a more theoretical question. By training these quantum circuits, we are basically training periodic functions, right? It heavily depends on the appropriate choice of the learning rate. Is there any way to figure out the \u201coptimal\u201d learning rate, or we\u2019re left with an empirical analysis?\nI apologize for the long text. Thank you very much.", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/11"}, "11": {"author": "antalszava", "date": "1604360870694", "content": "Hi @Andre_Sequeira,\n\nNow, is it possible to remove the classical layer and obtaining the probability distribution directly from the qnn?\n\nOne thing that could be done here, is to create a quantum circuit that samples basis states with the same probability distribution that was previously produced by the classical layer. In such a case, each basis state could correspond to the action that needs to be taken.\nFor getting the probability distribution, qml.probs could be used for example the previously mentioned QNode as follows:\n@qml.qnode(device, interface=\"tf\")\ndef qnode(inputs, weights):\n    qml.templates.AngleEmbedding(inputs, wires=range(nqubits))\n    qml.templates.StronglyEntanglingLayers(weights, wires=range(nqubits))\n    return qml.probs(wires=range(nqubits))\n\n\nBy training these quantum circuits, we are basically training periodic functions, right? It heavily depends on the appropriate choice of the learning rate. Is there any way to figure out the \u201coptimal\u201d learning rate, or we\u2019re left with an empirical analysis?\n\nIndeed, choosing a favourable learning rate for gradient descent as part of hyperparameter initialization is something that is an open question and is specific to the problem at hand. The hyperparameters chosen are closely related to the geometry used in the parameter space.\nWorth checking out the Quantum natural gradient tutorial 1 which describes an alternative optimization method that uses a different geometry than Euclidean geometry and can perform better than gradient descent.\nHope this helps a bit, let us know if you have further questions! 1 Reply1", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/12"}, "12": {"author": "Andre_Sequeira", "date": "1604364868680", "content": "Hi @antalszava, thank you for your answer.\n\n\n\n antalszava:\n\nOne thing that could be done here, is to create a quantum circuit that samples basis states with the same probability distribution that was previously produced by the classical layer. In such a case, each basis state could correspond to the action that needs to be taken.\n\n\nI am sorry , I don\u2019t understand. In this case, the quantum circuit has 4 qubits, therefore it has 16 possible basis states which would represent 16 different actions, but in my case the action set has only two actions.\n\n\n\n antalszava:\n\nWorth checking out the Quantum natural gradient tutorial which describes an alternative optimization method that uses a different geometry than Euclidean geometry and can perform better than gradient descent\n\n\nYes, thank you very much, I came across this optimization method while researching. Very interesting ", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/13"}, "13": {"author": "antalszava", "date": "1604369894837", "content": "Hi @Andre_Sequeira,\n\nIn this case, the quantum circuit has 4 qubits, therefore it has 16 possible basis states which would represent 16 different actions, but in my case the action set has only two actions.\n\nThat\u2019s correct! Not entirely sure about the specific use case, but one approach here could be to consider the marginal probability distribution of computational basis states on a single qubit (as the subsystem of the 4 qubit quantum circuit).\nLet\u2019s consider a circuit that prepares the two-qubit computational basis states (|00\\rangle, |01\\rangle, |10\\rangle, |11\\rangle) with equal probabilities:\nimport pennylane as qml\n\ndev = qml.device('default.qubit', wires=2)\n\n@qml.qnode(dev)\ndef circuit():\n    qml.Hadamard(0)\n    qml.CNOT(wires=[0,1])\n    qml.Hadamard(1)\n    return qml.probs(wires=[0,1])\n\nprint(circuit())\n\n[0.25 0.25 0.25 0.25]\n\nThe marginal probabilities of computational basis states on the first qubit can be obtained:\nimport pennylane as qml\n\ndev = qml.device('default.qubit', wires=2)\n\n@qml.qnode(dev)\ndef circuit():\n    qml.Hadamard(0)\n    qml.CNOT(wires=[0,1])\n    qml.Hadamard(1)\n    return qml.probs(wires=[0])\n\nprint(circuit())\n\n[0.5 0.5]\n\nThe first entry here corresponds to the probability of the first qubit being |0\\rangle, while the second entry corresponds to the probability of the first qubit being |1\\rangle.\nHope this helps with a bit of direction. ", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/14"}, "14": {"author": "Andre_Sequeira", "date": "1604419488334", "content": "Hello @antalszava ,\n\n\n\n antalszava:\n\nimport pennylane as qml dev = qml.device(\u2018default.qubit\u2019, wires=2) @qml.qnode(dev) def circuit(): qml.Hadamard(0) qml.CNOT(wires=[0,1]) qml.Hadamard(1) return qml.probs(wires=[0,1]) print(circuit()) [0.25 0.25 0.25 0.25]\n\n\nthis is interesting, thank you very much. Assuming that we prepare the uniform superposition state over the 2-qubit system, how many times do we need to prepare the  quantum circuit in order to have a good approximation of the probability distribution? In a sense what is qml.probs() doing under the hood?", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/15"}, "15": {"author": "antalszava", "date": "1604441601174", "content": "Hi @Andre_Sequeira,\nIn PennyLane state vector simulator devices (such as default.qubit) allow computations in two ways:\n\nby sampling the circuit a certain number of times and post-processing the samples (analytic=False case)\nby returning the analytic value of the output that is the probability distribution of basis states in this case (analytic=True case)\n\nIn the first case, you can further specify the shots attribute to define the number of circuit evaluations.\nimport pennylane as qml\n\ndev = qml.device('default.qubit', wires=2, analytic=False, shots=100)\n\n@qml.qnode(dev)\ndef circuit():\n    qml.Hadamard(0)\n    qml.CNOT(wires=[0,1])\n    qml.Hadamard(1)\n    return qml.probs(wires=[0])\n\nprint(circuit())\n\n[0.53 0.47]\n\nAs the number of shots is increased for the device, the probability distribution is nearing its analytic value. However, for only a few shots, the results may deviate greatly from the analytic values.\nBy default, default.qubit performs analytic computations (as per the example from the previous answer). Once analytic is set to False, the default value of 1000 is used for the shots attribute .", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/16"}, "16": {"author": "Andre_Sequeira", "date": "1604444670399", "content": "@antalszava is there a way to know the optimal shots for a quantum circuit? Because depending on the circuit, and if I run it on a real quantum device or simulator, 1000 might be a small/large number and it is important for the performance.\nThanks.", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/17"}, "17": {"author": "antalszava", "date": "1604533756625", "content": "Hi @Andre_Sequeira,\nThis I would say greatly comes down to trial and error and running separate simulations.\nAs you\u2019ve mentioned, this is highly dependent on the device. For hardware devices, inaccuracies can stem from the fact that applying gates and measurements in a quantum circuit introduces errors (how good a gate is often quantified by the fidelity of a gate). Furthermore, the quantum state itself can also change over time (decoherence). Each architecture performs operations in a different way (i.e., gate fidelities differ). Noise inherently influences measurement outcomes and hence the statistics that can be drawn from the observed outcomes (samples). This noisiness comes on top of the stochastic nature of running a quantum simulation.\nOverall one approach could be to first run quantum circuits on simulators and try to mimic real hardware. In PennyLane, noise can be simulated using the new default.mixed device (see Release notes 1 for an example) by applying quantum channels that can represent the noise 1.", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/18"}, "18": {"author": "Andre_Sequeira", "date": "1604534217552", "content": "Hi @antalszava, thank you very much for your help.", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/19"}, "19": {"author": "Andre_Sequeira", "date": "1603645722503", "content": "Hi @NikSchet, i do not follow if you want to do it in tensorflow also, but if you want to use pytorch maybe you could take a look at the \\href{https://pennylane.ai/qml/demos/tutorial_quantum_transfer_learning.html}{Quantum\\ Transfer\\ Learning}Quantum\u00a0Transfer\u00a0Learning demo.2 Replies", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/20"}, "20": {"author": "antalszava", "date": "1604369894837", "content": "Hi @Andre_Sequeira,\n\nIn this case, the quantum circuit has 4 qubits, therefore it has 16 possible basis states which would represent 16 different actions, but in my case the action set has only two actions.\n\nThat\u2019s correct! Not entirely sure about the specific use case, but one approach here could be to consider the marginal probability distribution of computational basis states on a single qubit (as the subsystem of the 4 qubit quantum circuit).\nLet\u2019s consider a circuit that prepares the two-qubit computational basis states (|00\\rangle|00\u27e9, |01\\rangle|01\u27e9, |10\\rangle|10\u27e9, |11\\rangle|11\u27e9) with equal probabilities:\nimport pennylane as qml\n\ndev = qml.device('default.qubit', wires=2)\n\n@qml.qnode(dev)\ndef circuit():\n    qml.Hadamard(0)\n    qml.CNOT(wires=[0,1])\n    qml.Hadamard(1)\n    return qml.probs(wires=[0,1])\n\nprint(circuit())\n\n[0.25 0.25 0.25 0.25]\n\nThe marginal probabilities of computational basis states on the first qubit can be obtained:\nimport pennylane as qml\n\ndev = qml.device('default.qubit', wires=2)\n\n@qml.qnode(dev)\ndef circuit():\n    qml.Hadamard(0)\n    qml.CNOT(wires=[0,1])\n    qml.Hadamard(1)\n    return qml.probs(wires=[0])\n\nprint(circuit())\n\n[0.5 0.5]\n\nThe first entry here corresponds to the probability of the first qubit being |0\\rangle|0\u27e9, while the second entry corresponds to the probability of the first qubit being |1\\rangle|1\u27e9.\nHope this helps with a bit of direction. ", "link": "https://discuss.pennylane.ai//t/hybrid-quantum-classical-network-with-pytorch/631/21"}}