{"0": {"author": "Shawn", "date": "1594653013815", "content": "Hello,\nI\u2019m using a quantum machine learning program that uses this game:\nhttps://gym.openai.com/envs/CartPole-v1/ 3\nto try to keep the brown stick up as long as possible. But the Pennylane qml algorithm doesn\u2019t learn:\n\nThe blue is the actual duration of each attempt/episode and the orange line is the average of the last 100 episodes. At the beginning, the high duration could be due to random choices and doesn\u2019t necessarily mean the algorithm is getting worse. To get a perspective how it should look, here is a result of the program with only classical machine learning:\n\nThe Ansatz that was used is below:\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.nn.functional import relu\nimport pennylane as qml\n\nout_dim = 2  # output dimension of model\nwires = 1  # this is the width of the quantum element\nn_quantum_layers = 2  # this is the depth of the quantum element\n\n\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    qml.templates.SqueezingEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10,\n                                    wires=range(wires))\n    return [qml.expval(qml.X(wires=i)) for i in range(wires)]\n\n\nclass DQN(nn.Module):\n\n    def __init__(self, img_height, img_width):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(in_features=img_height * img_width * 3, out_features=12)\n        self.fc2 = nn.Linear(in_features=12, out_features=8)\n       # self.fc3 = nn.Linear(in_features=10, out_features=8)\n        self.clayer_in = torch.nn.Linear(in_features=8, out_features=wires)\n        self.clayer_out = torch.nn.Linear(wires, out_dim)\n\n        dev = qml.device('strawberryfields.fock', wires=wires, cutoff_dim=3)\n        self.layer_qnode = qml.QNode(layer, dev)\n\n        weights = qml.init.cvqnn_layers_all(n_quantum_layers, wires)\n        weight_shapes = {\"w{}\".format(i): w.shape for i, w in enumerate(weights)}\n        \n        self.qlayer = qml.qnn.TorchLayer(self.layer_qnode, weight_shapes)\n\n    def forward(self, t):\n        t = self.flatten(t)\n        t = self.fc1(t)\n        t = self.fc2(t)\n       # t = self.fc3(t)\n        t = self.clayer_in(t)\n        t = self.qlayer(t)\n        t = self.clayer_out(t)\n        t = t.sigmoid()\n        return t\n\nDoes anyone have an idea why the algorithm is not learning?\n\n\n Solved by theodor in post #18 \n\n\n                Hi @Shawn, \nThe parameters are mostly between 0 and 2\\pi for the different angles for the beamsplitters and rotations in the interferometer part of the network (the details can be found in the documentation). There are no specific values that you should use here. What you could instead do is train t\u2026\n              \n1 Reply", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/1"}, "1": {"author": "nathan", "date": "1594666898732", "content": "Hi @Shawn,\nOne thing that always comes to mind when people are working with CV layers is that if the cutoff is too small, it can be very easy to obtain inaccurate or confusing answers. The reason for this would be that certain gates (squeezing, displacement, and cubic phase) add energy to the system. The more of these gates you have, the more likely they are to raise the energy of the CV state, requiring a higher cutoff to accurately capture.\nThe cutoff in your code (of 3) is very likely to be too small, and to be subject the problem I described above. I would recommend verifying whether or not the system has a trace equal to (or near to) 1 at the end of your quantum layer. If not, you\u2019ll need to bump up the cutoff dimension (with the tradeoffs in increased resources that come from that)", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/2"}, "2": {"author": "Shawn", "date": "1594668741713", "content": "Hi @nathan many thanks for the insight. Are you referring to self.qlayer() or at the end of the forward() function?", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/3"}, "3": {"author": "nathan", "date": "1594669656910", "content": "Yes. More specifically, in the device used to compute that layer, as specified here:\n\n\n\n Shawn:\n\ndev = qml.device(\u2018strawberryfields.fock\u2019, wires=wires, cutoff_dim=3)\n\n", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/4"}, "4": {"author": "Shawn", "date": "1594671946779", "content": "My apologies @nathan but I just tried to  print(dev) but I just get\nStrawberry Fields Fock PennyLane plugin\nShort name: strawberryfields.fock\nPackage: pennylane_sf\nPlugin version: 0.9.0\nAuthor: Josh Izaac\nWires: 1\nShots: 1000\n\nand just running >>>dev gives\n<StrawberryFieldsFock device (wires=1, shots=1000) at 0x7ff63e370bb0>\n\nI ran this code:\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.nn.functional import relu\nimport pennylane as qml\n\nout_dim = 2  # output dimension of model\nwires = 1  # this is the width of the quantum element\nn_quantum_layers = 2  # this is the depth of the quantum element\n\n\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    qml.templates.SqueezingEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10,wires=range(wires))\n    return [qml.expval(qml.X(wires=i)) for i in range(wires)]\n\n\nflatten = nn.Flatten()\nfc1 = nn.Linear(in_features=10 * 10 * 3, out_features=12)\nfc2 = nn.Linear(in_features=12, out_features=8)\nclayer_in = torch.nn.Linear(in_features=8, out_features=wires)\nclayer_out = torch.nn.Linear(wires, out_dim)\ndev = qml.device('strawberryfields.fock', wires=wires, cutoff_dim=3)\nlayer_qnode = qml.QNode(layer, dev)\nweights = qml.init.cvqnn_layers_all(n_quantum_layers, wires)\nweight_shapes = {\"w{}\".format(i): w.shape for i, w in enumerate(weights)}\nqlayer = qml.qnn.TorchLayer(layer_qnode, weight_shapes)", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/5"}, "5": {"author": "nathan", "date": "1594734490978", "content": "Hi @Shawn,\nAs mentioned, you\u2019ll need to change the cutoff dimension in your device.\nYou can do this by changing the line\ndev = qml.device('strawberryfields.fock', wires=wires, cutoff_dim=3)\nto\ndev = qml.device('strawberryfields.fock', wires=wires, cutoff_dim=N)\nwhere N is some higher cutoff value than 3", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/6"}, "6": {"author": "Shawn", "date": "1594747729450", "content": "Hi @nathan yea that is obvious. Was just wondering how to get the output of the trace i.e. the matrix so I could see if it is near 1 to find a good number.", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/7"}, "7": {"author": "josh", "date": "1594780909951", "content": "Hi Shawn,\nThe trace of the system, \\text{Tr}(\\rho), can also be written as \\text{Tr}(\\rho I)=\\langle I\\rangle, so we can equivalently think of it as the expectation of the identity operator.\nThis allows you to construct a QNode that returns the trace like so:\n@qml.qnode(dev)\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    qml.templates.SqueezingEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10,wires=range(wires))\n    return qml.Identity(wires=range(wires))\n\nAlternatively, without modifying your existing QNode, you can inspect the device after QNode evaluation to find the trace:\n@qml.qnode(dev)\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    qml.templates.SqueezingEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10,wires=range(wires))\n    return [qml.expval(qml.X(wires=i)) for i in range(wires)]\n\n# evaluate the QNode\nresult = layers(**inputs)\n\n# Check the device trace\ndev.state.trace()\n", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/8"}, "8": {"author": "Shawn", "date": "1595855580187", "content": "Hi @josh thanks for the insight. @nathan I have cutoff_dim set to 10 and played with other variables (also removed some linear layers) and still see no learning from the algorithm. Here is the DQN algorithm (similar to the one in my initial post but some things changed):\nout_dim = 4  # output dimension of model\nwires = 1  # this is the width of the quantum element\nn_quantum_layers = 2  # this is the depth of the quantum element\n\n\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    qml.templates.SqueezingEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10,\n                                    wires=range(wires))\n    return [qml.expval(qml.X(wires=i)) for i in range(wires)]\n\n\nclass DQN(nn.Module):\n\n    def __init__(self, img_height, img_width):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.clayer_in = torch.nn.Linear(in_features=img_height * img_width * 3, out_features=wires)\n        self.clayer_out = torch.nn.Linear(wires, out_dim)\n\n        dev = qml.device('strawberryfields.fock', wires=wires, cutoff_dim=10)\n        self.layer_qnode = qml.QNode(layer, dev)\n\n        weights = qml.init.cvqnn_layers_all(n_quantum_layers, wires)\n        weight_shapes = {\"w{}\".format(i): w.shape for i, w in enumerate(weights)}\n\n        self.qlayer = qml.qnn.TorchLayer(self.layer_qnode, weight_shapes)\n\n    def forward(self, t):\n        t = self.flatten(t)\n        t = self.clayer_in(t)\n        t = self.qlayer(t)\n        t = self.clayer_out(t)\n        t = t.sigmoid()\n        return t\n\nAny other ideas on how I can improve this?", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/9"}, "9": {"author": "nathan", "date": "1595863620193", "content": "Hi Shawn,\nWere you able to verify that the trace remained close to one (using the methods @josh mentioned) in your updated model?", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/10"}, "10": {"author": "Shawn", "date": "1595865392427", "content": "No I kept getting errors so I just opted to try different cut_off dimensions. I tried up to 30 and didn\u2019t see a difference. The problem is with @josh\u2019s code is that I don\u2019t have a decorator on my layer function. The first error I get is:\nTraceback (most recent call last):\n  File \"test_qdqn.py\", line 19, in <module>\n    result = layer(**inputs)\nNameError: name 'inputs' is not defined\n\n@Josh do you have any recommendations on to solve this?", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/11"}, "11": {"author": "Maria_Schuld", "date": "1595916835447", "content": "Hey @Shawn, if I may come in here briefly to clarify your last questions:\n\nThe decorator Josh used is just a shorthand for what you are doing, your code\n\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    ...\n    return ...\n\ndev = qml.device('strawberryfields.fock', wires=wires, cutoff_dim=3)\nlayer_qnode = qml.QNode(layer, dev)\n\nwould be the same as writing\ndev = qml.device('strawberryfields.fock', wires=wires, cutoff_dim=3)\n\n@qml.qnode(dev)\ndef layer_qnode(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    ...\n    return ...\n\nsince the decorator turns the quantum function directly into a qnode. In other words, both code pieces produce the same object layer_qnode.\n\nTo check the trace of your qnode you have to evaluate it with specific inputs. I think Josh just called generic inputs to the qnode inputs here, which may be confusing because it is not the same as the object in def layer(inputs,...).\n\nSo in your case, you need to define specific values for input, w0, w1,.... at which you want to check the trace, and feed them to the qnode:\nprint(layer_qnode(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10))\n# Hopefully the result is 1\n\nThe double star notation is just a handy way to unpack dictionaries, while a single star would unpack a list.", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/12"}, "12": {"author": "Shawn", "date": "1596021703101", "content": "Hi @Maria_Schuld thanks for clearing up the confusion there. I have a couple follow-up questions if that is okay:\n\n\nI read up on https://pennylane.readthedocs.io/en/ising/_modules/pennylane/qnode.html but how are the variables from layer()put into qml.QNode(layer, dev)? The variable res = self.func(*variables, **kwarg_variables) surely helps with this but the \u201cinputs\u201d and w_i\u2019s from the layer() function have to be originated somewhere \u2013 I\u2019m having troubles finding out how/where to find these values.\n\n\nI\u2019m confused on the dimension of the variables w_i that is explained here: https://pennylane.readthedocs.io/en/stable/code/api/pennylane.templates.layers.CVNeuralNetLayers.html :\n\u201cThe layers act on the M modes given in wires\u201d Since in my example uses wires=1 Does that mean M is equal to 1? That wouldn\u2019t make sense because K would then be zero.\n\n\nDoesn\u2019t it matter what values I put into the layer() function? I would assume that would alter the trace, right? So putting in arbitrary values would give me wrong insight to the trace.\n\n\nI\u2019m hoping to see real values for the \u201cinputs\u201d and \u201cw_i\u2019s\u201d from the layer()function so I can then run the function with those values and see what the value of the trace is. Seems more complicated than I thought! ", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/13"}, "13": {"author": "Maria_Schuld", "date": "1596031325264", "content": "Of course.\n\nMaybe the \u201cCreating a quantum node\u201d section of the intro in the documentation can clarify this? From a user perspective, you first create a qnode which you assign to a variable, and then you use that variable as if it was your function.\n\nlayer_qnode = qml.QNode(layer, dev)\n\nlayer_qnode(<...parameters that you want to feed into layer...>)\n\n\n\nWould you mind reminding me, what is K? Yes, if you have a single wire then M should be 1.\n\n\nThe parameters may very well alter the trace. Essentially, if your cutoff_dim is too small, the quantum simulation is not exact/correct. The level of correctness could change with the inputs. Especially in Displacement and Squeezing gates the higher your parameters, the higher the energies in your circuit, and the more dimensions you need to simulate it correctly. So the rule of thumb is: small cutoff_dim \u2192 keep parameters that influence energy small.\n\n\nAnd yes, CV quantum computing is a bit more advanced than qubit-based ", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/14"}, "14": {"author": "Shawn", "date": "1596038950817", "content": "Hi @Maria_Schuld thanks for the info!\n\nUnfortunately that link didn\u2019t help. I\u2019m just trying to find out what is actually going into the layer() function (i.e. the arrays for inputs and the w0-w10 parameters). Once I have some reasonable values, I can then see if the trace is near one or not.\nFrom the link I provided: https://pennylane.readthedocs.io/en/stable/code/api/pennylane.templates.layers.CVNeuralNetLayers.html, K is the amount of beamsplitters. So since K = 0, what is the dimension of some of the parameters shown from the link above? Some of them have the dimension (L,K).\nWhat do you mean by \u201cthe higher your parameters\u201d? Meaning the values of the parameters are bigger?\n\nThanks again!", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/15"}, "15": {"author": "theodor", "date": "1596052267505", "content": "Hi @Shawn!\nThe layer function that you\u2019ve defined will take in the parameters inputs and w0, w1, etc. and so will the layer_qnode = qml.QNode(layer, dev). What you decide to input into the QNode is up to you and your code, with some restrictions (see SqueezingEmbedding and CVNeuralNetLayers for specifics).\nTo get the trace of a state it\u2019s probably easiest to evaluate the QNode, i.e. input some parameters into the QNode as layer_qnode(\"params-of-your-choice\"), and then checking the trace of the state with dev.state.trace() as per the suggestion above.\nRegarding K=0, it\u2019s true that for a single wire the parameters with shape (L, K) will be empty, since the beamsplitters can be seen as rotations between two wires and thus won\u2019t be applied at all on a single wire.\nI hope this addresses your questions. ", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/16"}, "16": {"author": "Shawn", "date": "1596058693806", "content": "Hi @theodor  thanks for the reply! Yes, I understood all of that but my code doesn\u2019t provide the values for the layer function \u2013 that is where I am confused. My code provides states, actions and q-values but the w0, w1, etc. comes from  (or should I say is due to) the quantum layer. As Maria stated, the values of the parameters going into the layer() may alter the trace \u2013 so without knowing what usual values of the parameters are (are they negative? are they bounded within a set of real numbers? etc.), I am kind of swinging in the dark. Does that make sense?\nBut, of course I did try and I am confused on how the weights should look. Perhaps someone could give me some insight?\nI ran:\nimport pennylane as qml\nimport tensorflow as tf\n\n\nout_dim = 8 \nwires = 1 \nn_quantum_layers = 2 \n\n\ndev = qml.device(\"strawberryfields.fock\", wires=wires, cutoff_dim=10)\n\n@qml.qnode(dev)\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    qml.templates.DisplacementEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10, wires=range(wires))\n    return qml.Identity(wires=range(wires))\n    \nprint(layer([1],[1],[2],[3],[4],[5],[6],[7],[8],[9],[10],[11]))\n\nAnd am getting the error;\nValueError: wrong shape of weight input(s) detected\nI\u2019d appreciate any guidance on the shape of the parameters.", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/17"}, "17": {"author": "theodor", "date": "1596120409693", "content": "Hi @Shawn,\nThe parameters are mostly between 0 and 2\\pi for the different angles for the beamsplitters and rotations in the interferometer part of the network (the details can be found in the documentation). There are no specific values that you should use here. What you could instead do is train the network, optimizing over these parameters, and print the trace in-between each step to see if the trace keeps close to 1 (if it does not, then you should use a higher cutoff).\nThe shape of your inputs should follow the ones in the CVNeuralNetLayers; see the list of shapes under Parameters at the bottom of the documentation page 3 (e.g. they should be 2-dimensional arrays of floats with shape (L, K) or (L, M), with some being, as noted earlier, empty: [[],[]]).\nJust as an example (this should work):\nimport pennylane as qml\nimport tensorflow as tf\n\nwires = 1 \n\ndev = qml.device(\"strawberryfields.fock\", wires=wires, cutoff_dim=10)\n\n@qml.qnode(dev)\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    qml.templates.SqueezingEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10,wires=range(wires))\n    return [qml.expval(qml.X(wires=i)) for i in range(wires)]\n\nand then printing the trace after evaluating the above QNode:\ninputs = [0.5]\na = [[], []]  # shape: (L, K) = (2, 0)\nb = [[0.5], [0.5]]  # shape: (L, M) = (2, 1)\n\nresults = layer(inputs, a, a, b, b, b, a, a, b, b, b, b)\n\ndev.state.trace()\nSolution", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/18"}, "18": {"author": "Shawn", "date": "1596129677571", "content": "Thank you @theodor and everyone! 1", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/19"}, "19": {"author": "Shawn", "date": "1596572004600", "content": "Hi everyone, I\u2019d like to restart this topic. So over the last week I\u2019ve been programing and running several games with classical and quantum algorithms and would like to discuss some of my findings.\nI made a new very simplified reinforcement learning deep q-network algorithm (DQN) using the game Frozenlake-v0  and have been running both classical ML and QML programs over the last 5 days. The cartpole game that I used at the beginning of this post ended up being too time costly in terms of finding an optimal policy when using QML so I switched games. Frozenlake is as simple as it gets.\nThe neural network for the DQN (classical ML) is as follows:\nn_actions = env.action_space.n\ninput_dim = env.observation_space.n\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Dense(32, input_dim = input_dim , activation = 'relu'))\nmodel.add(tf.keras.layers.Dense(16, activation = 'relu'))\nmodel.add(tf.keras.layers.Dense(n_actions, activation = 'linear'))\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.00012), loss = 'mse')\n\nAnd after testing an assortment of different hyperparameters here are the best results I got with a learning rate of 0.00012:\n\nWhat you see here is: 0 is the total reward if the agent does not get to the goal and 1 if the agent makes it to the goal (click on the Frozenlake hyperlink above to get a visualization of the game: H = hole, F = Frozen, G = Goal and S = Start). So we see after a lot of exploration, the agent learns heavily around the 700 mark and it is almost certain that the agent reaches the goal every time after 1000 episodes.\nFor the QML version I used:\nout_dim = 4  \nwires = 1\nn_quantum_layers = 2\n\ndev = qml.device(\"strawberryfields.fock\", wires=wires, cutoff_dim=30)\n\n@qml.qnode(dev)\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n   qml.templates.DisplacementEmbedding(inputs, wires=range(wires))\n   qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10, wires=range(wires))\n   return [qml.expval(qml.X(wires=i)) for i in range(wires)]\n\n\nweights = qml.init.cvqnn_layers_all(n_quantum_layers, wires)#, seed=0)\nweight_shapes = {\"w{}\".format(i): w.shape for i, w in enumerate(weights)}\nqlayer = qml.qnn.KerasLayer(layer, weight_shapes, output_dim=wires)\nclayer_in = tf.keras.layers.Dense(wires)  # we will sandwich the quantum circuit between two classical layers\nclayer_out = tf.keras.layers.Dense(out_dim)\nmodel = tf.keras.models.Sequential([clayer_in, qlayer, clayer_out])\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.00012), loss = 'mse')\n\nI used cutoff_dim = 30 as it gave roughly .99 from the trace. Two of the best results were:\nwith learning rate 0.00012:\n\nand with learning rate 0.0012:\n\nSo it\u2019s a bummer it is not learning and I would like to get some input as to why this could be or what else I can try out that could potentially improve the results.\nSome more remarks and questions:\n\n\nThe QML program takes much longer than the classical. Classical takes about 10-20 minutes to finish and the QML 1-2 days. What could be the reason(s) behind this? Is there a way to see where the bottlenecks are or what is actually taking so long on the pennylane side?\n\n\nAlso, this is of couse reinforcement learning, something that is a bit different than un/supervised learning. Could it be that Pennylane isn\u2019t prepared to do RL i.e. sequential decision making just yet? (I believe if pennylane has a neural network, it should work disregarding what area of ML it is being used in)\n\n\nCould it be a bad Ansatz? In this paper they provide an \u201cequivalent\u201d (CVNN) to the classical neural network and also explain that we just don\u2019t know which Ans\u00e4tze will be good (just like in classical machine learning). Could it be that we need to just run through the guessing game and try things out to see what works?\n\n\nThe findings in the HuHu papers:\n\nscirp.org\n\n\n\nNS_2019012315280690.pdf\n1754.89 KB\n\n\n\n\n\n\n\nscirp.org\n\n\n\nJQIS_2019030715065853.pdf\n690.56 KB\n\n\n\n\n\n\n\nscirp.org\n\n\n\nNS_2019011714330284.pdf\n1368.44 KB\n\n\n\n\n\nuse various algorithms from RL and he was able to get his programs to work quite quickly and successfully in terms of episodes.\nI contacted him about his findings but he hasn\u2019t been responsive unfortunately.\nAny insight is greatly appreciated.", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/20"}, "20": {"author": "josh", "date": "1594780909951", "content": "Hi Shawn,\nThe trace of the system, \\text{Tr}(\\rho)Tr(\u03c1), can also be written as \\text{Tr}(\\rho I)=\\langle I\\rangleTr(\u03c1I)=\u27e8I\u27e9, so we can equivalently think of it as the expectation of the identity operator.\nThis allows you to construct a QNode that returns the trace like so:\n@qml.qnode(dev)\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    qml.templates.SqueezingEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10,wires=range(wires))\n    return qml.Identity(wires=range(wires))\n\nAlternatively, without modifying your existing QNode, you can inspect the device after QNode evaluation to find the trace:\n@qml.qnode(dev)\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    qml.templates.SqueezingEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10,wires=range(wires))\n    return [qml.expval(qml.X(wires=i)) for i in range(wires)]\n\n# evaluate the QNode\nresult = layers(**inputs)\n\n# Check the device trace\ndev.state.trace()\n", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/21"}, "21": {"author": "theodor", "date": "1596120409693", "content": "Hi @Shawn,\nThe parameters are mostly between 0 and 2\\pi2\u03c0 for the different angles for the beamsplitters and rotations in the interferometer part of the network (the details can be found in the documentation). There are no specific values that you should use here. What you could instead do is train the network, optimizing over these parameters, and print the trace in-between each step to see if the trace keeps close to 1 (if it does not, then you should use a higher cutoff).\nThe shape of your inputs should follow the ones in the CVNeuralNetLayers; see the list of shapes under Parameters at the bottom of the documentation page 3 (e.g. they should be 2-dimensional arrays of floats with shape (L, K) or (L, M), with some being, as noted earlier, empty: [[],[]]).\nJust as an example (this should work):\nimport pennylane as qml\nimport tensorflow as tf\n\nwires = 1 \n\ndev = qml.device(\"strawberryfields.fock\", wires=wires, cutoff_dim=10)\n\n@qml.qnode(dev)\ndef layer(inputs, w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10):\n    qml.templates.SqueezingEmbedding(inputs, wires=range(wires))\n    qml.templates.CVNeuralNetLayers(w0, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10,wires=range(wires))\n    return [qml.expval(qml.X(wires=i)) for i in range(wires)]\n\nand then printing the trace after evaluating the above QNode:\ninputs = [0.5]\na = [[], []]  # shape: (L, K) = (2, 0)\nb = [[0.5], [0.5]]  # shape: (L, M) = (2, 1)\n\nresults = layer(inputs, a, a, b, b, b, a, a, b, b, b, b)\n\ndev.state.trace()\nSolution", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/22"}, "22": {"author": "jmarrazola", "date": "1596650156557", "content": "Hi Shawn,\nWow, you\u2019re tackling an interesting problem! Here\u2019s my perspective on your questions:\n\n\nSimulating quantum computers is a resource-intensive task \u2013 that\u2019s why it\u2019s worthwhile to put so much effort into building them! In your case, simulating a single wire with cutoff=30 should take considerable effort.  You can\u2019t expect training to be as fast as in the classical case. However, 1-2 days seems excessive. My only guess is that you are training over too many steps, perhaps because the learning rate is very low. So maybe try to reduce the number of optimization steps. A good benchmark would be to determine how long it takes to evaluate one run of the circuit, without training.\n\n\nThis is not an issue with PennyLane, but perhaps your quantum model is indeed not powerful enough to tackle this task. This wouldn\u2019t be too surprising: quantum and classical neural networks are different! One of the goals of quantum machine learning is to identify specific situations where quantum models can be advantageous. It\u2019s not easy! One piece of advice would be to look at the literature on quantum reinforcement learning and try to determine what strategies have already been proposed.\n\n\nIt\u2019s definitely possible that you are implementing the wrong ansatz. It may also be that the problem is not well-suited for quantum approaches. This ties in with the second question: part of the job of researchers is to figure these things out!\n\n\nAs a final reflection, I personally worked on training similar models for other tasks. You can find some examples in these papers: https://arxiv.org/abs/1806.06871 and https://arxiv.org/abs/1807.10781. The results reported there work well, but I can tell you, there were many failures along the way! Certainly there were problems where the quantum neural networks were not giving good answers.\nSo, I\u2019m afraid you are facing an obstacle that is familiar to any research scientist: interesting problems are often difficult to solve, and sometimes we have to solve them ourselves since nobody knows the answer! My personal advice: push a bit further into this example and see if you can get it to work. If you\u2019re still struggling, maybe divert your attention to another problem; there\u2019s plenty to do in QML.", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/23"}, "23": {"author": "Shawn", "date": "1596663996935", "content": "Hi @jmarrazola many thanks for the reply. Just a couple questions to your responses.\n\n\nI tried various learning rates: 0.12, 0.012, 0.0012, 0.00012 and 0.000012 and there wasn\u2019t a change in the per episode time. Learning rates in RL are usually relatively low but can be anywhere between 0.1 - 10e-6. The code for the game is exactly the same for the classical and quantum algorithms above. The only difference is the neural networks above. So I would assume that that fact would exclude it being a problem with the code (right?). Also, I have two additional programs using a different game and pytorch and the quantum alg took much longer than the classical one.\n\n\nWhat do you mean by quantum model? Just the layers that I used? The game is as simple as it gets so I\u2019d be really surprised if it\u2019s not powerful enough.\n\n\nThis is what confuses me. Professor Hu has three papers using RL algorithms (one of them being the same I am using \u2013 a DQN) and Pennylane and he used a very similar game to the one I am using and he seems to have had positive results on all of them.\n\n\nNonetheless thanks again for the tips and info!", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/24"}, "24": {"author": "jmarrazola", "date": "1596753127671", "content": "Hey Shawn,\nQuick replies:\n\n\nHow long does it take to execute the circuit in your computer? By this I mean, given some fixed parameters in the circuit, how long does it take to compute its output? If that\u2019s slow, then training will be slow\n\n\nI mean the specific quantum circuit, comprised of the specific set of gates you have chosen.\n\n\nYeah, seems like a nice puzzle for you to solve! Scientific discoveries are often just removing confusion about things we previously didn\u2019t understand.\n\n\nGood luck!1", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/25"}, "25": {"author": "Shawn", "date": "1597321527845", "content": "Hi all,\nGreat news! The program is learning! The Ansatz from this paper 2\ni.e. CVNN layer above didn\u2019t work unfortunately and the Ansatz from Professor Hu is working. Here is the layer that I am using:\ndef layer(inputs, theta, phi, varphi, x, y, z, r, ph):\n    qml.templates.DisplacementEmbedding(inputs, wires=range(wires))\n    qml.templates.Interferometer([theta], [phi], varphi, wires=range(wires))#qml.templates.Interferometer(theta, phi, varphi, wires=range(wires))\n    for i in range(wires):\n        qml.Displacement(x[i], 0, wires=i)\n        qml.Rotation(y[i], wires=i)\n        qml.Squeezing(r[i], ph[i], wires=i)\n        qml.Kerr(z[i], wires=i)\n    return [qml.expval(qml.X(wires=i)) for i in range(wires)]\n\nqlayer = qml.qnn.KerasLayer(layer, weight_shapes, output_dim=wires)\nclayer_in = tf.keras.layers.Dense(wires)\nclayer_out = tf.keras.layers.Dense(out_dim)\nmodel = tf.keras.models.Sequential([clayer_in, qlayer,clayer_out])\n\nI am surprised it ended up working and would like to expound a bit as to why this use case wouldn\u2019t/shouldn\u2019t have worked (also for the CVNN layer case) with the structure of the Tensorflow layer stack:\nI think the main problem with this task is with the initial classical layer clayer_in. The input into it is in my case a 16-dimensional array and since the out dimension of the clayer_in is wires: clayer_in = tf.keras.layers.Dense(wires), all of the information from the input is essentially lost and truncated into either 1 or 2 dimensions (1 or 2 dimensions because if wires is anything higher than two, it takes a very long time to run). Any thoughts on this? If I ended up using 16 wires and just had the clayer_in as a 16 in 16 out layer, then I would think we would see better results. But I\u2019m just speculating here.\nHere is the Ansatz from Professor Hu in his papers:\n\nAnd it ended up working. I would still think that the truncation of the clayer_in would cause problems, but the results are almost on par to the classical case.\nLastly, what information can I extrapolate from the program/layer/results to show that there is a quantum advantage or a benefit to use Pennylane/Strawberry Fields? Are there already some benchmarking tools to use? Speed is of course out of the question \u2013 we\u2019re on a classical computer. So what does one actually benchmark?\nThanks in advance!", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/26"}, "26": {"author": "Tom_Bromley", "date": "1597346464210", "content": "Hi @Shawn,\n\nGreat news! The program is learning! The Ansatz from this paper\n\nThat\u2019s great! Once you wrap up this project, you might want to consider submitting a demo 2, although note that we have a high bar for accepting demos.\n\nThe Ansatz from this paper i.e. CVNN layer above didn\u2019t work unfortunately and the Ansatz from Professor Hu is working.\n\nThat\u2019s strange - I\u2019d expect both layers to be equivalent given enough depth. Although, note that you\u2019re considering just one layer in the code block you shared - what depth where you using for CVNeuralNetLayers? Perhaps the problem with CVNeuralNetLayers is a subtlety regarding implementation rather than something fundamental, e.g., maybe problems with cutoff, or depth. Indeed, two layers of CVNeuralNetLayers should be able to emulate your ansatz exactly by turning on/off some of the gates in the two layers.\n\nI think the main problem with this task is with the initial classical layer clayer_in . The input into it is in my case a 16-dimensional array and since the out dimension of the clayer_in is wires: clayer_in = tf.keras.layers.Dense(wires) , all of the information from the input is essentially lost and truncated into either 1 or 2 dimensions (1 or 2 dimensions because if wires is anything higher than two, it takes a very long time to run). Any thoughts on this? If I ended up using 16 wires and just had the clayer_in as a 16 in 16 out layer, then I would think we would see better results. But I\u2019m just speculating here.\n\nYes, it\u2019s quite reasonable to expect that greater width in the quantum circuit might lead to better results - it\u2019s a double-edged sword, we expect to do better but at the same time it gets hard to simulate. This really is a nice motivation for hardware. For now, we have to stick with more prototype-level architectures. One thing to mention is that the dimension of the data embedded into the quantum circuit is not limited to the number of wires in the circuit. Although things like DisplacementEmbedding are commonly used, one could embed data using a combination of gates to get past the dim=wires limitation.\n\nLastly, what information can I extrapolate from the program/layer/results to show that there is a quantum advantage or a benefit to use Pennylane/Strawberry Fields?\n\nThis is always a tough bar for prototype circuits, raising questions on what is a fair comparison (e.g. should we compare quantum and classical networks of the same width/depth?). If we compare the current prototype models to cutting edge classical models, we of course wouldn\u2019t expect to do better. In terms of figure of merit, for classification or regression there is normally a nice quantity such as accuracy or mean-squared error to look at. Is there a similar quantity in your RL problem?", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/27"}, "27": {"author": "Shawn", "date": "1597349238886", "content": "Hi @Tom_Bromley\n\n\nThat\u2019s strange - I\u2019d expect both layers to be equivalent given enough depth. Although, note that you\u2019re considering just one layer in the code block you shared - what depth where you using for CVNeuralNetLayers ? Perhaps the problem with CVNeuralNetLayers is a subtlety regarding implementation rather than something fundamental, e.g., maybe problems with cutoff, or depth. Indeed, two layers of CVNeuralNetLayers should be able to emulate your ansatz exactly by turning on/off some of the gates in the two layers.\n\n\nFor the Hu Ansatz I used 1 layer, tried both wires=1,2 and played around with the cutoff_dim. For the CVNeuralNetLayers I played a ton with the parameters. I could try again to see if wires=2 and num_layers = 2 changes something but I am pretty sure I tried that already. That\u2019s what you mean right?\n\n\none could embed data using a combination of gates to get past the dim=wires limitation.\n\n\nThat certainly peaks my interest! Is there more information on this? I would like to test this out. So essentially it would be an embedded quantum layer that then sends the embedded data to the real quantum layer? If we can get this to work, I think this would make PL/SF accessible to all RL use cases.\n\n\nThis is always a tough bar for prototype circuits, raising questions on what is a fair comparison (e.g. should we compare quantum and classical networks of the same width/depth?). If we compare the current prototype models to cutting edge classical models, we of course wouldn\u2019t expect to do better. In terms of figure of merit, for classification or regression there is normally a nice quantity such as accuracy or mean-squared error to look at. Is there a similar quantity in your RL problem?\n\n\nExactly what I was thinking. Yea the loss function (I also use mse) could be something of interest. I\u2019ll look into that.\nOtherwise the reward and average reward over X attempts is usually of interest in RL but these depend heavily on the hyperparameters that are chosen.", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/28"}, "28": {"author": "Tom_Bromley", "date": "1597419091040", "content": "\nFor the Hu Ansatz I used 1 layer, tried both wires=1,2 and played around with the cutoff_dim . For the CVNeuralNetLayers I played a ton with the parameters. I could try again to see if wires=2 and num_layers = 2 changes something but I am pretty sure I tried that already. That\u2019s what you mean right?\n\nYes, what I mean specifically is that CVNeuralNetLayers with depth=2 can exactly simulate the Hu ansatz with depth=1 by carefully setting some of the parameters in CVNeuralNetLayers. For example, you could get layer 1 of CVNeuralNetLayers to do U and D of the Hu ansatz (setting parameters so that the other gates don\u2019t do anything), and then get layer 2 of CVNeuralNetLayers to do R, S and K. So in this way, we know that there exists a set of parameters for CVNeuralNetLayers that realizes the other ansatz. That being said, if the Hu ansatz is working for you, then that\u2019s great - whatever works!\n\nThat certainly peaks my interest! Is there more information on this? I would like to test this out. So essentially it would be an embedded quantum layer that then sends the embedded data to the real quantum layer? If we can get this to work, I think this would make PL/SF accessible to all RL use cases.\n\nRight, you could have an embedding layer followed by a trainable layer, you could have alternating embedding and trainable layers. You could even have the embedding at the end of the circuit (although need to think if that makes sense). So there\u2019s a lot of options. You could take a look at this 4 tutorial. It\u2019s still more of a research question on best practices and the implications of doing this.", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/29"}, "29": {"author": "Shawn", "date": "1598115476682", "content": "Hi @Tom_Bromley, I got it to work bypassing the wires constriction but am having troubles understanding how this is solving the dimension problem. My current input has a 9-dim vector, x, and I have added for an example 9 qml.Rotation() gates for the embedding part. And say if I only have one wire then the process would look like this:\n0: \u2500\u2500R(2.3)\u2500\u2500R(1.7)\u2500\u2500R(3.3)\u2500\u2500R(4.0)\u2500\u2500R(1.9)\u2500\u2500R(3.0)\u2500\u2500R(4.0)\u2500\u2500R(5.9)\u2500\u2500R(7.3)\u2500\u2500R(1.7)\u2500\u2500D(1.9, 0)\u2500\u2500R(2.9)\u2500\u2500S(2.2, 2.0)\u2500\u2500Kerr(1.7)\u2500\u2500\u2524 \u27e8x\u27e9\n\nwith RDRSK being the quantum layer. It seems we still have a dimension problem. The first 9 rotation gates each take in a x_ixi but then the information is still lost because it passes through the same gates with all the other x_ixi's and it seems that the x_ixi's at the beginning of the wire then pass through into the other rotation gates.\nAny thoughts on this?", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/30"}, "30": {"author": "Tom_Bromley", "date": "1598273153688", "content": "Hey @Shawn!\nYes good question, I agree that it seems like the R(2.3) rotation would somehow get washed out by the following 8 rotations. Also, supposing we just had two rotations R(x)R(y), all of the points for which x+y=c for a fixed constant c would result in the same rotation overall . I\u2019d have to look more carefully at the paper 1 that motivated the above tutorial, but off the top of my head, how about:\n\nDoing a single R + RDRSK repeated 9 times. The first one encodes x_0, the second x_1 and so on. Although, this will result in an increased depth.\n\nRDRSK could be used as an encoding. E.g., you could do RDRSK (first 5 params), followed by RDRSK (last 4 params), followed by a trainable RDRSK. This approach encodes different parameters in different gates, so not sure how well it will do.\n\nOverall I\u2019d say it\u2019s an opportunity to get creative and explore different encodings (as well as checking out the existing literature).\nJust wanted to point out a recent paper 3 that talks about the expressivity of quantum circuits using this repeated encoding strategy. This paper is mainly focused on qubits, but has a nice result for the power of the CV Rotation gate.", "link": "https://discuss.pennylane.ai//t/qml-algorithm-doesnt-learn/468/31"}}