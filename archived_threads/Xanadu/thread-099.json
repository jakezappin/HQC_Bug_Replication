{"0": {"author": "theodor", "date": "1612302047769", "content": "We\u2019re excited to announce our latest PennyLane release, version 0.14.0, containing a lot of new and exciting features and improvements.  \nNew JAX interface \nJAX joins TensorFlow, PyTorch and NumPy as a supported PennyLane interface, bringing its powers of automatic differentiation to the PennyLane ecosystem.\n\n\nCode example\nimport pennylane as qml\nfrom jax import numpy as jnp\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev, interface=\"jax\", diff_method=\"backprop\")\ndef circuit(x):\n    qml.RX(x[1], wires=0)\n    qml.Rot(x[0], x[1], x[2], wires=0)\n    return qml.expval(qml.PauliZ(0))\n\nweights = jnp.array([0.2, 0.5, 0.1])\ngrad_fn = jax.grad(circuit)\n\nprint(grad_fn(weights))\n\n\n\nSpeed improvements across the board  \nWe\u2019ve taken a deep dive into the codebase and updated it with many optimizations, tweaks, and improvements to make the PennyLane experience as fast as it gets.\nGradient calculations have been upgraded to better choose the \u201cbest\u201d differentiation method for the task at hand.\nA new and powerful adjoint method for gradients of simulated circuits has been added. This method is similar to the reversible method, but has a lower time overhead and a similar memory overhead.\n\n\nCode example\ndevice = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(device, diff_method=\"adjoint\")\ndef f(params):\n    qml.RX(0.1, wires=0)\n    qml.Rot(*params, wires=0)\n    qml.RX(-0.3, wires=0)\n    return qml.expval(qml.PauliZ(0))\n\nparams = [0.1, 0.2, 0.3]\nqml.grad(f)(params)\n\n\n\nA faster, leaner, and more flexible core  \nPennyLane\u2019s new core, which has been in development during the last few cycles, has finally become default in v0.14.0, providing several advantages and improvements:\n1. Support for in-QNode classical processing allows for differentiable classical processing within the QNode.\n\n\nCode example\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev, interface=\"tf\")\ndef circuit(p):\n    qml.RX(tf.sin(p[0])**2 + p[1], wires=0)\n    return qml.expval(qml.PauliZ(0))\n\nThe classical processing functions used within the QNode must match the QNode interface. Here, we use TensorFlow:\n>>> params = tf.Variable([0.5, 0.1], dtype=tf.float64)\n>>> with tf.GradientTape() as tape:\n...     res = circuit(params)\n>>> grad = tape.gradient(res, params)\n>>> print(res)\ntf.Tensor(0.9460913127754935, shape=(), dtype=float64)\n>>> print(grad)\ntf.Tensor([-0.27255248 -0.32390003], shape=(2,), dtype=float64)\n\n\n\n2. There is no longer any restriction on the QNode signature; the QNode can be defined and called following the same rules as standard Python functions.\n\n\nCode example\nThe following QNode uses positional, named, and variable keyword arguments:\nx = torch.tensor(0.1, requires_grad=True)\ny = torch.tensor([0.2, 0.3], requires_grad=True)\nz = torch.tensor(0.4, requires_grad=True)\n\n@qml.qnode(dev, interface=\"torch\")\ndef circuit(p1, p2=y, **kwargs):\n    qml.RX(p1, wires=0)\n    qml.RY(p2[0] * p2[1], wires=0)\n    qml.RX(kwargs[\"p3\"], wires=0)\n    return qml.var(qml.PauliZ(0))\n\nWhen we call the QNode, we may pass the arguments by name even if defined positionally; any argument not provided will use the default value.\n\n```pycon\n>>> res = circuit(p1=x, p3=z)\n>>> print(res)\ntensor(0.2327, dtype=torch.float64, grad_fn=<SelectBackward>)\n>>> res.backward()\n>>> print(x.grad, y.grad, z.grad)\ntensor(0.8396) tensor([0.0289, 0.0193]) tensor(0.8387)\n\nThis extends to the qnn module, where KerasLayer and TorchLayer modules can be created from QNodes with unrestricted signatures.\n\n\n3. QNodes can now measure wires more than once, as long as all observables are commuting.\n\n\nCode example\ndev = qml.device('default.qubit', wires=2)\n\n@qml.qnode(dev)\ndef circuit(x):\n    qml.RX(x, wires=0)\n    return [\n        qml.expval(qml.PauliZ(0)),\n        qml.expval(qml.PauliZ(0) @ qml.PauliZ(1))\n    ]\n\n\n\nand many more.\nNew Orquestra plugin  \nThere\u2019s a brand new plugin for Orquestra, Zapata\u2019s quantum-enabled workflow composer. With it, multiple devices offered by Orquestra can be accessed straightaway in PennyLane for cloud-based execution without the need to import new packages, including Rigetti Forest, Qiskit and Qulacs.\nAdditional improvements and features  \nIncludes support for more flexible cost functions for the built-in PennyLane optimizers (see code example below), updates to the circuit drawer allowing user-specified wire ordering, along with a lot of bug fixes and other improvements.\n\n\nCode example\ndef cost(x, y, data, scale=1.0):\n    return scale * (x[0]-data)**2 + scale * (y-data)**2\n\nx = np.array([1.], requires_grad=True)\ny = np.array([1.0])\ndata = np.array([2.], requires_grad=False)\n\nopt = qml.GradientDescentOptimizer()\n\n# the optimizer step and step_and_cost methods can\n# now update multiple parameters at once\nx_new, y_new, data = opt.step(cost, x, y, data, scale=0.5)\n(x_new, y_new, data), value = opt.step_and_cost(cost, x, y, data, scale=0.5)\n\n# list and tuple unpacking is also supported\nparams = (x, y, data)\nparams = opt.step(cost, *params)\n\n\n\nThe full release notes are available at Release notes \u2014 PennyLane 0.27.0 documentation 7.\nAs always, this release would not have been possible without all the help from our contributors:\nJuan Miguel Arrazola, Thomas Bromley, Olivia Di Matteo, Theodor Isacsson, Josh Izaac, Christina Lee, Alejandro Montanez, Steven Oud, Chase Roberts, Sankalp Sanand, Maria Schuld, Antal Sz\u00e1va, David Wierichs, Jiahao Yao.3", "link": "https://discuss.pennylane.ai//t/pennylane-v0-14-0-released/803/1"}, "1": {"author": "theodor", "date": "1612302047769", "content": "We\u2019re excited to announce our latest PennyLane release, version 0.14.0, containing a lot of new and exciting features and improvements.  \nNew JAX interface \nJAX joins TensorFlow, PyTorch and NumPy as a supported PennyLane interface, bringing its powers of automatic differentiation to the PennyLane ecosystem.\n\n\nCode example\nimport pennylane as qml\nfrom jax import numpy as jnp\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev, interface=\"jax\", diff_method=\"backprop\")\ndef circuit(x):\n    qml.RX(x[1], wires=0)\n    qml.Rot(x[0], x[1], x[2], wires=0)\n    return qml.expval(qml.PauliZ(0))\n\nweights = jnp.array([0.2, 0.5, 0.1])\ngrad_fn = jax.grad(circuit)\n\nprint(grad_fn(weights))\n\n\n\nSpeed improvements across the board  \nWe\u2019ve taken a deep dive into the codebase and updated it with many optimizations, tweaks, and improvements to make the PennyLane experience as fast as it gets.\nGradient calculations have been upgraded to better choose the \u201cbest\u201d differentiation method for the task at hand.\nA new and powerful adjoint method for gradients of simulated circuits has been added. This method is similar to the reversible method, but has a lower time overhead and a similar memory overhead.\n\n\nCode example\ndevice = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(device, diff_method=\"adjoint\")\ndef f(params):\n    qml.RX(0.1, wires=0)\n    qml.Rot(*params, wires=0)\n    qml.RX(-0.3, wires=0)\n    return qml.expval(qml.PauliZ(0))\n\nparams = [0.1, 0.2, 0.3]\nqml.grad(f)(params)\n\n\n\nA faster, leaner, and more flexible core  \nPennyLane\u2019s new core, which has been in development during the last few cycles, has finally become default in v0.14.0, providing several advantages and improvements:\n1. Support for in-QNode classical processing allows for differentiable classical processing within the QNode.\n\n\nCode example\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev, interface=\"tf\")\ndef circuit(p):\n    qml.RX(tf.sin(p[0])**2 + p[1], wires=0)\n    return qml.expval(qml.PauliZ(0))\n\nThe classical processing functions used within the QNode must match the QNode interface. Here, we use TensorFlow:\n>>> params = tf.Variable([0.5, 0.1], dtype=tf.float64)\n>>> with tf.GradientTape() as tape:\n...     res = circuit(params)\n>>> grad = tape.gradient(res, params)\n>>> print(res)\ntf.Tensor(0.9460913127754935, shape=(), dtype=float64)\n>>> print(grad)\ntf.Tensor([-0.27255248 -0.32390003], shape=(2,), dtype=float64)\n\n\n\n2. There is no longer any restriction on the QNode signature; the QNode can be defined and called following the same rules as standard Python functions.\n\n\nCode example\nThe following QNode uses positional, named, and variable keyword arguments:\nx = torch.tensor(0.1, requires_grad=True)\ny = torch.tensor([0.2, 0.3], requires_grad=True)\nz = torch.tensor(0.4, requires_grad=True)\n\n@qml.qnode(dev, interface=\"torch\")\ndef circuit(p1, p2=y, **kwargs):\n    qml.RX(p1, wires=0)\n    qml.RY(p2[0] * p2[1], wires=0)\n    qml.RX(kwargs[\"p3\"], wires=0)\n    return qml.var(qml.PauliZ(0))\n\nWhen we call the QNode, we may pass the arguments by name even if defined positionally; any argument not provided will use the default value.\n\n```pycon\n>>> res = circuit(p1=x, p3=z)\n>>> print(res)\ntensor(0.2327, dtype=torch.float64, grad_fn=<SelectBackward>)\n>>> res.backward()\n>>> print(x.grad, y.grad, z.grad)\ntensor(0.8396) tensor([0.0289, 0.0193]) tensor(0.8387)\n\nThis extends to the qnn module, where KerasLayer and TorchLayer modules can be created from QNodes with unrestricted signatures.\n\n\n3. QNodes can now measure wires more than once, as long as all observables are commuting.\n\n\nCode example\ndev = qml.device('default.qubit', wires=2)\n\n@qml.qnode(dev)\ndef circuit(x):\n    qml.RX(x, wires=0)\n    return [\n        qml.expval(qml.PauliZ(0)),\n        qml.expval(qml.PauliZ(0) @ qml.PauliZ(1))\n    ]\n\n\n\nand many more.\nNew Orquestra plugin  \nThere\u2019s a brand new plugin for Orquestra, Zapata\u2019s quantum-enabled workflow composer. With it, multiple devices offered by Orquestra can be accessed straightaway in PennyLane for cloud-based execution without the need to import new packages, including Rigetti Forest, Qiskit and Qulacs.\nAdditional improvements and features  \nIncludes support for more flexible cost functions for the built-in PennyLane optimizers (see code example below), updates to the circuit drawer allowing user-specified wire ordering, along with a lot of bug fixes and other improvements.\n\n\nCode example\ndef cost(x, y, data, scale=1.0):\n    return scale * (x[0]-data)**2 + scale * (y-data)**2\n\nx = np.array([1.], requires_grad=True)\ny = np.array([1.0])\ndata = np.array([2.], requires_grad=False)\n\nopt = qml.GradientDescentOptimizer()\n\n# the optimizer step and step_and_cost methods can\n# now update multiple parameters at once\nx_new, y_new, data = opt.step(cost, x, y, data, scale=0.5)\n(x_new, y_new, data), value = opt.step_and_cost(cost, x, y, data, scale=0.5)\n\n# list and tuple unpacking is also supported\nparams = (x, y, data)\nparams = opt.step(cost, *params)\n\n\n\nThe full release notes are available at Release notes \u2014 PennyLane 0.27.0 documentation 7.\nAs always, this release would not have been possible without all the help from our contributors:\nJuan Miguel Arrazola, Thomas Bromley, Olivia Di Matteo, Theodor Isacsson, Josh Izaac, Christina Lee, Alejandro Montanez, Steven Oud, Chase Roberts, Sankalp Sanand, Maria Schuld, Antal Sz\u00e1va, David Wierichs, Jiahao Yao.3", "link": "https://discuss.pennylane.ai//t/pennylane-v0-14-0-released/803/2"}}