{"0": {"author": "Kuma-quant", "date": "1624604518386", "content": "I want to implement data re-uploading technique in hybrid NN.\nBut I don\u2019t know how to make the number of layers variable.\nHere is my sample code.\nKeras layers were used.\nn_qubits = 2\nlayers = 2\ndata_dimension = 1 # output\nparam = {'num_epochs': 64}\n\ndev = qml.device(\"lightning.qubit\", wires=n_qubits)\n\n@qml.qnode(dev, diff_method = \"adjoint\")\n# data re-uploading 2 times manually.\ndef qnode(inputs, weights0, weights1):\n    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.templates.StronglyEntanglingLayers(weights0, wires=range(n_qubits))\n    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.templates.StronglyEntanglingLayers(weights1, wires=range(n_qubits))    \n    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n\n\nweight_shapes = dict()\nfor i in range(layers):\n    weight_shapes[\"weights\"+str(i)]=(1, n_qubits,3)\n\nqlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nclayer1 = tf.keras.layers.Dense(n_qubits, activation='linear')\nclayer2 = tf.keras.layers.Dense(data_dimension, activation=\"linear\")\nmodel = tf.keras.models.Sequential([clayer1,qlayer,clayer2])\n\nIn the code, I manually iterate data re-uploading layer 2 times without using for loop.\nI want to make the number of data re-uploading layer variable by introducing for loop.\nHere is just image.\nfor i in range(layers):\n    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.templates.StronglyEntanglingLayers(weights[i], wires=range(n_qubits))\n\nHow can I implement it?", "link": "https://discuss.pennylane.ai//t/data-re-uploading-impelementation-in-hybrid-nn-with-keras-layer/1145/1"}, "1": {"author": "theodor", "date": "1624641590252", "content": "Hi @Kuma-quant,\nIt should work to just use a for-loop inside the QNode (as per you\u2019re suggestion), just defining the number of layers outside of it, as you\u2019re also currently doing:\ndef qnode(inputs, weights0, weights1):\n    for i in range(layers):\n        qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n        qml.templates.StronglyEntanglingLayers(weights[i], wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n\nIs this what you\u2019re aiming to do or are you attempting to optimize over the number of layers as well? If you can share with me exactly what\u2019s not working (e.g. a minimal non-working example) I could probably help you a bit better. ", "link": "https://discuss.pennylane.ai//t/data-re-uploading-impelementation-in-hybrid-nn-with-keras-layer/1145/2"}, "2": {"author": "Kuma-quant", "date": "1624800439436", "content": "Here is a sample code including dummy input data.\nIt returns error.\nPennylane : Version: 0.16.0\nTensorflow : Version: 2.4.1\nimport tensorflow as tf\nimport keras_metrics\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\nimport pennylane as qml\nfrom pennylane import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nnum_of_data = 64\nX = np.random.normal((num_of_data,1))\nY = np.sin(X)\n\nn_qubits = 1\nlayers = 2\ndata_dimension = 1 # output\n\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(dev, diff_method='adjoint')\ndef qnode(inputs, weights):\n    for i in range(layers):\n        qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n        qml.templates.StronglyEntanglingLayers(weights[i,:,:], wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n\nweight_shapes = {\"weights\": (layers, n_qubits,3)}\n\nqlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nclayer1 = tf.keras.layers.Dense(n_qubits, activation='linear')\nclayer2 = tf.keras.layers.Dense(data_dimension, activation=\"linear\")\nmodel = tf.keras.models.Sequential([clayer1,qlayer,clayer2])\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.01)\nmodel.compile(opt, loss='mse')\n\nhist = model.fit(X, Y, epochs=30, validation_split=0.1, verbose=1, shuffle='True', batch_size=32)\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-18-01ae07b47770> in <module>\n     23 model.compile(opt, loss='mse')\n     24 \n---> 25 hist = model.fit(X, Y, epochs=30, validation_split=0.1, verbose=1, shuffle='True', batch_size=32)\n\n~~~~~\n\nValueError: Weights tensor must be 3-dimensional; got shape (1, 3)\n\nweights[i,:,:] was treated as a 2d-array.\nI tried to fix the array dimenstion by introducing np_split.\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(dev, diff_method='adjoint')\ndef qnode(inputs, weights):\n    weights_each_layer = np.split(weights,layers,axis=0)\n    for i in range(layers):\n        qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n        qml.templates.StronglyEntanglingLayers(weights_each_layer[i], wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n\nweight_shapes = {\"weights\": (layers, n_qubits,3)}\n\nqlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nclayer1 = tf.keras.layers.Dense(n_qubits, activation='linear')\nclayer2 = tf.keras.layers.Dense(data_dimension, activation=\"linear\")\nmodel = tf.keras.models.Sequential([clayer1,qlayer,clayer2])\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.01)\nmodel.compile(opt, loss='mse')\n\nhist = model.fit(X, Y, epochs=30, validation_split=0.1, verbose=1, shuffle='True', batch_size=32)\n\nThis revised code can run but I got another warning.\nEpoch 1/30\nWARNING:tensorflow:Gradients do not exist for variables ['sequential_9/keras_layer_9/weights:0'] when minimizing the loss.\nWARNING:tensorflow:Gradients do not exist for variables ['sequential_9/keras_layer_9/weights:0'] when minimizing the loss.\n1/1 [==============================] - 0s 155ms/step - loss: 0.1568 - val_loss: 0.0025\nEpoch 2/30\nWARNING:tensorflow:Gradients do not exist for variables ['sequential_9/keras_layer_9/weights:0'] when minimizing the loss.\nWARNING:tensorflow:Gradients do not exist for variables ['sequential_9/keras_layer_9/weights:0'] when minimizing the loss.\n1/1 [==============================] - 0s 75ms/step - loss: 0.1231 - val_loss: 0.0030\n\nThe error seems critical.\nHow can I fix it?", "link": "https://discuss.pennylane.ai//t/data-re-uploading-impelementation-in-hybrid-nn-with-keras-layer/1145/3"}, "3": {"author": "Kuma-quant", "date": "1624804217061", "content": "I have found a temporary solution.\nIt worked!\nI pushed layer-dimension on 3rd-dimension of weight.\n@qml.qnode(dev, diff_method='adjoint')\ndef qnode(inputs, weights):\n    for i in range(layers):\n        qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n        qml.templates.StronglyEntanglingLayers(weights[:,:,3*i:3*(i+1)], wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n\nweight_shapes = {\"weights\": (1, n_qubits,3*layers)}\n\nEpoch 1/30\n1/1 [==============================] - 0s 140ms/step - loss: 0.8418 - val_loss: 0.1298\nEpoch 2/30\n1/1 [==============================] - 0s 65ms/step - loss: 0.1251 - val_loss: 0.1253\nEpoch 3/30\n1/1 [==============================] - 0s 65ms/step - loss: 0.0714 - val_loss: 0.1183\n\nNo error occurs.\nTo check if the model is correct, I have investigated the number of trainable parameters.\nmodel.summary()\n\nModel: \"sequential_14\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_28 (Dense)             (1, 1)                    2         \n_________________________________________________________________\nkeras_layer_14 (KerasLayer)  (1, 1)                    6         \n_________________________________________________________________\ndense_29 (Dense)             (1, 1)                    2         \n=================================================================\nTotal params: 10\nTrainable params: 10\nNon-trainable params: 0\n\nSince a StronglyEntanglingLayer requires 3 trainable parameters, the number of trainable parameters should be 6 for two StronglyEntanglingLayer.\nTherefore, the above result is reasonable!\nBut the implementation would not be beautiful.\nIf there is some better idea, please teach me.", "link": "https://discuss.pennylane.ai//t/data-re-uploading-impelementation-in-hybrid-nn-with-keras-layer/1145/4"}, "4": {"author": "josh", "date": "1624864571211", "content": "Hi @Kuma-quant, glad to see you got it working!!\nWith regards to your previous post, my guess is that you were getting the error\nWARNING:tensorflow:Gradients do not exist for variables ['sequential_9/keras_layer_9/weights:0'] when minimizing the loss.\n\nbecause, inside the QNode, you were using NumPy:\nweights_each_layer = np.split(weights,layers,axis=0)\n\nWhen using Keras with QNodes, you will need to ensure that all array/tensor manipulations use TensorFlow rather than NumPy. Otherwise, Keras will not be able to differentiate your QNode.\nLuckily, there is often a TensorFlow equivalent for most NumPy functions. In this case, tf.split.", "link": "https://discuss.pennylane.ai//t/data-re-uploading-impelementation-in-hybrid-nn-with-keras-layer/1145/5"}, "5": {"author": "Kuma-quant", "date": "1625020368451", "content": "Dear josh-san,\nThanks for the advice.\ntf.split worked well.\nGreat.\ndev = qml.device(\"lightning.qubit\", wires=n_qubits)\n\n@qml.qnode(dev, diff_method='adjoint', immutable=False)\ndef qnode(inputs, weights):\n    weights_each_layer = tf.split(weights, num_or_size_splits=layers, axis=0)\n    for i in range(layers):\n        qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n        qml.templates.StronglyEntanglingLayers(weights_each_layer[i], wires=range(n_qubits))\n    return qml.expval(qml.PauliZ(0))\n\nweight_shapes = {\"weights\": (layers, n_qubits,3)}\n\nEpoch 1/3\n4/4 [==============================] - 1s 271ms/step - loss: 0.9884 - val_loss: 1.0154\nEpoch 2/3\n4/4 [==============================] - 1s 264ms/step - loss: 0.6703 - val_loss: 0.6914\nEpoch 3/3\n4/4 [==============================] - 1s 262ms/step - loss: 0.3764 - val_loss: 0.3741\n1", "link": "https://discuss.pennylane.ai//t/data-re-uploading-impelementation-in-hybrid-nn-with-keras-layer/1145/6"}, "6": {"author": "josh", "date": "1625026914372", "content": "@Kuma-quant glad to hear it worked out ", "link": "https://discuss.pennylane.ai//t/data-re-uploading-impelementation-in-hybrid-nn-with-keras-layer/1145/7"}}