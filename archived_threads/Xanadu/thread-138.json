{"0": {"author": "KAJ226", "date": "1612984000439", "content": "I recently went over the tutorial write-up \" Doubly stochastic gradient descent\"(https://pennylane.ai/qml/demos/tutorial_doubly_stochastic.html#doubly-stochastic-gradient-descent 1)\nand there are a few things that I don\u2019t understand. But here I just want to ask about the single-shot result.\nHow can a single-shot give you anything here? A single shot gives you a single eigenstate that either belongs into the +1 or -1 eigenspace of P_i where P_i \\in {I,X,Y,Z}^{\\otimes n}. It does not give you any info on the expectation of P_i, \\langle P_i \\rangle.\nThank you.\n\n\n Solved by josh in post #4 \n\n\n                It definitely is a bit unintuitive! \nHowever, it is worth noting that this result does not come purely from the quantum mechanics; this is a result that holds in classical settings whenever we use stochastic gradient descent (SGD). \nIn SGD, we typically consider a cost function of the following form\u2026\n              \n", "link": "https://discuss.pennylane.ai//t/single-shot-stochastic-gradient-descent/842/1"}, "1": {"author": "josh", "date": "1613014203353", "content": "Hi @KAJ226! When computing expectation values of observables on hardware, we can only sample a finite number of shots N from the quantum device. For each shot, we are measuring an eigenvalue of the observable, \\lambda, so we will get an output vector\n\n\\Lambda = (\\lambda^{(0)}, \\lambda^{(1)}, \\dots, \\lambda^{(N-1)}).\n\nSo when we compute the expectation value, we are always computing an approximation to the expectation value:\n\n\\langle P_i \\rangle \\approx \\frac{1}{N} \\sum_{n=0}^{N-1} \\Lambda_n.\n\n(This is in fact an unbiased estimator of the expectation value.) For a single shot, we have N=1. So we can interpret a single shot measurement as a 1-shot approximation to the expectation value.\nThis is exactly what happens in PennyLane if we ask for an expectation value with only a single shot:\ndev = qml.device(\"default.qubit\", wires=1, analytic=False, shots=1)\n\n@qml.qnode(dev)\ndef circuit():\n    qml.Hadamard(wires=0)\n    return qml.expval(qml.PauliZ(0)), qml.sample(qml.PauliZ(0))\n\n>>> circuit()\ntensor([1., 1.], requires_grad=True)\n>>> circuit()\ntensor([-1., -1.], requires_grad=True)\n\nHope that helps, let me know if you have any other questions!2", "link": "https://discuss.pennylane.ai//t/single-shot-stochastic-gradient-descent/842/2"}, "2": {"author": "KAJ226", "date": "1613017993615", "content": "Hi @Josh! Thank you so much for the response.\nYes, I understand that you don\u2019t get exact expectation and only in the limit of infinity that you achieve the true expectation here.\nSuppose I have the Pauli term P_1 = XX. Now, to calculate \\langle P_1 \\rangle  with respect to a state |\\psi \\rangle, I would do :\n\\langle \\psi|(H\\otimes H) (Z \\otimes Z) (H\\otimes H) |\\psi \\rangle = \\langle \\psi H\\otimes H| Z\\otimes Z |H\\otimes H \\psi \\rangle \nNow , if I do a measurement/shot on the device, I collapsed my state into either the state |00\\rangle, |01\\rangle, |10\\rangle, or |11\\rangle. If it is |00\\rangle or |11\\rangle, then I record it in the +1 eigenspace. If it is |01\\rangle or |10\\rangle then I record it in the -1 eigenspace. Now, suppose |\\psi\\rangle is in the state |00\\rangle which we know that \\langle \\psi | XX | \\psi \\rangle = 0 . However,  a single shot wouldn\u2019t give us this information since we will just get a +1 or -1. If we had do 1000 shots, then the results will add up close to 0.\nSo to me a single shot is essentially useless as I only retrieve either a +1 or -1\u2026 I guess I am missing something here\u2026 thanks for the response again!", "link": "https://discuss.pennylane.ai//t/single-shot-stochastic-gradient-descent/842/3"}, "3": {"author": "josh", "date": "1613022369291", "content": "It definitely is a bit unintuitive!\nHowever, it is worth noting that this result does not come purely from the quantum mechanics; this is a result that holds in classical settings whenever we use stochastic gradient descent (SGD).\nIn SGD, we typically consider a cost function of the following form:\n\nC(w) = \\frac{1}{N} \\sum_{n=0}^N C_n(w),\n\nwhere we are summing over multiple \u2018observations\u2019 C_i. (Note that this cost function has the same form as computing expectation values of quantum observables!).\nIn typical gradient descent, we perform iterative update steps on the parameters w to minimize the cost function:\n\nw \\rightarrow w - \\eta \\nabla C(w) = w - \\frac{\\eta}{N} \\sum_{n=0}^N \\nabla C_n(w).\n\nHowever, the beauty of stochastic gradient descent is that we can replace the gradient of the cost function with the gradient of a single observation, randomly chosen for each update step, and convergence to a local minimum is still guaranteed (assuming the learning rate \\eta decreases appropriately):\n\nw \\rightarrow w - \\eta \\nabla C_n(w).\n\nThis is a really nice result, especially if the full gradient \\nabla C(w) is expensive to compute.\nIn Stochastic gradient descent for hybrid quantum-classical optimization 1, the authors generalize this result to the quantum case (after noting that C can be interpreted as an expectation value over finite shots, and the stochasticity coming from the process of measuring the quantum system):\nimage779\u00d7348 47.7 KB\n\nSo to me a single shot is essentially useless as I only retrieve either a +1 or \u22121 \u2026 I guess I am missing something here\u2026 thanks for the response again!\n\nSo here, the single shot expectation value is useful in the specific case of quantum gradient descent.\nHowever, convergence will definitely be faster by increasing the shot number! It gives us a nice strategy though; we can begin the minimization process by starting with single shots in order to get a better approximate solution. As our approximation improves, we can increase the number of shots to fine-tune and converge towards the local minimum.\nNote that this doesn\u2019t apply to evaluating the expectation value in a general setting, as you correctly point out. We will need to increase the number of shots to get a better estimation.Solution1", "link": "https://discuss.pennylane.ai//t/single-shot-stochastic-gradient-descent/842/4"}, "4": {"author": "KAJ226", "date": "1613781876979", "content": "@josh Thanks for the explanation!\nIs the term \u201cStochastic\u201d Gradient Descent instead of Gradient Descent being used here is because we use estimate the expectation from our shots counts instead of doing it analytically? So if we have used statevector simulator and able to calculate the gradient exactly, then we would just say that it is Gradient Descent?  I saw Vanilla Gradient Descent and Stochastic Gradient Descent being mentioned a lot\u2026 just want to make sure I understand them correctly. ", "link": "https://discuss.pennylane.ai//t/single-shot-stochastic-gradient-descent/842/5"}, "5": {"author": "nathan", "date": "1613847700181", "content": "Hi @KAJ226,\nThe term stochastic gradient descent is actually borrowed heavily from the classical ML literature. It usually means producing an (unbiased) estimator for the gradient in cases where computing the gradient exactly would be costly.\nIn ML, usually this means taking a minibatch of your training data to build your cost function, instead of using the entire dataset at once.\nIn the quantum case, there are a number of elements that could be stochastic (e.g., noise, finite-shot expectation values, etc). In the case where you use a simulator, then it is not a stochastic estimate, but the exact gradient (up to machine precision).2", "link": "https://discuss.pennylane.ai//t/single-shot-stochastic-gradient-descent/842/6"}, "6": {"author": "josh", "date": "1613014203353", "content": "Hi @KAJ226! When computing expectation values of observables on hardware, we can only sample a finite number of shots NN from the quantum device. For each shot, we are measuring an eigenvalue of the observable, \\lambda\u03bb, so we will get an output vector\n\n\\Lambda = (\\lambda^{(0)}, \\lambda^{(1)}, \\dots, \\lambda^{(N-1)}).\n\u039b=(\u03bb(0),\u03bb(1),\u2026,\u03bb(N\u22121)).\nSo when we compute the expectation value, we are always computing an approximation to the expectation value:\n\n\\langle P_i \\rangle \\approx \\frac{1}{N} \\sum_{n=0}^{N-1} \\Lambda_n.\n\u27e8Pi\u27e9\u22481NN\u22121\u2211n=0\u039bn.\n(This is in fact an unbiased estimator of the expectation value.) For a single shot, we have N=1N=1. So we can interpret a single shot measurement as a 1-shot approximation to the expectation value.\nThis is exactly what happens in PennyLane if we ask for an expectation value with only a single shot:\ndev = qml.device(\"default.qubit\", wires=1, analytic=False, shots=1)\n\n@qml.qnode(dev)\ndef circuit():\n    qml.Hadamard(wires=0)\n    return qml.expval(qml.PauliZ(0)), qml.sample(qml.PauliZ(0))\n\n>>> circuit()\ntensor([1., 1.], requires_grad=True)\n>>> circuit()\ntensor([-1., -1.], requires_grad=True)\n\nHope that helps, let me know if you have any other questions!2", "link": "https://discuss.pennylane.ai//t/single-shot-stochastic-gradient-descent/842/7"}, "7": {"author": "KAJ226", "date": "1613017993615", "content": "Hi @Josh! Thank you so much for the response.\nYes, I understand that you don\u2019t get exact expectation and only in the limit of infinity that you achieve the true expectation here.\nSuppose I have the Pauli term P_1 = XXP1=XX. Now, to calculate \\langle P_1 \\rangle\u27e8P1\u27e9  with respect to a state |\\psi \\rangle|\u03c8\u27e9, I would do :\n\\langle \\psi|(H\\otimes H) (Z \\otimes Z) (H\\otimes H) |\\psi \\rangle = \\langle \\psi H\\otimes H| Z\\otimes Z |H\\otimes H \\psi \\rangle \u27e8\u03c8|(H\u2297H)(Z\u2297Z)(H\u2297H)|\u03c8\u27e9=\u27e8\u03c8H\u2297H|Z\u2297Z|H\u2297H\u03c8\u27e9\nNow , if I do a measurement/shot on the device, I collapsed my state into either the state |00\\rangle, |01\\rangle, |10\\rangle|00\u27e9,|01\u27e9,|10\u27e9, or |11\\rangle|11\u27e9. If it is |00\\rangle|00\u27e9 or |11\\rangle|11\u27e9, then I record it in the +1+1 eigenspace. If it is |01\\rangle|01\u27e9 or |10\\rangle|10\u27e9 then I record it in the -1\u22121 eigenspace. Now, suppose |\\psi\\rangle|\u03c8\u27e9 is in the state |00\\rangle|00\u27e9 which we know that \\langle \\psi | XX | \\psi \\rangle = 0\u27e8\u03c8|XX|\u03c8\u27e9=0 . However,  a single shot wouldn\u2019t give us this information since we will just get a +1+1 or -1\u22121. If we had do 1000 shots, then the results will add up close to 0.\nSo to me a single shot is essentially useless as I only retrieve either a +1+1 or -1\u22121\u2026 I guess I am missing something here\u2026 thanks for the response again!", "link": "https://discuss.pennylane.ai//t/single-shot-stochastic-gradient-descent/842/8"}, "8": {"author": "josh", "date": "1613022369291", "content": "It definitely is a bit unintuitive!\nHowever, it is worth noting that this result does not come purely from the quantum mechanics; this is a result that holds in classical settings whenever we use stochastic gradient descent (SGD).\nIn SGD, we typically consider a cost function of the following form:\n\nC(w) = \\frac{1}{N} \\sum_{n=0}^N C_n(w),\nC(w)=1NN\u2211n=0Cn(w),\nwhere we are summing over multiple \u2018observations\u2019 C_iCi. (Note that this cost function has the same form as computing expectation values of quantum observables!).\nIn typical gradient descent, we perform iterative update steps on the parameters ww to minimize the cost function:\n\nw \\rightarrow w - \\eta \\nabla C(w) = w - \\frac{\\eta}{N} \\sum_{n=0}^N \\nabla C_n(w).\nw\u2192w\u2212\u03b7\u2207C(w)=w\u2212\u03b7NN\u2211n=0\u2207Cn(w).\nHowever, the beauty of stochastic gradient descent is that we can replace the gradient of the cost function with the gradient of a single observation, randomly chosen for each update step, and convergence to a local minimum is still guaranteed (assuming the learning rate \\eta\u03b7 decreases appropriately):\n\nw \\rightarrow w - \\eta \\nabla C_n(w).\nw\u2192w\u2212\u03b7\u2207Cn(w).\nThis is a really nice result, especially if the full gradient \\nabla C(w)\u2207C(w) is expensive to compute.\nIn Stochastic gradient descent for hybrid quantum-classical optimization 1, the authors generalize this result to the quantum case (after noting that CC can be interpreted as an expectation value over finite shots, and the stochasticity coming from the process of measuring the quantum system):\nimage779\u00d7348 47.7 KB\n\nSo to me a single shot is essentially useless as I only retrieve either a +1 or \u22121 \u2026 I guess I am missing something here\u2026 thanks for the response again!\n\nSo here, the single shot expectation value is useful in the specific case of quantum gradient descent.\nHowever, convergence will definitely be faster by increasing the shot number! It gives us a nice strategy though; we can begin the minimization process by starting with single shots in order to get a better approximate solution. As our approximation improves, we can increase the number of shots to fine-tune and converge towards the local minimum.\nNote that this doesn\u2019t apply to evaluating the expectation value in a general setting, as you correctly point out. We will need to increase the number of shots to get a better estimation.Solution1", "link": "https://discuss.pennylane.ai//t/single-shot-stochastic-gradient-descent/842/9"}}