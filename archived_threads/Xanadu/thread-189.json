{"0": {"author": "kushkhosla", "date": "1558811649138", "content": "Hi!\nAs I mentioned in my previous post, I\u2019m trying to write a quantum circuit to learn MNIST classifications. Because images are too large for a quantum circuit, the data is first run through an autoencoder to reduce the dimensionality from 28 * 28 to just one vector of length 10. I then run through a circuit with 10 wires, and use the expectation of each wire as the score for that class. I\u2019ve got it all working, but it\u2019s pretty slow.\nThis is what the circuit, cost and grad code look like. I\u2019ve omitted setup and imports for the sake of brevity, but can post that if it might affect things.\n# x will be a length ENCODING_SIZE vector\n# that represents the encoding of a MNIST image\n# thetas is of size 2 * NUM_QUBITS\n@qml.qnode(dev)\ndef circuit(x, thetas):\n    for i in range(ENCODING_SIZE):\n        RX(x[i], wires=i)\n    for i in range(NUM_QUBITS - 1):\n        CNOT(wires=[i, i+1])\n    for i in range(NUM_QUBITS):\n        RX(thetas[i], wires=i)\n    for i in range(NUM_QUBITS, 2 * NUM_QUBITS):\n        RY(thetas[i], wires=(i - NUM_QUBITS))\n    return tuple(qml.expval.PauliZ(wires=i) for i in range(NUM_QUBITS))\n\n# X is of size (b, 10), actual_labels is size (b,)\n# thetas if of size 2 * NUM_QUBITS.\n# implements cross-entropy classification loss\n# as described here:\n# https://pytorch.org/docs/stable/nn.html#crossentropyloss\n# with numerical stability\ndef cost(X, actual_labels, thetas):\n    b = X.shape[0]\n    yhats = []\n    for i in range(b):\n        yhat = circuit(X[i], thetas)\n        yhats.append(yhat)\n    st = np.stack(yhats)\n    actual_class_vals = st[range(b), actual_labels]\n    shifted = st - np.max(st, axis=1)[:, np.newaxis]\n    the_sum = np.log(np.sum(np.exp(shifted), axis=1))\n    return np.mean(-actual_class_vals + the_sum)\n\n# loaded the data in batches of size 4, so\n# X is of size (4, 10)\nX = encoder(inputs.view(len(labels), -1))\nstart = time.time()\nqml.grad(cost, argnum=2)(X.numpy(), labels.numpy(), thetas)\nprint(time.time() - start)\n\nthis operation takes about 200 seconds (and scales linearly with the size of the batch, so 50 seconds per example). at this speed, it would take a month to do the entire 60000 image dataset. Is there anything I can do to speed this up, or is this just the nature of the implementation and there is not much that can be done about this? the reason I ask is because this is for a class project (CS269Q at Stanford) and we only have about two weeks remaining.\nI have two thoughts so far on why it is slow:\n\nthe cost function is semi complicated so calculating the gradient is quite a hassle. however, I feel like in any classification task it\u2019s going to be like this. should I try to switch to some dataset on which I can perform regression instead?\nthere are too many wires. I could try to reduce the number of wires, but the reason I picked 10 was so each wire could correspond to one of the 10 classes. if I need to reduce the number of wires to say 5, how would I classify after that? I guess I could attach it to a simple matrix multiplication that maps from the 5 wires to the 10 classes, and also learn that 5 x 10 matrix. the only problem is that really increases the number of parameters to learn, which may or may not be a problem. I\u2019m not sure.\n\nany thoughts on this would be very much appreciated. thanks so much!", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/1"}, "1": {"author": "josh", "date": "1558817151655", "content": "Hi @kushkhosla! Thanks for your question.\nCan I ask what simulator/device you are using for your quantum simulation? I would like to run some benchmarking on my side, to work out the best approach/work out where the speed up would be most effective.", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/2"}, "2": {"author": "kushkhosla", "date": "1558819018942", "content": "hi @josh! thanks so much for your help, I really appreciate it.\nI\u2019m just using the standard qml.device(\u2018default.qubit\u2019) simulator. as for actual hardware, I\u2019m on my laptop\u2019s CPU.", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/3"}, "3": {"author": "josh", "date": "1558966536822", "content": "Hi @kushkhosla, before looking at the scaling issue, I decided to try benchmarking the different simulators. I used the following IPython script:\nimport pennylane as qml\nfrom pennylane import numpy as np\n\nENCODING_SIZE = 10\nNUM_QUBITS = 10\n\ndef circuit(x, thetas):\n    for i in range(ENCODING_SIZE):\n        qml.RX(x[i], wires=i)\n    for i in range(NUM_QUBITS - 1):\n        qml.CNOT(wires=[i, i + 1])\n    for i in range(NUM_QUBITS):\n        qml.RX(thetas[i], wires=i)\n    for i in range(NUM_QUBITS, 2 * NUM_QUBITS):\n        qml.RY(thetas[i], wires=(i - NUM_QUBITS))\n    return tuple(qml.expval.PauliZ(wires=i) for i in range(NUM_QUBITS))\n\n\nx = np.random.random([ENCODING_SIZE])\nthetas = np.random.random(2 * NUM_QUBITS)\n\ndevices = [\n    qml.device(\"default.qubit\", wires=NUM_QUBITS),\n    qml.device(\"forest.numpy_wavefunction\", wires=NUM_QUBITS),\n    qml.device(\"forest.wavefunction\", wires=NUM_QUBITS),\n    qml.device(\"forest.qvm\", device=\"{}q-qvm\".format(NUM_QUBITS)),\n    qml.device(\"forest.qvm\", device=\"{}q-pyqvm\".format(NUM_QUBITS)),\n    qml.device(\"qiskit.basicaer\", wires=NUM_QUBITS),\n    qml.device(\"qiskit.aer\", wires=NUM_QUBITS),\n    qml.device(\"projectq.simulator\", wires=NUM_QUBITS),\n    # qml.device(\"microsoft.QubitSimulator\", wires=NUM_QUBITS),\n]\n\nprint(\"Encoding size: {}\".format(ENCODING_SIZE))\nprint(\"Number of qubits: {}\".format(NUM_QUBITS))\n\nfor dev in devices:\n    print(\"\\nDevice: {}\".format(dev.name))\n    qnode = qml.QNode(circuit, dev)\n    %timeit qnode(x, thetas)\n\nRunning this script with ipython timing.ipy, gives the following results:\nEncoding size: 10\nNumber of qubits: 10\n\nDevice: Default qubit PennyLane plugin\n2.35 s \u00b1 236 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nDevice: pyQVM NumpyWavefunction Simulator Device\n293 ms \u00b1 36.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nDevice: Forest Wavefunction Simulator Device\n350 ms \u00b1 65.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nDevice: Forest QVM Device (10q-qvm, 1024 shots)\n5.6 s \u00b1 92.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nDevice: Forest pyQVM Device (10q-pyqvm, 1024 shots)\n6.71 ms \u00b1 245 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n\nDevice: Qiskit Basic Aer (1024 shots)\n179 ms \u00b1 4.95 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nDevice: Qiskit Aer (1024 shots)\n162 ms \u00b1 5.18 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n\nDevice: ProjectQ PennyLane plugin (1024 shots)\n60.5 ms \u00b1 26.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n\n(NB: I modified the print statement above to give more device information. The devices that specify shots are hardware simulators, so increasing the number of shots increases accuracy, but also increases runtime.)\nA couple of things to note:\n\n\nThe default.qubit device is quite slow. This is not intentional, but at the same time, the default.qubit device is not meant for production code \u2014 it is a reference plugin designed to show developers how a PennyLane plugin is coded.\n\n\nWe recommend instead that you use a plugin for an external high-performance qubit simulator. From the rough benchmarking above, it appears that for 10 qubits, the Rigetti Forest pyQVM simulator destroys the competition  So you should see some significant improvements using\n qml.device(\"forest.qvm\", device=\"{}q-pyqvm\".format(NUM_QUBITS), shots=1024)\n\nAlternatively, you can use the NumPy wavefunction simulator for exact expectation values:\n qml.device(\"forest.numpy_wavefunction\", wires=NUM_QUBITS)\n\nBoth of these devices can be installed via\n git clone https://github.com/rigetti/pennylane-forest\n cd pennylane-forest\n pip install -e .\n\n\n\n\nIn terms of the scaling, note that the above times t are for a single circuit evaluation. To determine the gradient for M free parameters, PennyLane must query the quantum device 2M times; so the expected time taken per optimization step should be \\sim 2Mt.\nFor more details on why this is the case, see @nathan\u2019s great answer here:\n\n\n\n\nCost functions: Multiple wire measurements + backends for Hermitians PennyLane Help\n\n\n    Hi mxn.wls, \n\n\nYes, the runtime scales linearly. If you want to evaluate the same circuit, but with a different final measurement setting, the entire circuit is reevaluated. This is because PennyLane is hardware-based, and this is a constraint you have on real hardware. Saying this, we do realize that there are efficiency gains that could be had using simulators, e.g., caching the state right before measurement and re-using that. \n\n\nNot sure I follow here, unfortunately, but I\u2019ll give a shot to \u2026\n  \n\n\nNote that we are working on alleviating the optimization runtime scaling! This will likely be through a combination of:\n\n\nExtending PennyLane to perform the gradient computations for each parameter in parallel, and\n\n\nImplementing efficiency gains that can be achieved assuming the underlying device is a simulator (and not hardware).\n\n4 Replies2", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/4"}, "4": {"author": "kushkhosla", "date": "1559018931860", "content": "@josh, thank you so much for the suggestion and work you put into this. we took your advice, and performance sped up by a factor of about 200. we are now able to train in a reasonable amount of time, and only have to work on the circuit architecture.\nagain, thanks so much!", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/5"}, "5": {"author": "kareem_essafty", "date": "1559328786719", "content": "@josh\ncan you please tell the version of each lib?", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/6"}, "6": {"author": "josh", "date": "1559329761536", "content": "Certainly.\n\n\nPennyLane: latest master version.\n\n\nAll PennyLane plugins: I am running the latest master version.\n\n\npyQuil: 2.7\n\n\nQiskit: 0.10.1\n\n\nQiskit-aer: 0.2.0\n\n\nProjectQ: 0.4.1\n\n\nQ#: 0.5.1904.1302\n\n\nQVM: 1.8.2 [94d402b]\n\n\nQuilc: 1.8.2 [85e2290]\n\n", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/7"}, "7": {"author": "kareem_essafty", "date": "1559330129031", "content": "there must be something in my environment that causes the pauliZ to produce an error ", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/8"}, "8": {"author": "mxn.wls", "date": "1561758008589", "content": "On this is there any way to get some performance gains here?\nI\u2019m running pyqvm & currently using a 2^N x 2^N hermitian cost operator. I was working with several different circuits (as I had \u2018collisions\u2019 between variables) so had to initialize 2 circuits for the hamitlonian H = z1 + z1z2, however this scales with the number of collisions. If we move to a hermitian cost operator though we get this exponential slowdown in the computation, is there something going on with the plugin?\nThanks for any help! Example below.\n(This code runs  ~1000x slower than measuring the expectations in the commented out return.)\nimport pennylane as qml\nfrom pennylane import numpy as np\nfrom homegrown.timing.utils import time_it\n\nENCODING_SIZE = 10\nNUM_QUBITS = 10\n\n\n# loop over problem\n\ndef circuit(x, thetas):\n    for i in range(ENCODING_SIZE):\n        qml.RX(x[i], wires=i)\n    for i in range(NUM_QUBITS - 1):\n        qml.CNOT(wires=[i, i + 1])\n    for i in range(NUM_QUBITS):\n        qml.RX(thetas[i], wires=i)\n    for i in range(NUM_QUBITS, 2 * NUM_QUBITS):\n        qml.RY(thetas[i], wires=(i - NUM_QUBITS))\n    # return tuple(qml.expval.PauliZ(wires=i) for i in range(NUM_QUBITS))\n    wires = list(range(NUM_QUBITS))\n    observable = np.zeros((2**NUM_QUBITS, 2**NUM_QUBITS)).astype(np.float32)\n    return qml.expval.Hermitian(observable, wires=wires)\n\nx = np.random.random([ENCODING_SIZE])\nthetas = np.random.random(2 * NUM_QUBITS)\n\ndevices = [\n    # qml.device(\"default.qubit\", wires=NUM_QUBITS),\n    # qml.device(\"forest.numpy_wavefunction\", wires=NUM_QUBITS),\n    # qml.device(\"forest.wavefunction\", wires=NUM_QUBITS),\n    # qml.device(\"forest.qvm\", device=\"{}q-qvm\".format(NUM_QUBITS)),\n    qml.device(\"forest.qvm\", device=\"{}q-pyqvm\".format(NUM_QUBITS)),\n    # qml.device(\"qiskit.basicaer\", wires=NUM_QUBITS),\n    # qml.device(\"qiskit.aer\", wires=NUM_QUBITS),\n    # qml.device(\"projectq.simulator\", wires=NUM_QUBITS),\n    # qml.device(\"microsoft.QubitSimulator\", wires=NUM_QUBITS),\n]\n\nprint(\"Encoding size: {}\".format(ENCODING_SIZE))\nprint(\"Number of qubits: {}\".format(NUM_QUBITS))\n\nfor dev in devices:\n    print(\"\\nDevice: {}\".format(dev.name))\n    qnode = time_it(qml.QNode(circuit, dev))\n    qnode(x, thetas)", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/9"}, "9": {"author": "mxn.wls", "date": "1561758158813", "content": "It\u2019d be just super grand if we could hack the state out of the pyqvm simulation and work with that instead?", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/10"}, "10": {"author": "mxn.wls", "date": "1561762368995", "content": "\ntime_compare800\u00d7600 40.5 KB\n\nthis is eval times for the same circuit, using 2 different methods of exp val evaluation (a)\u2018piecewise\u2019 and \u2018entire Hamiltonian\u2019 for a) when the exp vals are divided into smaller chunks and b) aggregated into a single Hermitian matrix).\nThere are the cost evals on there and then the gradient computation for the entire hermitian matrix goes nuts.\nThe piecewise gradient computation circuits seem to scale as expected 2MN.\nEach circuit has around 6 params.\nby \u2018gradient\u2019 I mean a computation which calls an optimizer for 1 step.", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/11"}, "11": {"author": "nathan", "date": "1561766795066", "content": "Hi @mxn.wls,\nI don\u2019t have the codebase in front of me at the moment, but if I had to guess, it might be that there is a dense matrix multiplication somewhere in the plugin code whose complexity blows up as you increase number of qubits.\nYou could maybe try the latest version of PL (0.4) and use the default.qubit simulator. Not 100% it may solve your problem, but we did recently make some improvements there which significantly speed up the Hermitian expval.2 Replies2", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/12"}, "12": {"author": "mxn.wls", "date": "1561826315990", "content": "This seems very slow, could you explain a little how the simulation works?\ni.e. if I simulate a 2^10 state vector and 100 unitary operations exactly in numpy this takes 0.04 seconds. As far as I understand the gradient computations require 2 new circuits for each parameter. So let\u2019s call gradient + classical processing ~1s (generously), where is all the overhead coming from?\nEven if I simulate the whole probability density matrix instead of the statevector (100 operations, 8 qubits) I get <0.07s circuit evals, so should be getting <1s (roughly) circuit + gradient evals at 8 qubits, whereas the piecewise eval is O(10s). Actually thinking about it this makes sense (kind of) because the in the piecewise implementation number of circuits scales with the number of \u2018common\u2019 variables\u2026 so am I right in saying the simulator uses the whole density matrix?", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/13"}, "13": {"author": "mxn.wls", "date": "1561826738918", "content": "Thanks for the tip I\u2019ll give it a try (will have to be Monday) and let you know.", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/14"}, "14": {"author": "mxn.wls", "date": "1561995074742", "content": "Hey, so the forest wavefunction simulator is particularly bad & there is clearly something going on (details below), but I\u2019m still not understanding the circuit run times for the other simulators, 10s seems like a lot for 8 qubits (even with grad computations). What do you think?\nExample\nimport pennylane as qml\nfrom pennylane import numpy as np\nNUM_QUBITS = 8\n\ndef circuit(thetas):\nfor i in range(NUM_QUBITS):\n    qml.RX(thetas[i], wires=i)\nfor i in range(NUM_QUBITS - 1):\n    qml.CNOT(wires=[i, i + 1])\nfor i in range(NUM_QUBITS):\n    qml.RX(thetas[i], wires=i)\nfor i in range(NUM_QUBITS, 2 * NUM_QUBITS):\n    qml.RY(thetas[i], wires=(i - NUM_QUBITS))\nobservable = np.zeros((2**NUM_QUBITS, 2**NUM_QUBITS))\nwires = list(range(NUM_QUBITS))\nreturn qml.expval.Hermitian(observable, wires=wires)\n\nx = np.random.random([NUM_QUBITS])\n\ndevices = [\nqml.device(\"default.qubit\", wires=NUM_QUBITS),\nqml.device(\"forest.numpy_wavefunction\", wires=NUM_QUBITS),\nqml.device(\"forest.wavefunction\", wires=NUM_QUBITS),\nqml.device(\"forest.qvm\", device=\"{}q-qvm\".format(NUM_QUBITS)),\nqml.device(\"forest.qvm\", device=\"{}q-pyqvm\".format(NUM_QUBITS)),\n]\n\nprint(\"Encoding size: {}\".format(NUM_QUBITS))\nprint(\"Number of qubits: {}\".format(NUM_QUBITS))\n\nfrom time import time\n\nfor dev in devices:\nprint(\"\\nDevice: {}\".format(dev.name))\nt0 = time()\nopt = qml.AdamOptimizer(stepsize=0.1)\nqnode = qml.QNode(circuit, dev)\nthetas = np.random.random(2 * NUM_QUBITS)\nthetas = opt.step(qnode, thetas)\nprint('Time: ', (time() - t0))\n\nOutput\nDevice: Default qubit PennyLane plugin\nTime:  10.741438150405884\nDevice: pyQVM NumpyWavefunction Simulator Device\nTime:  10.3768470287323\nDevice: Forest Wavefunction Simulator Device\nTime:  12.075280666351318\nDevice: Forest QVM Device\nTime:  112.82866406440735\nDevice: Forest QVM Device\nTime:  20.80642604827881", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/15"}, "15": {"author": "josh", "date": "1561996067408", "content": "Hi @mxn.wls,\nThe results look to be expected, once the number of parameters are taken into account. For example, consider the following modification to the script, which times both a single QNode evaluation, as well as an optimization step:\nfrom time import time\nimport pennylane as qml\nfrom pennylane import numpy as np\n\nNUM_QUBITS = 8\n\ndef circuit(thetas):\n    for i in range(NUM_QUBITS):\n        qml.RX(thetas[i], wires=i)\n    for i in range(NUM_QUBITS - 1):\n        qml.CNOT(wires=[i, i + 1])\n    for i in range(NUM_QUBITS):\n        qml.RX(thetas[i], wires=i)\n    for i in range(NUM_QUBITS, 2 * NUM_QUBITS):\n        qml.RY(thetas[i], wires=(i - NUM_QUBITS))\n    observable = np.zeros((2**NUM_QUBITS, 2**NUM_QUBITS))\n    wires = list(range(NUM_QUBITS))\n    return qml.expval(qml.Hermitian(observable, wires=wires))\n\nx = np.random.random([NUM_QUBITS])\n\ndevices = [\nqml.device(\"default.qubit\", wires=NUM_QUBITS),\nqml.device(\"forest.numpy_wavefunction\", wires=NUM_QUBITS),\nqml.device(\"forest.wavefunction\", wires=NUM_QUBITS),\nqml.device(\"forest.qvm\", device=\"{}q-qvm\".format(NUM_QUBITS)),\nqml.device(\"forest.qvm\", device=\"{}q-pyqvm\".format(NUM_QUBITS)),\n]\n\nthetas = np.random.random(2 * NUM_QUBITS)\n\nprint(\"Encoding size: {}\".format(NUM_QUBITS))\nprint(\"Number of qubits: {}\".format(NUM_QUBITS))\nprint(\"Number of parameters:\", len(thetas))\n\nfor dev in devices:\n    print(\"\\nDevice: {}\".format(dev.name))\n    qnode = qml.QNode(circuit, dev)\n\n    t0 = time()\n    qnode(thetas)\n    t1 = time()\n\n    print(\"Forward pass:\", t1-t0)\n\n    opt = qml.AdamOptimizer(stepsize=0.1)\n\n    t0 = time()\n    thetas = opt.step(qnode, thetas)\n    t1 = time()\n\n    print('Backwards pass: ', (t1 - t0))\n\nFor me, this gives the following result:\nEncoding size: 8\nNumber of qubits: 8\nNumber of parameters: 16\n\nDevice: Default qubit PennyLane plugin\n\nForward pass: 0.5093185901641846\nBackwards pass:  18.87824559211731\n\n(timings will vary depending on CPU/memory).\nSince PennyLane treats all devices as hardware devices, a single optimization step using a gradient-based optimizer requires (at minimum) 2 circuit evaluations per parameter. In this case, with 16 parameters, a single gradient descent step should take\n\\sim 2\\times 16\\times 0.5s \\approx 16 s\nwhich is approximately what we see above.\nThere are a couple of things we are working on to speed up this process:\n\n\nMake default.qubit more efficient (recent work has resulted in a \\sim 2 orders of magnitude improvement in default.qubit).\nOne improvement has been the move away from dense matrix multiplication, to using np.tensordot for matrix-vector multiplication. Currently, forest.wavefunction continues to use dense matrix multiplication for qml.Hermitian, hence the exponential growth in your plot above.\n\n\nParallelize the gradient computations. Since the gradient of each parameter is independently computed, this could be done in parallel, scaling with the number of cores available on the system. This is a bit difficult due to Python, however.\n\n\nProvide a plugin device that can natively perform backpropagation through the quantum simulation, without requiring multiple quantum evaluations. For example, a simulator coded using TensorFlow or PyTorch.\n\n", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/16"}, "16": {"author": "josh", "date": "1561996328238", "content": "Note: playing around with the timing script above, I can verify that the size of the observable passed to qml.Hermitian significantly affects the speed of the simulation.\nPerhaps the faster path to improvement is rewriting how qml.Hermitian is handled in the default.qubit simulator, in order to chase down any inefficiencies.", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/17"}, "17": {"author": "mxn.wls", "date": "1561996887884", "content": "Thanks for the detailed response.\nOn (1.) above you say that the problem comes from the forest.wavefunction simulator continues to use dense matrix multiplication.\n\nDoes the same problem apply to the pyqvm?\nIs this something on the pennylane plugin side or the forest side?\n\nI ask because the pyqvm simulator is usually very fast, whereas the other simulators scale badly.\n(ex)\nimport pennylane as qml\nfrom pennylane import numpy as np\nNUM_QUBITS = 12\ndef circuit(thetas):\n    for i in range(NUM_QUBITS):\n        qml.RX(thetas[i], wires=i)\n    for i in range(NUM_QUBITS - 1):\n        qml.CNOT(wires=[i,&#32;i&#32;+&#32;1])\n    for i in range(NUM_QUBITS):\n        qml.RX(thetas[i], wires=i)\n    for i in range(NUM_QUBITS, 2 * NUM_QUBITS):\n        qml.RY(thetas[i], wires=(i - NUM_QUBITS))\n    observable = np.zeros((2NUM_QUBITS, 2NUM_QUBITS))\n    wires = list(range(NUM_QUBITS))\n    # return qml.expval.Hermitian(observable, wires=wires)\n    return [qml.expval.PauliZ(wires=[i]) for i in range(NUM_QUBITS)]\nx = np.random.random([NUM_QUBITS])\ndevices = [\n    qml.device(\u201cdefault.qubit\u201d, wires=NUM_QUBITS),\n    qml.device(\u201cforest.numpy_wavefunction\u201d, wires=NUM_QUBITS),\n    qml.device(\u201cforest.wavefunction\u201d, wires=NUM_QUBITS),\n    qml.device(\u201cforest.qvm\u201d, device=\"{}q-qvm\".format(NUM_QUBITS)),\n    qml.device(\u201cforest.qvm\u201d, device=\"{}q-pyqvm\".format(NUM_QUBITS)),\n]\nprint(\u201cEncoding size: {}\u201d.format(NUM_QUBITS))\nprint(\u201cNumber of qubits: {}\u201d.format(NUM_QUBITS))\nfrom time import time\nfor dev in devices:\n    print(\"\\nDevice: {}\".format(dev.name))\n    qnode = qml.QNode(circuit, dev)\n    thetas = np.random.random(2 * NUM_QUBITS)\n    # t0 = time()\n    # opt = qml.AdamOptimizer(stepsize=0.1)\n    # thetas = opt.step(qnode, thetas)\n    # print('Time gradients: ', (time() - t0))\n    t0 = time()\n    qnode(thetas)\n    print('Time cost: ', (time() - t0))\nout\nDevice: Default qubit PennyLane plugin\nTime cost:  6.934019327163696\nDevice: pyQVM NumpyWavefunction Simulator Device\nTime cost:  6.896592617034912\nDevice: Forest Wavefunction Simulator Device\nTime cost:  6.934622526168823\nDevice: Forest QVM Device\nTime cost:  14.904531717300415\nDevice: Forest QVM Device\nTime cost:  0.006373643875122071 Reply", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/18"}, "18": {"author": "josh", "date": "1561998725805", "content": "\n\n\n mxn.wls:\n\nOn (1.) above you say that the problem comes from the forest.wavefunction simulator continues to use dense matrix multiplication.\n\nDoes the same problem apply to the pyqvm?\nIs this something on the pennylane plugin side or the forest side?\n\nI ask because the pyqvm simulator is usually very fast, whereas the other simulators scale badly.\n\n\nSince the pyQVM is a hardware simulator, it doesn\u2019t provide access to the wavefunction, just output samples. So no dense matrix multiplication needs to take place.\nOn the other hand, due to sampling the accuracy of the pyQVM will not be exact, like forest.wavefunction or default.qubit. Instead, as you increase the number of shots, you will start to approach the exact expectation value.2 Replies", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/19"}, "19": {"author": "mxn.wls", "date": "1562001488080", "content": "Ok, so the problem won\u2019t be with the dense matrix multiplication which is good. It looks like the issue is just with how the pyqvm handles the \u2018hermitian\u2019 observables, where do you think the issue is here? (i.e. the crazy scaling of the pyqvm when using the hermitian operator)1 Reply", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/20"}, "20": {"author": "josh", "date": "1561996067408", "content": "Hi @mxn.wls,\nThe results look to be expected, once the number of parameters are taken into account. For example, consider the following modification to the script, which times both a single QNode evaluation, as well as an optimization step:\nfrom time import time\nimport pennylane as qml\nfrom pennylane import numpy as np\n\nNUM_QUBITS = 8\n\ndef circuit(thetas):\n    for i in range(NUM_QUBITS):\n        qml.RX(thetas[i], wires=i)\n    for i in range(NUM_QUBITS - 1):\n        qml.CNOT(wires=[i, i + 1])\n    for i in range(NUM_QUBITS):\n        qml.RX(thetas[i], wires=i)\n    for i in range(NUM_QUBITS, 2 * NUM_QUBITS):\n        qml.RY(thetas[i], wires=(i - NUM_QUBITS))\n    observable = np.zeros((2**NUM_QUBITS, 2**NUM_QUBITS))\n    wires = list(range(NUM_QUBITS))\n    return qml.expval(qml.Hermitian(observable, wires=wires))\n\nx = np.random.random([NUM_QUBITS])\n\ndevices = [\nqml.device(\"default.qubit\", wires=NUM_QUBITS),\nqml.device(\"forest.numpy_wavefunction\", wires=NUM_QUBITS),\nqml.device(\"forest.wavefunction\", wires=NUM_QUBITS),\nqml.device(\"forest.qvm\", device=\"{}q-qvm\".format(NUM_QUBITS)),\nqml.device(\"forest.qvm\", device=\"{}q-pyqvm\".format(NUM_QUBITS)),\n]\n\nthetas = np.random.random(2 * NUM_QUBITS)\n\nprint(\"Encoding size: {}\".format(NUM_QUBITS))\nprint(\"Number of qubits: {}\".format(NUM_QUBITS))\nprint(\"Number of parameters:\", len(thetas))\n\nfor dev in devices:\n    print(\"\\nDevice: {}\".format(dev.name))\n    qnode = qml.QNode(circuit, dev)\n\n    t0 = time()\n    qnode(thetas)\n    t1 = time()\n\n    print(\"Forward pass:\", t1-t0)\n\n    opt = qml.AdamOptimizer(stepsize=0.1)\n\n    t0 = time()\n    thetas = opt.step(qnode, thetas)\n    t1 = time()\n\n    print('Backwards pass: ', (t1 - t0))\n\nFor me, this gives the following result:\nEncoding size: 8\nNumber of qubits: 8\nNumber of parameters: 16\n\nDevice: Default qubit PennyLane plugin\n\nForward pass: 0.5093185901641846\nBackwards pass:  18.87824559211731\n\n(timings will vary depending on CPU/memory).\nSince PennyLane treats all devices as hardware devices, a single optimization step using a gradient-based optimizer requires (at minimum) 2 circuit evaluations per parameter. In this case, with 16 parameters, a single gradient descent step should take\n\\sim 2\\times 16\\times 0.5s \\approx 16 s\u223c2\u00d716\u00d70.5s\u224816s\nwhich is approximately what we see above.\nThere are a couple of things we are working on to speed up this process:\n\n\nMake default.qubit more efficient (recent work has resulted in a \\sim\u223c 2 orders of magnitude improvement in default.qubit).\nOne improvement has been the move away from dense matrix multiplication, to using np.tensordot for matrix-vector multiplication. Currently, forest.wavefunction continues to use dense matrix multiplication for qml.Hermitian, hence the exponential growth in your plot above.\n\n\nParallelize the gradient computations. Since the gradient of each parameter is independently computed, this could be done in parallel, scaling with the number of cores available on the system. This is a bit difficult due to Python, however.\n\n\nProvide a plugin device that can natively perform backpropagation through the quantum simulation, without requiring multiple quantum evaluations. For example, a simulator coded using TensorFlow or PyTorch.\n\n", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/21"}, "21": {"author": "mxn.wls", "date": "1562022276999", "content": "Also, is it 2 new circuits per parameter if that parameter only corresponds to one gate? If it isn\u2019t, then that means it scales as 2*number of gates with parameters (applying the parameter shift rule to all gates containing that parameter then applying the product rule)", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/22"}, "22": {"author": "josh", "date": "1562053246364", "content": "\n\n\n mxn.wls:\n\nIt looks like the issue is just with how the pyqvm handles the \u2018hermitian\u2019 observables, where do you think the issue is here?\n\n\nAh, that might be the key. In order to perform arbitrary measurements of Hermitian observable AA on a hardware device, this is the process that needs to be undertaken:\n\n\nCalculate the unitary matrix UU, comprised of the orthonormal eigenvectors of AA down the columns.\n\n\nApply the unitary U^\\daggerU\u2020 to the quantum state |\\psi\\rangle|\u03c8\u27e9, just prior to measurement.\n\n\nFrom the resulting Pauli-Z measurement samples, calculate the probability of measuring each computational basis state |\\langle i | U^\\dagger |\\psi\\rangle|^2|\u27e8i|U\u2020|\u03c8\u27e9|2.\n\n\nThe resulting expectation value is given by:\n\\langle \\psi | A | \\psi \\rangle = \\sum_i \\lambda_i |\\langle i | U^\\dagger |\\psi\\rangle|^2\u27e8\u03c8|A|\u03c8\u27e9=\u2211i\u03bbi|\u27e8i|U\u2020|\u03c8\u27e9|2\nwhere \\lambda_i\u03bbi are the eigenvalues of AA.\n\n", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/23"}, "23": {"author": "mxn.wls", "date": "1562099967035", "content": "So some of the problem comes from the number of gates. Though the number of parameters is O(10) the number of gates using these parameters is O(100).\nThe exponential issue with the pyqvm is less obvious to me. Maybe it comes from computing U^(dag)? I appreciate the description above but can\u2019t immediately see why it would slow down the computation so much.1 Reply", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/24"}, "24": {"author": "mxn.wls", "date": "1562117838429", "content": "\ntiming800\u00d7600 62.3 KB\n\ndefault is default.qubit\npyqvm is forest.qvm\nentire is evaluating the whole hamiltonian\npiecewise is splitting into pieces and evaluating different circuits for \u2018collisions\u2019 between expectations/variables\nI also parallelized and wrote my own gradient computation, given the large overhead of the number of gates, so these speeds will be v machine dependent. I still think there is something funny going on with the arbitrary hermitian evals in the pyqvm so will be interested to hear what you guys come out with. Thx for all the info so far1 Reply", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/25"}, "25": {"author": "josh", "date": "1562131749754", "content": "\n\n\n mxn.wls:\n\nMaybe it comes from computing U^(dag)\n\n\nThis is my thought as well, however the scaling of np.linalg.eigh would need to be investigated to see if this is in fact the cause. Another reason could be how PyQuil implements arbitrary unitaries \u2014 whether it\u2019s via direct matrix multiplication, or whether they decompose the unitary first (which might have some cost associated with it).\n\n\n\n mxn.wls:\n\nThx for all the info so far\n\n\nThe plots look great! We are always looking to speed up the optimization and work on the performance of PennyLane, so if you have noticed anything while writing your own parallelized gradient computation, please feel free to submit a PR to the PennyLane GitHub repository ", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/26"}, "26": {"author": "soudy", "date": "1571655775750", "content": "I\u2019ve encountered the same issue while training a QNN with high-dimensional state vectors. In an attempt to speed it up, I implemented a PennyLane device for Qulacs 4. It\u2019s more than 2 times faster than the default PennyLane plugin (which was the fastest before from my experiments):\nEncoding size: 10\nNumber of qubits: 10\n\nDevice: Default qubit PennyLane plugin\n6.89 ms \u00b1 233 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n\nDevice: pyQVM NumpyWavefunction Simulator Device\n437 ms \u00b1 10 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nDevice: Qiskit PennyLane plugin\n232 ms \u00b1 9.44 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nDevice: Qiskit PennyLane plugin\n217 ms \u00b1 3.09 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nDevice: ProjectQ PennyLane plugin\n10.2 ms \u00b1 134 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n\nDevice: Qulacs device\n2.49 ms \u00b1 27.6 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n\n(I don\u2019t have QVM installed at the moment)\nI put it on GitHub for others to use: https://github.com/soudy/pennylane-qulacs/ 14. Note that it is still a very basic implementation tailored to my needs, but it can easily be expanded.1", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/27"}, "27": {"author": "josh", "date": "1571666875741", "content": "That is awesome, @soudy! Is the Qulacs plugin something you would consider open-sourcing? We could also link to it on https://pennylane.ai/plugins.html 9", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/28"}, "28": {"author": "soudy", "date": "1571668101511", "content": "Definitely, see my edit. So far only basic gates and expectation value of Paulis and arbitrary Hermitians are implemented. Maybe in the near future I\u2019ll find some time to expand it, or  someone else will so you can link to it.\nI do think it\u2019s a good first contender for a simple, faster back-end. Qulacs also has GPU and OpenMP support which I haven\u2019t explored yet, so it could even give a larger speedup.1", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/29"}, "29": {"author": "soudy", "date": "1573552980142", "content": "Further update: I did some benchmarks comparing CPU and GPU with the Qulacs plugin:\n\n\n(tested on Intel Xeon Gold 5118 CPUs and an NVIDIA TITAN RTX GPU)\nThe testing script I used if you want to compare with other devices:\nimport time\nimport sys\nimport torch\nimport numpy as np\nimport pennylane as qml\n\ndevice = torch.device('cuda:0')\n\ntorch.tensor([1, 2], device=device)\n\nqubits = range(2, 26)\n\nREPEATS = 50\nN_LAYERS = 8\n\nnp.random.seed(23326)\n\nfor n in qubits:\n    VAR = 0.01 * np.random.randn(N_LAYERS, n, 3)\n\n    def layer(w):\n        for i in range(n):\n            qml.Rot(w[i, 0], w[i, 1], w[i, 2], wires=i)\n\n        for i in range(n-1):\n            qml.CNOT(wires=[i, i+1])\n\n        qml.CNOT(wires=[n-1, 0])\n\n\n    # =============== Qulacs GPU\n    dev = qml.device('qulacs.simulator', gpu=True, wires=n)\n\n\n    @qml.qnode(dev)\n    def circuit(weights):\n        for w in weights:\n            layer(w)\n\n        return qml.expval(qml.PauliZ(0))\n\n\n    time_start = time.time()\n    vals = []\n    for i in range(REPEATS):\n        val = circuit(VAR)\n        vals.append(val)\n\n    time_end = time.time()\n    gpu_duration = time_end - time_start\n    print(f'Qulacs GPU {n} qubits took {gpu_duration}s')\n\n    gpu_average = np.sum(vals) / len(vals)\n\n    # =============== Qulacs CPU\n    dev2 = qml.device('qulacs.simulator', wires=n)\n\n    @qml.qnode(dev2)\n    def qulacs_circuit(weights):\n        for w in weights:\n            layer(w)\n\n        return qml.expval(qml.PauliZ(0))\n\n\n    time_start = time.time()\n    vals = []\n    for i in range(REPEATS):\n        val = qulacs_circuit(VAR)\n        vals.append(val)\n\n    time_end = time.time()\n    cpu_duration = time_end - time_start\n    print(f'Qulacs CPU {n} qubits took {cpu_duration}s')\n\n    cpu_average = np.sum(vals) / len(vals)\n\n    assert np.allclose(gpu_average, cpu_average), 'GPU and CPU results dont agree'\n\nNote that due to some weird bug with Qulacs, the torch.tensor call is needed to make it recognize the GPU (CUDA error without loading something into GPU memory first \u00b7 Issue #195 \u00b7 qulacs/qulacs \u00b7 GitHub 3). So the GPU scales nicely for higher number of qubits, while single-core is best for 12 qubits and fewer.", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/30"}, "30": {"author": "nathan", "date": "1573745264252", "content": "Thanks for sharing the benchmarks @soudy!\nNote that we\u2019ve been having some issues with the discourse server lately, so some of the uploaded images are no longer available ", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/31"}, "31": {"author": "ycchen1989", "date": "1574990827161", "content": "Will this setup also be effective when I switch the interface to torch?", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/32"}, "32": {"author": "nathan", "date": "1575069878485", "content": "Hi @ycchen1989, yes it should be relatively similar between the default interface and the torch interface (most bottlenecks are in the simulation of the quantum circuits and computation of gradients).\nAlso note that in the latest version of pennylane, we\u2019ve added an experimental device expt.tensornet.tf which should provide faster gradient computation and training than the default plugin for most cases.1", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/33"}, "33": {"author": "quantshah", "date": "1651773153287", "content": "Hi, continuing on this thread I have some benchmarks regarding gradient computation comparing JIT vs no JIT (in Jax). Using backprop we get gradients faster ~3 orders of magnitude. Using a finite number of shots, with or without JIT, its quite a bit slower:\nJIT True     | shots None   | time taken  5.002456e-05\nJIT False   | shots None    | time taken  2.144583e-02\nJIT True     | shots 500      | time taken  7.670196e-02\nJIT False   | shots 500       | time taken  7.490716e-02\nHere is the code snippet. I hope this helps to get a clear picture and for some of the future benchmarking:\nimport pennylane as qml\n\n\nimport jax\nimport jax.numpy as jnp\nfrom jax import config\n\nconfig.update(\"jax_enable_x64\", True)\n\n\nimport time\n\n\ndef timeit(func, params):\n    \"\"\"Time the function.\n\n    Args:\n        func (Callable): A function to call.\n        params (array): The inputs to the function.\n\n    Returns:\n        float: The time taken to run the function.\n    \"\"\"\n    tic = time.perf_counter()\n    func(params)\n    toc = time.perf_counter()\n    return toc - tic\n\n\nN = 5\nvariational_ansatz = qml.BasicEntanglerLayers\nn_layers = 5\n\n\ndef get_grad_fn(shots=None, diff_method='best', jit=True):\n    \"\"\"Get the gradient function with a combination of shots, diff_method and JIT\n\n    Args:\n        shots (int, optional): Number of shots. Defaults to None.\n        diff_method (str, optional): The method to use for gradient computation.\n                                     Defaults to 'best'.\n        jit (bool, optional): Should the gradient function be JIT compiled.\n                              Defaults to True.\n\n    Returns:\n        Callable: A callable function that computes gradients\n    \"\"\"\n    dev = qml.device(\"default.qubit.jax\", wires=N, shots=shots)\n    variational_ansatz = qml.BasicEntanglerLayers\n\n    @jax.jit\n    @qml.qnode(dev, interface=\"jax\", diff_method=diff_method)\n    def circuit(params: jnp.array):\n        \"\"\"Variational circuit that we want to optimize\n\n        Args:\n            params (jnp.array): _description_\n\n        Returns:\n            float: Expecatation value\n        \"\"\"\n        variational_ansatz(params, wires=range(N))\n        return qml.expval(qml.PauliZ(0))\n\n    grad_x = jax.grad(circuit)\n\n    if jit:\n        return jax.jit(grad_x)\n    else:\n        return grad_x\n\n\nfor shots in [None, 500]:\n    for jit in [True, False]:\n        grad_x = get_grad_fn(shots=shots, jit=jit)\n\n        key = jax.random.PRNGKey(42)\n        x = jax.random.uniform(key, variational_ansatz.shape(n_layers=n_layers, n_wires=N))\n\n        # Run the grad function once to compile\n        grad_x(x)\n\n        num_repeat = 100\n        times = np.empty(num_repeat)\n\n        for i in range(100):\n            x = jax.random.uniform(key, variational_ansatz.shape(n_layers=n_layers, n_wires=N))\n            times[i] = timeit(grad_x, x)\n\n        print(f\"JIT {jit} | shots {shots} | time taken \", \"{:e}\".format(jnp.mean(times)))\n1", "link": "https://discuss.pennylane.ai//t/speeding-up-grad-computation/141/34"}}