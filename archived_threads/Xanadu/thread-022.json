{"0": {"author": "Joan", "date": "1689785736025", "content": "Hello! If applicable, put your complete code example down below. Make sure that your code:\n\nis 100% self-contained \u2014 someone can copy-paste exactly what is here and run it to\nreproduce the behaviour you are observing\nincludes comments\n\nimport pennylane as qml \nfrom pennylane import qchem\nfrom pennylane import numpy as np\nimport matplotlib.pyplot as plt\n\n#Defining an algorithm class for Grover search\n#This class will have added functionality to optimize the number of calls to the oracle to experimentally verify the optimal value of sqrt(n)\n\nclass Grover:\n#------------\n#    INITIALIZATION, Input number of qubits, shots, and the bit string to be marked for search\n#------------    \n    def __init__(self, qubits, shots, oracle_state):\n        #num of qubits\n        self.qubits = qubits\n        #num of shots on backend\n        self.shots = shots\n        \n        #marked state defining the oracle - input in the form of an integer\n        #integer is converted to bit string which is converted to binary vector for later use in FlipState method\n        self.num = oracle_state\n        if oracle_state >= 2**self.qubits:\n            raise ValueError(f\"Insufficient qubits. Input value less than {2**self.qubits}\")\n        v = []\n        B = bin(oracle_state)[2:].zfill(self.qubits)\n        for i in range(len(B)):\n            v.append(int(B[i]))\n        self.oracle = v\n        \n        #optimal number of oracle+diffuser cycles - this value is used as the default to reproduce the standard Grover search\n        self.cycles = int(np.floor(np.sqrt(self.qubits)))\n\n#------------\n#    RUN METHOD, This is the core method which is used as input to all other methods\n#    Default run uses the optimal number of oracle cycles\n#    User can specify alternate number of cycles if desired\n#------------    \n    def run(self, cycles = None):\n        #cycles is an optional input if the user wants to implement Grover with a nonstandard number of oracle calls\n        if cycles is None:\n            cycles = self.cycles\n        #the run method takes in an integer to define the number of cycles - during optimization a tensor is passed to run - this converts the tensor input to one the method can use\n        if type(cycles) == np.tensor:\n            cycles = int(np.floor(cycles.item()))\n        \n        #setup for Grover algorithm with initial state [1,1,...,1] (this is more optimal as the diffuser does not need to be conjugated by x gates)\n        initial_state = []\n        for i in range(self.qubits):\n            initial_state.append(1)\n            \n        #oracle+diffusion\n        def OD():\n        #oracle\n            qml.FlipSign(self.oracle, wires = range(self.qubits))\n        #diffusion\n            for i in range(self.qubits):\n                qml.Hadamard(i)\n            qml.FlipSign(initial_state, wires = range(self.qubits))\n            for i in range(self.qubits):\n                qml.Hadamard(i)\n                \n        #repeater oracle+diffuser \n        def Oracle_Diffusion(n):\n            for i in range(n):\n                OD()\n                \n    #run grover\n        dev = qml.device(\"default.qubit\", wires = self.qubits, shots = self.shots)\n        @qml.qnode(dev, interface=\"autograd\")\n        def G(q):\n        #initial state prep\n            for i in range(self.qubits):\n                qml.PauliX(i)\n                qml.Hadamard(i)\n        #repeated component\n            Oracle_Diffusion(cycles)\n        #measurement\n            return qml.probs(wires = range(self.qubits))\n        #the output of the method is a 1D tensor of probabilities for each bit string given the number of cycles specified\n        return (G(cycles))\n#------------\n#    PLOT METHOD, visualizes probabilities outputted by run method\n#    Default run uses the optimal number of oracle cycles\n#    User can specify alternate number of cycles if desired\n#------------    \n    \n    def plot(self, cycles = None):\n        #same as for run\n        if cycles is None:\n            cycles = self.cycles\n        if type(cycles) == np.tensor:\n            cycles = int(np.floor(cycles.item()))\n            \n        #store y values as output of run method\n        y = self.run(cycles)\n        bit_strings = [f\"{x:0{self.qubits}b}\" for x in range(len(y))]\n        plt.bar(bit_strings, y, color = \"#212121\")\n        plt.xticks(rotation=\"vertical\")\n        plt.xlabel(\"State label\")\n        plt.ylabel(\"Probability Amplitude\")\n        plt.title(\"States probabilities amplitudes\")\n        plt.show()\n        \n#------------BROKEN METHOD\n#    OPT METHOD, utilizes cycle input capability to experimentally recover optimal number of cycles\n#------------BROKEN METHOD           \n    def opt(self):\n        #initialize optimizer using integer step size as cycles must always be an integer\n        opt = qml.GradientDescentOptimizer(stepsize=1)\n        #initialize training parameter\n        theta = np.array(0.0, requires_grad=True)\n        #cost function to be trained\n        #sends theta -> run method and selects the amplitude of marked state from output tensor\n        #value is negative to permit minimization\n        Cost_vec = [-self.run(theta)[self.num]]\n        angle = [theta]\n    \n        max_iterations = 100\n        convergence_tolerance = 1e-06\n    \n        for n in range(max_iterations):\n            #cost function\n            cost = -self.run(theta)[self.num]\n            #BROKEN LINE - step and cost does not appear to be working with this setup\n            theta, prev_prob = opt.step_and_cost(cost, theta)\n            \n            #store subsequent optimization steps in the corresponding vectors\n            Cost_vec.append(self.run(theta)[self.num])\n            angle.append(theta)\n            \n            #convergence condition left over from VQE demo where opt code was first sourced - doesn't apply to this problem\n            #conv = np.abs(Prob[-1] - prev_prob)\n              \n            if n % 2 == 0:\n                print(f\"Step = {n}, probability = {Prob[-1]:.8f}\")\n              \n            #if conv <= convergence_tolerance:\n            #    break\n\n        print(\"\\n\" f\"Final amplitude of the target state = {Prob[-1]:.8f}\")\n        print(\"\\n\" f\"Optimal value of the circuit parameter = {angle[-1]:.4f}\")     \n\n\nTypeError                                 Traceback (most recent call last)\n/tmp/ipykernel_70/2615489177.py in <cell line: 1>()\n----> 1 G.opt()\n/tmp/ipykernel_70/3335889083.py in opt(self)\n89\n90             cost = -self.run(theta)[self.num]\n\u2014> 91             theta, prev_prob = opt.step_and_cost(cost, theta)\n92\n93             Prob.append(self.run(theta)[self.num])\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py in step_and_cost(self, objective_fn, grad_fn, *args, **kwargs)\n57         \u201c\u201d\"\n58\n\u2014> 59         g, forward = self.compute_grad(objective_fn, args, kwargs, grad_fn=grad_fn)\n60         new_args = self.apply_grad(g, args)\n61\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py in compute_grad(objective_fn, args, kwargs, grad_fn)\n115         \u201c\u201d\"\n116         g = get_gradient(objective_fn) if grad_fn is None else grad_fn\n \u2192 117         grad = g(*args, **kwargs)\n118         forward = getattr(g, \u201cforward\u201d, None)\n119\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/pennylane/_grad.py in call(self, *args, **kwargs)\n113             return ()\n114\n \u2192 115         grad_value, ans = grad_fn(*args, **kwargs)\n116         self._forward = ans\n117\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/autograd/wrap_util.py in nary_f(*args, **kwargs)\n18             else:\n19                 x = tuple(args[i] for i in argnum)\n\u2014> 20             return unary_operator(unary_f, x, *nary_op_args, **nary_op_kwargs)\n21         return nary_f\n22     return nary_operator\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/pennylane/_grad.py in _grad_with_forward(fun, x)\n131         difference being that it returns both the gradient and the forward pass\n132         value.\u201c\u201d\"\n \u2192 133         vjp, ans = _make_vjp(fun, x)\n134\n135         if not vspace(ans).size == 1:\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/autograd/core.py in make_vjp(fun, x)\n8 def make_vjp(fun, x):\n9     start_node = VJPNode.new_root()\n\u2014> 10     end_value, end_node =  trace(start_node, fun, x)\n11     if end_node is None:\n12         def vjp(g): return vspace(x).zeros()\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/autograd/tracer.py in trace(start_node, fun, x)\n8     with trace_stack.new_trace() as t:\n9         start_box = new_box(x, t, start_node)\n\u2014> 10         end_box = fun(start_box)\n11         if isbox(end_box) and end_box._trace == start_box._trace:\n12             return end_box._value, end_box._node\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/autograd/wrap_util.py in unary_f(x)\n13                 else:\n14                     subargs = subvals(args, zip(argnum, x))\n\u2014> 15                 return fun(*subargs, **kwargs)\n16             if isinstance(argnum, int):\n17                 x = args[argnum]\nTypeError: \u2018tensor\u2019 object is not callable\n\n\nAnd, finally, make sure to include the versions of your packages. Specifically, show us the output of qml.about().\nName: PennyLane\nVersion: 0.28.0\nSummary: PennyLane is a Python quantum machine learning library by Xanadu Inc.\nHome-page: GitHub - PennyLaneAI/pennylane: PennyLane is a cross-platform Python library for differentiable programming of quantum computers. Train a quantum computer the same way as a neural network.\nAuthor:\nAuthor-email:\nLicense: Apache License 2.0\nLocation: /opt/conda/envs/pennylane/lib/python3.9/site-packages\nRequires: appdirs, autograd, autoray, cachetools, networkx, numpy, pennylane-lightning, requests, retworkx, scipy, semantic-version, toml\nRequired-by: PennyLane-Cirq, PennyLane-Lightning, PennyLane-qiskit, pennylane-qulacs, PennyLane-SF\nPlatform info:           Linux-5.4.209-116.367.amzn2.x86_64-x86_64-with-glibc2.31\nPython version:          3.9.15\nNumpy version:           1.23.5\nScipy version:           1.10.0\nInstalled devices:\n\ndefault.gaussian (PennyLane-0.28.0)\ndefault.mixed (PennyLane-0.28.0)\ndefault.qubit (PennyLane-0.28.0)\ndefault.qubit.autograd (PennyLane-0.28.0)\ndefault.qubit.jax (PennyLane-0.28.0)\ndefault.qubit.tf (PennyLane-0.28.0)\ndefault.qubit.torch (PennyLane-0.28.0)\ndefault.qutrit (PennyLane-0.28.0)\nnull.qubit (PennyLane-0.28.0)\ncirq.mixedsimulator (PennyLane-Cirq-0.28.0)\ncirq.pasqal (PennyLane-Cirq-0.28.0)\ncirq.qsim (PennyLane-Cirq-0.28.0)\ncirq.qsimh (PennyLane-Cirq-0.28.0)\ncirq.simulator (PennyLane-Cirq-0.28.0)\nlightning.qubit (PennyLane-Lightning-0.28.2)\nstrawberryfields.fock (PennyLane-SF-0.20.1)\nstrawberryfields.gaussian (PennyLane-SF-0.20.1)\nstrawberryfields.gbs (PennyLane-SF-0.20.1)\nstrawberryfields.remote (PennyLane-SF-0.20.1)\nstrawberryfields.tf (PennyLane-SF-0.20.1)\nqiskit.aer (PennyLane-qiskit-0.28.0)\nqiskit.basicaer (PennyLane-qiskit-0.28.0)\nqiskit.ibmq (PennyLane-qiskit-0.28.0)\nqiskit.ibmq.circuit_runner (PennyLane-qiskit-0.28.0)\nqiskit.ibmq.sampler (PennyLane-qiskit-0.28.0)\nqulacs.simulator (pennylane-qulacs-0.28.0)\n\u200b\n", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/1"}, "1": {"author": "isaacdevlugt", "date": "1689792356251", "content": "Hey @Joan!\nThere\u2019s quite a bit going on, and I think it would best serve us to work with a much simpler example that highlights the key parts to any circuit optimization in PennyLane. The code I\u2019m about to show is in the qubit rotation demo.\nIn your code, there\u2019s a parameterized circuit whose parameters need to be tuned to optimize some cost function. Let\u2019s first define a parameterized circuit:\nimport pennylane as qml\nfrom pennylane import numpy as np\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef circuit(params):\n    qml.RX(params[0], wires=0)\n    qml.RY(params[1], wires=0)\n    return qml.expval(qml.PauliZ(0))\n\nThis circuit takes a vector of parameters \u2014 length 2 \u2014 and returns an expectation value. Now, we need to define a separate function that we want to optimize \u2014 the cost function. It could literally be anything so long as it returns a scalar output (e.g., mean square loss, KL divergence, etc. \u2014 any loss function). Here, let\u2019s just use the circuit\u2019s output as the cost function:\ndef cost(x):\n    return circuit(x)\n\ninit_params = np.array([0.011, 0.012], requires_grad=True)\nprint(cost(init_params))\n\n0.9998675058299389\n\nNow we can go ahead and optimize the cost function. To do that, we define an optimizer then update the parameters with the optimizer\u2019s step method, which takes the loss function as the first argument and the arguments of the loss function next. step_and_cost returns both the parameters and the loss function value.\n# initialise the optimizer\nopt = qml.GradientDescentOptimizer(stepsize=0.4)\n\n# set the number of steps\nsteps = 5\n# set the initial parameter values\nparams = init_params\n\nfor i in range(steps):\n    # update the circuit parameters\n    params = opt.step(cost, params)\n\n    print(\"Cost after step {:5d}: {: .7f}\".format(i + 1, cost(params)))\n\nprint(\"Optimized rotation angles: {}\".format(params))\n\nIt sounds like you\u2019re aware of most of this already, but it helps to simplify what you\u2019re doing if you get stuck. If what you\u2019re trying to do is more complex than what\u2019s above, then I can definitely help! Just fill me in on the details ", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/2"}, "2": {"author": "Joan", "date": "1689795960159", "content": "Hey Isaac,\nThanks for your response. I am familiar with the qubit rotation tutorial - it doesn\u2019t seem to make a difference whether I use opt.step or opt.step_and_cost.\nIt may be more helpful to compare how I am trying to optimize my problem to the opt module in the VQE demo, as this was my starting point.\nI believe that the problem I am running into is at the interaction of GradientDescentOptimizer\u2019s methods and my run() module.\nIn your example code, you call cost(init_params), and this returns a zero-dimensional tensor:\ntensor(0.99986751, requires_grad=True)\nIn my code, when I initialize an instance of Grover G, then G.run(theta) returns a 1D tensor where each entry corresponds to the measurement probability of a particular bit string after applying some number theta of oracle+diffusion modules.\nFor my optimization problem, I define the 3 qubit grover with 100 shots that searches for the bit string 000 via\nG = Grover(3,100,0)\ndef cost(x):\nreturn -G.run(x)[G.num]\nIf I define\ntheta = np.array(0.0, requires_grad=True)\nthen cost(theta) gives\ntensor(-0.111, requires_grad=True)\nThis outputs a zero-dimensional tensor corresponding to the measurement probability of the bit string which has been marked for search after zero calls to the oracle. This is the quantity I want to maximize (or minimize in this case as I have made it negative to be compatible with gradient descent).\nWhat does step or step_and_cost expect for inputs? I have tried to ensure that cost(theta) and theta are both tensors with requires_grad=True - but is it possible that I am feeding the opt methods something they don\u2019t know how to work with?\nI added\ndef cost(x)\nreturn -G.run(x)[G.num]\nto the opt method as I thought it was cleaner, so now I have\ndef opt(self):\n#initialize optimizer using integer step size as cycles must always be an integer\nopt = qml.GradientDescentOptimizer(stepsize=1)\n#initialize training parameter\n#dev = qml.device(\u201cdefault.qubit\u201d, wires = self.qubits, shots = self.shots)\n#@qml.qnode(dev, interface=\u201cautograd\u201d)\ndef cost(x):\nreturn -self.run(x)[self.num]\ntheta = np.array(0.0, requires_grad=True)\n#cost function to be trained\n#sends theta \u2192 run method and selects the amplitude of marked state from output tensor\n#value is negative to permit minimization\n#Cost_vec = [-self.run(theta)[self.num]]\nCost_vec = [cost(theta)]\nangle = [theta]\nmax_iterations = 5\n#convergence_tolerance = 1e-06\nfor n in range(max_iterations):\n#BROKEN LINE - step and cost does not appear to be working with this settup\ntheta = opt.step(cost, theta)\n#store subsequent optimization steps in the corresponding vectors\nCost_vec.append(cost(theta))\nangle.append(theta)\n#convergence condition left over from VQE demo where opt code was first sourced - doesn\u2019t apply to this problem\n#conv = np.abs(Prob[-1] - prev_prob)\nif n % 2 == 0:\nprint(f\"Step = {n}, probability = {Cost_vec[-1]:.8f}\u201c)\n#if conv <= convergence_tolerance:\n#    break\nprint(\u201d\\n\" f\"Final amplitude of the target state = {Prob[-1]:.8f}\u201c)\nprint(\u201d\\n\" f\"Optimal value of the circuit parameter = {angle[-1]:.4f}\")\nWhich produces a different error: TypeError: \u2018ArrayBox\u2019 object cannot be interpreted as an integer\n\nTypeError                                 Traceback (most recent call last)\n/tmp/ipykernel_51/2615489177.py in <cell line: 1>()\n----> 1 G.opt()\n/tmp/ipykernel_51/3346500594.py in opt(self)\n121         for n in range(max_iterations):\n122             #BROKEN LINE - step and cost does not appear to be working with this settup\n \u2192 123             theta = opt.step(cost, theta)\n124\n125             #store subsequent optimization steps in the corresponding vectors\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py in step(self, objective_fn, grad_fn, *args, **kwargs)\n86         \u201c\u201d\"\n87\n\u2014> 88         g, _ = self.compute_grad(objective_fn, args, kwargs, grad_fn=grad_fn)\n89         new_args = self.apply_grad(g, args)\n90\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/pennylane/optimize/gradient_descent.py in compute_grad(objective_fn, args, kwargs, grad_fn)\n115         \u201c\u201d\"\n116         g = get_gradient(objective_fn) if grad_fn is None else grad_fn\n \u2192 117         grad = g(*args, **kwargs)\n118         forward = getattr(g, \u201cforward\u201d, None)\n119\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/pennylane/_grad.py in call(self, *args, **kwargs)\n113             return ()\n114\n \u2192 115         grad_value, ans = grad_fn(*args, **kwargs)\n116         self._forward = ans\n117\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/autograd/wrap_util.py in nary_f(*args, **kwargs)\n18             else:\n19                 x = tuple(args[i] for i in argnum)\n\u2014> 20             return unary_operator(unary_f, x, *nary_op_args, **nary_op_kwargs)\n21         return nary_f\n22     return nary_operator\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/pennylane/_grad.py in _grad_with_forward(fun, x)\n131         difference being that it returns both the gradient and the forward pass\n132         value.\u201c\u201d\"\n \u2192 133         vjp, ans = _make_vjp(fun, x)\n134\n135         if not vspace(ans).size == 1:\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/autograd/core.py in make_vjp(fun, x)\n8 def make_vjp(fun, x):\n9     start_node = VJPNode.new_root()\n\u2014> 10     end_value, end_node =  trace(start_node, fun, x)\n11     if end_node is None:\n12         def vjp(g): return vspace(x).zeros()\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/autograd/tracer.py in trace(start_node, fun, x)\n8     with trace_stack.new_trace() as t:\n9         start_box = new_box(x, t, start_node)\n\u2014> 10         end_box = fun(start_box)\n11         if isbox(end_box) and end_box._trace == start_box._trace:\n12             return end_box._value, end_box._node\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/autograd/wrap_util.py in unary_f(x)\n13                 else:\n14                     subargs = subvals(args, zip(argnum, x))\n\u2014> 15                 return fun(*subargs, **kwargs)\n16             if isinstance(argnum, int):\n17                 x = args[argnum]\n/tmp/ipykernel_51/3360673386.py in cost(x)\n1 def cost(x):\n----> 2     return -G.run(x)[G.num]\n/tmp/ipykernel_51/3346500594.py in run(self, cycles)\n73             return qml.probs(wires = range(self.qubits))\n74         #the output of the method is a 1D tensor of probabilities for each bit string given the number of cycles specified\n\u2014> 75         return (G(cycles))\n76 #------------\n77 #    PLOT METHOD, visualizes probabilities outputted by run method\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/pennylane/qnode.py in call(self, *args, **kwargs)\n798\n799         # construct the tape\n \u2192 800         self.construct(args, kwargs)\n801\n802         cache = self.execute_kwargs.get(\u201ccache\u201d, False)\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/pennylane/qnode.py in construct(self, args, kwargs)\n709         \u201c\u201d\u201cCall the quantum function with a tape context, ensuring the operations get queued.\u201d\u201c\u201d\n710\n \u2192 711         self._tape = make_qscript(self.func)(*args, **kwargs)\n712         self._tape._queue_category = \u201c_ops\u201d\n713         self._qfunc_output = self.tape._qfunc_output\n/opt/conda/envs/pennylane/lib/python3.9/site-packages/pennylane/tape/qscript.py in wrapper(*args, **kwargs)\n1344     def wrapper(*args, **kwargs):\n1345         with AnnotatedQueue() as q:\n \u2192 1346             result = fn(*args, **kwargs)\n1347\n1348         qscript = QuantumScript.from_queue(q)\n/tmp/ipykernel_51/3346500594.py in G(q)\n69                 qml.Hadamard(i)\n70         #repeated component\n\u2014> 71             Oracle_Diffusion(cycles)\n72         #measurement\n73             return qml.probs(wires = range(self.qubits))\n/tmp/ipykernel_51/3346500594.py in Oracle_Diffusion(n)\n57         #repeater oracle+diffuser\n58         def Oracle_Diffusion(n):\n\u2014> 59             for i in range(n):\n60                 OD()\n61\nTypeError: \u2018ArrayBox\u2019 object cannot be interpreted as an integer", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/3"}, "3": {"author": "Joan", "date": "1689802185906", "content": "I did a bit more digging, and it seems as if when I pass a tensor like theta \u2192 autograd it converts the input to the ArrayBox data type.\nThis data type is then incompatible with my range(theta) as range needs an integer data type\n#repeater oracle+diffuser\ndef Oracle_Diffusion(n):\nfor i in range(n):\nOD()\nI ran into this issue prior to bringing in gradient descent - and I thought I had fixed it by adding this line to the run method\ndef run(self, cycles = None):\n#cycles is an optional input if the user wants to implement Grover with a nonstandard number of oracle calls\nif cycles is None:\ncycles = self.cycles\n#the run method takes in an integer to define the number of cycles - during optimization a tensor is passed to run - this converts the tensor input to one the method can use\nif type(cycles) == np.tensor:\ncycles = int(np.floor(cycles.item()))\nBut apparently the issue is still there???", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/4"}, "4": {"author": "CatalinaAlbornoz", "date": "1689867404602", "content": "Hi @Joan,\nArrayBox issues usually come up when your cost function is updating a global variable or when you do things that Autograd doesn\u2019t like (details here 1 in the docs).\nI will take a look at the code you shared to see if I can reproduce the issue and share some more specific insights. Stay tuned! ", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/5"}, "5": {"author": "Joan", "date": "1689868561919", "content": "Hey @CatalinaAlbornoz - great to hear from you!\nLooking forward to learning more, the good news is that if I am right about the cause of the error then it is an artifact of my unusual framing of Grover as a variational algorithm that can only take integer theta\nI was building this code as a conceptual bridge for my students to go from non-variational to variational algorithms - I don\u2019t expect the VQA code I am working on next will have this issue since their variational parameters will be more conventional", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/6"}, "6": {"author": "CatalinaAlbornoz", "date": "1689978796807", "content": "Hi @Joan,\nI wasn\u2019t able to find an answer to your issue here so I will forward your question to my colleagues here who may have some insights.", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/7"}, "7": {"author": "isaacdevlugt", "date": "1690206096394", "content": "Hey @Joan,\nI think you can just get away with casting a larger net to make sure cycles is an int. Right now, checking if it\u2019s a numpy array won\u2019t catch subsequent instances when it\u2019s converted to an ArrayBox. Let me know if this works:\nclass Grover:\n    def __init__(self, qubits, shots, oracle_state):\n        # num of qubits\n        self.qubits = qubits\n        # num of shots on backend\n        self.shots = shots\n\n        # marked state defining the oracle - input in the form of an integer\n        # integer is converted to bit string which is converted to binary vector for later use in FlipState method\n        self.num = oracle_state\n        if oracle_state >= 2**self.qubits:\n            raise ValueError(\n                f\"Insufficient qubits. Input value less than {2**self.qubits}\"\n            )\n        v = []\n        B = bin(oracle_state)[2:].zfill(self.qubits)\n        for i in range(len(B)):\n            v.append(int(B[i]))\n        self.oracle = v\n\n        # optimal number of oracle+diffuser cycles - this value is used as the default to reproduce the standard Grover search\n        self.cycles = int(np.floor(np.sqrt(self.qubits)))\n\n    def run(self, cycles=None):\n        # cycles is an optional input if the user wants to implement Grover with a nonstandard number of oracle calls\n        if cycles is None:\n            cycles = self.cycles\n        # the run method takes in an integer to define the number of cycles - during optimization a tensor is passed to run - this converts the tensor input to one the method can use\n        elif type(cycles) != int:\n            cycles = int(np.floor(cycles))\n\n        # setup for Grover algorithm with initial state [1,1,...,1] (this is more optimal as the diffuser does not need to be conjugated by x gates)\n        initial_state = []\n        for i in range(self.qubits):\n            initial_state.append(1)\n\n        # oracle+diffusion\n        def OD():\n            # oracle\n            qml.FlipSign(self.oracle, wires=range(self.qubits))\n            # diffusion\n            for i in range(self.qubits):\n                qml.Hadamard(i)\n            qml.FlipSign(initial_state, wires=range(self.qubits))\n            for i in range(self.qubits):\n                qml.Hadamard(i)\n\n        # repeater oracle+diffuser\n        def Oracle_Diffusion(n):\n            for i in range(n):\n                OD()\n\n        # run grover\n        dev = qml.device(\"default.qubit\", wires=self.qubits, shots=self.shots)\n\n        @qml.qnode(dev, interface=\"autograd\")\n        def G(q):\n            # initial state prep\n            for i in range(self.qubits):\n                qml.PauliX(i)\n                qml.Hadamard(i)\n            # repeated component\n            Oracle_Diffusion(cycles)\n            # measurement\n            return qml.probs(wires=range(self.qubits))\n\n        # the output of the method is a 1D tensor of probabilities for each bit string given the number of cycles specified\n        return G(cycles)\n\n    def cost(self, x):\n        return -self.run(x)[self.num]\n\n    def opt(self):\n        # initialize optimizer using integer step size as cycles must always be an integer\n        opt = qml.GradientDescentOptimizer(stepsize=1)\n        # initialize training parameter\n        theta = np.array(0.0, requires_grad=True)\n        # cost function to be trained\n        # sends theta -> run method and selects the amplitude of marked state from output tensor\n        # value is negative to permit minimization\n        Cost_vec = [-self.run(theta)[self.num]]\n        angle = [theta]\n\n        max_iterations = 100\n        convergence_tolerance = 1e-06\n\n        for n in range(max_iterations):\n            # cost function\n            # BROKEN LINE - step and cost does not appear to be working with this setup\n            theta, prev_prob = opt.step_and_cost(cost, theta)\n            # store subsequent optimization steps in the corresponding vectors\n            Cost_vec.append(self.run(theta)[self.num])\n            angle.append(theta)\n\nNB:\n        if cycles is None:\n            cycles = self.cycles\n        # the run method takes in an integer to define the number of cycles - during optimization a tensor is passed to run - this converts the tensor input to one the method can use\n        elif type(cycles) != int:\n\n            cycles = int(np.floor(cycles))\n", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/8"}, "8": {"author": "Joan", "date": "1690233559943", "content": "That did something!\nNow opt() runs, but it seems not to be passing new theta values to opt.step\nI also tried running step_and_cost and got the same error\nHere is my updated code:\n#Defining an algorithm class for Grover search\n#This class will have addded functionality to optimize the number of calls to the oracle to experimentally verify the optimal value of sqrt(n)\nclass Grover:\n#------------\nINITIALIZATION, Input number of qubits, shots, and the bit string to be marked for search\n#------------\ndef init(self, qubits, shots, oracle_state):\n#num of qubits\nself.qubits = qubits\n#num of shots on backend\nself.shots = shots\n    #marked state defining the oracle - input in the form of an integer\n    #integer is converted to bit string which is converted to binary vector for later use in FlipState method\n    self.num = oracle_state\n    if oracle_state >= 2**self.qubits:\n        raise ValueError(f\"Insufficient qubits. Input value less than {2**self.qubits}\")\n    v = []\n    B = bin(oracle_state)[2:].zfill(self.qubits)\n    for i in range(len(B)):\n        v.append(int(B[i]))\n    self.oracle = v\n    \n    #optimal number of oracle+diffuser cycles - this value is used as the default to reproduce the standard Grover search\n    self.cycles = int(np.floor(np.sqrt(self.qubits)))\n\n#------------\nRUN METHOD, This is the core method which is used as input to all other methods\nDefault run uses the optimal number of oracle cycles\nUser can specify alternate number of cycles if desired\n#------------\ndef run(self, cycles = None):\n#cycles is an optional input if the user wants to implement Grover with a nonstandard number of oracle calls\nif cycles is None:\ncycles = self.cycles\n#the run method takes in an integer to define the number of cycles - during optimization a tensor is passed to run - this converts the tensor input to one the method can use\n#if type(cycles) == np.tensor:\n#    cycles = int(np.floor(cycles.item()))\nelif type(cycles) != int:\ncycles = int(np.floor(cycles))\n    #setup for Grover algorithm with initial state [1,1,...,1] (this is more optimal as the diffuser does not need to be conjugated by x gates)\n    initial_state = []\n    for i in range(self.qubits):\n        initial_state.append(1)\n        \n    #oracle+diffusion\n    def OD():\n    #oracle\n        qml.FlipSign(self.oracle, wires = range(self.qubits))\n    #diffusion\n        for i in range(self.qubits):\n            qml.Hadamard(i)\n        qml.FlipSign(initial_state, wires = range(self.qubits))\n        for i in range(self.qubits):\n            qml.Hadamard(i)\n            \n    #repeater oracle+diffuser \n    def Oracle_Diffusion(n):\n        if type(n) == np.tensor:\n            n = int(np.floor(n.item()))\n        for i in range(int(n)):\n            OD()\n            \n#run grover\n    dev = qml.device(\"default.qubit\", wires = self.qubits, shots = self.shots)\n    @qml.qnode(dev, interface=\"autograd\")\n    def G(x):\n        if type(x) == np.tensor:\n            x = int(np.floor(x.item()))\n    #initial state prep\n        for i in range(self.qubits):\n            qml.PauliX(i)\n            qml.Hadamard(i)\n    #repeated component\n        Oracle_Diffusion(x)\n    #measurement\n        return qml.probs(wires = range(self.qubits))\n    #the output of the method is a 1D tensor of probabilities for each bit string given the number of cycles specified\n    return (G(cycles))\n\n#------------\nPLOT METHOD, visualizes probabilities outputted by run method\nDefault run uses the optimal number of oracle cycles\nUser can specify alternate number of cycles if desired\n#------------\ndef plot(self, cycles = None):\n    #same as for run\n    if cycles is None:\n        cycles = self.cycles\n    if type(cycles) == np.tensor:\n        cycles = int(np.floor(cycles.item()))\n        \n    #store y values as output of run method\n    y = self.run(cycles)\n    bit_strings = [f\"{x:0{self.qubits}b}\" for x in range(len(y))]\n    plt.bar(bit_strings, y, color = \"#212121\")\n    plt.xticks(rotation=\"vertical\")\n    plt.xlabel(\"State label\")\n    plt.ylabel(\"Probability Amplitude\")\n    plt.title(\"States probabilities amplitudes\")\n    plt.show()\n\n#------------\nOPT METHOD, utilizes cycle input capability to experimentally recover optimal number of cycles\n#------------\ndef opt(self):\n#initialize optimizer using integer step size as cycles must always be an integer\nopt = qml.GradientDescentOptimizer(stepsize=1)\n#initialize training parameter\n#dev = qml.device(\u201cdefault.qubit\u201d, wires = self.qubits, shots = self.shots)\n#@qml.qnode(dev, interface=\u201cautograd\u201d)\ndef cost(x):\nreturn -self.run(x)[self.num]\ntheta = np.array(0.0, requires_grad=True)\n#cost function to be trained\n#sends theta \u2192 run method and selects the amplitude of marked state from output tensor\n#value is negative to permit minimization\n#Cost_vec = [-self.run(theta)[self.num]]\nCost_vec = [cost(theta)]\nangle = [theta]\n    max_iterations = 10\n    #convergence_tolerance = 1e-06\n\n    for n in range(max_iterations):\n        #BROKEN LINE - step and cost does not appear to be working with this settup\n        #theta = opt.step(cost, theta)\n        theta, prev_cost = opt.step_and_cost(cost, theta)\n        \n        #store subsequent optimization steps in the corresponding vectors\n        Cost_vec.append(cost(theta))\n        angle.append(theta)\n        \n        #convergence condition left over from VQE demo where opt code was first sourced - doesn't apply to this problem\n        #conv = np.abs(Prob[-1] - prev_prob)\n          \n        print(f\"Step = {n}, probability = {Cost_vec[-1]:.8f}\")\n          \n        #if conv <= convergence_tolerance:\n        #    break\n\n    print(\"\\n\" f\"Final amplitude of the target state = {Cost_vec[-1]:.8f}\")\n    print(\"\\n\" f\"Optimal value of the circuit parameter = {angle[-1]:.4f}\")\n\nHere is what I expect from ten iterations compared to the method output\nimage452\u00d7532 5.9 KB", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/9"}, "9": {"author": "isaacdevlugt", "date": "1690236816146", "content": "I think the issue is (probably two-fold) in that that you\u2019re creating a QNode every time you call run, which is (essentially) what is being differentiated. Can you try creating the QNode once by  either (1) defining it outside of the Grover class or (2) in the Grover class making sure that the QNode is created when an instance of Grover is created? Let me know if that works!", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/10"}, "10": {"author": "Joan", "date": "1690238649310", "content": "So this is something I played with in the early stages of Grover\u2019s development and I couldn\u2019t seem to get it to work without having @qml.qnode(dev) immediately preceding the circuit I wanted to run - that is why it put it inside the run method\nIf I put qnode anywhere else I get errors - is there another way to do this?\nIs qnode created when I define dev = qml.device(\u201cdefault.qubit\u201d, wires=self.qubits, shots = self.shots)?\nor when I write @qml.node(dev)?\nIf it is the former, then I can store dev as self.dev in the following way (this is a simpler bit of code code designed to implement a superposition circuit within this OOP framework I am learning)\nclass Sup:\ndef __init__(self, qubits, shots):\n    self.qubits = qubits\n    self.shots = shots\n    self.dev = qml.device(\"default.qubit\", wires=self.qubits, shots = self.shots)\n    \ndef run(self):\n    @qml.qnode(self.dev, interface=\"autograd\")\n    def H(q):\n        for i in range(self.qubits):\n            qml.Hadamard(i)\n        return [qml.expval(qml.PauliZ(i)) for i in range(self.qubits)]\n    return (H(self.qubits))\n\nBut beyond this I\u2019m not sure how to create a node without placing it immediately above the circuit I am passing to it", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/11"}, "11": {"author": "isaacdevlugt", "date": "1690291136511", "content": "\nIs qnode created when I define dev = qml.device(\u201cdefault.qubit\u201d, wires=self.qubits, shots = self.shots)? or when I write @qml.node(dev)?\n\nA QNode is created when you decorate a quantum function with @qml.qnode. You should be able to put it outside the class and have things work (option 1) or as a class attribute (option 2) ", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/12"}, "12": {"author": "Joan", "date": "1690302377278", "content": "I think my issue is I dont really understand Qnode - I have tried placing it as a class attribute in the following example code\nclass Sup:\ndef __init__(self, qubits, shots):\n    self.qubits = qubits\n    self.shots = shots\n    self.dev = qml.device(\"default.qubit\", wires=self.qubits, shots = self.shots)\n    self.node = qml.qnode(self.dev)\n    \ndef run(self):\n    #wrapper\n    @self.node\n    #circuit\n    def H(q):\n        for i in range(self.qubits):\n            qml.Hadamard(i)\n        return [qml.expval(qml.PauliZ(i)) for i in range(self.qubits)]\n        #return qml.sample()\n    return (H(self.qubits))\n\nBut I don\u2019t think this is functionally any different from what I had before.\nI tried removing it from the class and placing it outside\nA = sup(3,100) #no device or qnode inside the class\ndev = qml.device(\u201cdefault.qubit\u201d, wires=A.qubits, shots = A.shots)\n@qml.node(dev)\nA.run()\nbut this gives \u2018invalid syntax\u2019 error\nI have tried several other placements of qnode all with the same effect\nCan you give an example of how the qnode can be made a class attribute such that the run method still works?\nI was playing with node = qml.QNode(circuit, dev) also but havent had any luck", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/13"}, "13": {"author": "isaacdevlugt", "date": "1690306745361", "content": "\n\n\n Joan:\n\nCan you give an example of how the qnode can be made a class attribute such that the run method still works?\n\n\nSure thing! Here\u2019s a minimal example:\nimport pennylane as qml\nfrom pennylane import numpy as np\n\nclass MyClass:\n    def __init__(self, n_qubits):\n        self.n_qubits = n_qubits\n        device = qml.device(\"default.qubit\", wires=n_qubits)\n\n        self.quantum_node = qml.QNode(self.quantum_function, device)\n\n    def quantum_function(self, params):\n        for i in range(len(params)):\n            qml.RX(params[i], wires=i)\n        return [qml.expval(qml.PauliZ(i)) for i in range(len(params))]\n\n    def cost(self, params):\n        return -np.sum(self.quantum_node(params))\n\n    def do_optimization(self):\n        params = np.random.uniform(0, np.pi, size=(self.n_qubits,), requires_grad=True)\n        opt = qml.GradientDescentOptimizer(0.1)\n        for n in range(10):\n            params = opt.step(self.cost, params)\n            print(self.cost(params))\n\nobj = MyClass(4)\nobj.do_optimization()\n\n-3.6838202359463894\n-3.737987269714827\n-3.783698057758141\n-3.8220120753125184\n-3.8539404434260787\n-3.880416877392254\n-3.9022816835753353\n-3.920275812324963\n-3.9350420219145708\n-3.9471306216104813\n\nHope this helps!1", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/14"}, "14": {"author": "Joan", "date": "1690390150535", "content": "Fantastic thank you!1", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/15"}, "15": {"author": "isaacdevlugt", "date": "1690395581777", "content": "My pleasure! Glad I could help ", "link": "https://discuss.pennylane.ai//t/issues-using-step-and-cost-as-part-of-an-optimization-method/3198/16"}}