{"0": {"author": "Muhammad_Kashif", "date": "1623421175213", "content": "Hello,\nI have been going through the official tutorials on quantum neural networks (QNN) and Quanvolution neural network(QuNN): I have some questions regarding both in comparsion to classical NN and Classical convolutional NN:\nQNN: Referred Tutorial 12\n\nI have tried running the same model for MNIST dataset (both with  quantum layer(s) and without) and it turns out that quantum layer(s) do not have any impact on the validation accuracy, I even tried adding more quantum layers and even increasing the number of qubits/layer, but still the validation accuracy turns out to be the same (more or less) in both with and without quantum layers. Now my question is what is the point of quantum circuit/layers addition if it is not affecting the model training at all?\nI believe the quantum parameters are not being trained, if I am right, and this is the reason that quantum layers are not affecting the model learning, then how can we make them trainable and see if it is improving the training as compared to classical NN?\nis it necessary to have the first and last layers of hybrid QNN to be the classical layers? Can we have complete QNN without any classical layers at the moment?\n\nQuNN: This tutorial 10\n\nMore suitable for image classification problems, right? However, the Quanvolution of MNIST images takes way too much time, I have tried for 5000 training and 1000 test images and it took around 5+ hours roughly on google colab, which roughly maps to around 60 hours for complete dataset (70000 images). Is it even practical for MNIST dataset, which is considered to be the Hello world dataset for classical CNNs.\nwe need a reasonably large dataset to guage the performance since for this small data, even a very simple CNN model overfits in a couple of epochs, and the same would be the case with QuNNs, i suppose.\nEven for small (5000/1000) dataset, the quanvoluted data performs almost the same as convoluted dataset. What is the point of doing quantum convolution (seems very impractical compared to classical counterpart).  In tutorial the quanvoluted images are processed by classical NN so I thought may be some quantum layers addition would better process the quanvoluted images but no significant effect(might be because of non-trainable quantum parameters, discussed above).\n\nIn both models (QNN and QUNN), the optimizer used is a classical one, if we can make the quantum parameters trainable, it sure would need a quantum optimizer, right? But I am not sure how to integrate it here, particularly in hybrid setting, any light on that would be beneficial?\nThanks for this great discussion forum. It has been and hopefully will be quite helpful.\nBest,\nMuhammad Kashif2", "link": "https://discuss.pennylane.ai//t/quantum-neural-networks-quanvolutional-nn/1111/1"}, "1": {"author": "Tom_Bromley", "date": "1623430277306", "content": "Hey @Muhammad_Kashif!\n\nI have tried running the same model for MNIST dataset (both with quantum layer(s) and without) and it turns out that quantum layer(s) do not have any impact on the validation accuracy, I even tried adding more quantum layers and even increasing the number of qubits/layer, but still the validation accuracy turns out to be the same (more or less) in both with and without quantum layers. Now my question is what is the point of quantum circuit/layers addition if it is not affecting the model training at all?\nI believe the quantum parameters are not being trained, if I am right, and this is the reason that quantum layers are not affecting the model learning, then how can we make them trainable and see if it is improving the training as compared to classical NN?\n\nThere are potentially two questions here: (1) in theory what can a quantum circuit add to improve a hybrid model, and (2) is the model set up correctly so that the weights of the quantum parts are being trained?\nFor (1), it is in fact quite an open research question on how to best use quantum circuits within the machine learning toolchain. There are lots of interesting insights coming in, for example showing that you can think of these circuits as kernel methods 2 and how you might understand their expressive power 1. Nevertheless, the best practices are not fully established and using the typical templates like StronglyEntanglingLayers 2 may not be performant with all datasets.\nTo answer (2), we\u2019d have to see a minimum working code for your hybrid model.\n\nis it necessary to have the first and last layers of hybrid QNN to be the classical layers? Can we have complete QNN without any classical layers at the moment?\n\nIt is not necessary and you should be able to create a Keras model composed purely of quantum circuits. However, the classical layers are useful for scaling the number of features and for applying familiar nonlinearities like softmax. The approach of adding a classical layer before and after the quantum circuit is discussed here 6.\n\nMore suitable for image classification problems, right? However, the Quanvolution of MNIST images takes way too much time, I have tried for 5000 training and 1000 test images and it took around 5+ hours roughly on google colab, which roughly maps to around 60 hours for complete dataset (70000 images). Is it even practical for MNIST dataset, which is considered to be the Hello world dataset for classical CNNs.\nwe need a reasonably large dataset to guage the performance since for this small data, even a very simple CNN model overfits in a couple of epochs, and the same would be the case with QuNNs, i suppose.\n\nYes, the Quanvolutional layer was created by the authors 3 with image recognition in mind. You are correct that training time will be much slower, primarily due to the overhead of trying to simulate a quantum device which scales exponentially with the number of qubits. The natural approach is to use quantum hardware, but due to noise and current limitations we typically aim to train more prototypical models on simulator.\nFor now, your options are to use a smaller dataset (number of images, or resolution) as well as to make sure you are squeezing the best performance from your computer. Make sure that you are using the backprop or adjoint differentiation methods 1, since this will provide a significant speedup during training (note that you may already be using backprop).\n\nEven for small (5000/1000) dataset, the quanvoluted data performs almost the same as convoluted dataset. What is the point of doing quantum convolution (seems very impractical compared to classical counterpart). In tutorial the quanvoluted images are processed by classical NN so I thought may be some quantum layers addition would better process the quanvoluted images but no significant effect(might be because of non-trainable quantum parameters, discussed above).\n\nSimilar to my previous response, currently we\u2019re still scouting out a lot of ideas in QML and building up the theory and understanding for what works best. I\u2019d say there isn\u2019t a universal version of a quantum convolutional layer yet, with the one introduced in the paper 3 an interesting candidate. I\u2019d have to dig deeper into the paper to understand their motivations, but right now the field is definitely open for new ideas on how to compose circuits in an advantageous way.\n\nIn both models (QNN and QUNN), the optimizer used is a classical one, if we can make the quantum parameters trainable, it sure would need a quantum optimizer, right?\n\nIn a sense you can think of the circuit as a function f(theta) that has a well defined gradient f'(theta). This way of thinking allows you to use any classical optimizer. On the other hand, there are quantum aware optimizers being developed, for example see this 1 demo.1 Reply", "link": "https://discuss.pennylane.ai//t/quantum-neural-networks-quanvolutional-nn/1111/2"}, "2": {"author": "Muhammad_Kashif", "date": "1623507798152", "content": "Hi @Tom_Bromley,\nThanks for answering and referring the corresponding papers.\nYes, it is quite right that the best strategy to use quantum circuit in ML context is yet to be developed, and the best practice so far while building such circuits is that they should incorporate the properties of quantum mechanics having no classical counterparts (superposition and entanglement).\n\nTo answer (2), we\u2019d have to see a minimum working code for your hybrid model.\n\nSure, I can share the code, its very much similar to that provided in QNN  (here 3) and QuNN tutorials and here 2. What I am doing is to perform quantum convolution following the QuNN tutorial, infact exactly the same. The data size is (5000 train_images and 1000 test_images).  Afterwards, I am training the following model:\nn_qubits = 3\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1), qml.expval(qml.PauliX(2)))\n\nn_layers = 6\nweight_shapes = {\"weights\": (n_layers, n_qubits)}        \nclayer_1 = tf.keras.layers.Dense(12,activation ='relu')\n\nqlayer_1 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nqlayer_2 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nqlayer_3 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nqlayer_4 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nclayer_2 = tf.keras.layers.Dense(10, activation=\"softmax\")\n\n# construct the model\ninputs = tf.keras.Input(shape=(784,))\nkeras.layers.Flatten(),\nx = clayer_1(inputs)\nx_1, x_2, x_3,x_4 = tf.split(x, 4, axis=1)\nx_1 = qlayer_1(x_1)\nx_2 = qlayer_2(x_2)\nx_3 = qlayer_2(x_3)\nx_4 = qlayer_2(x_4)\n\n\nx_1, x_2, x_3,x_4 = tf.split(x, 4, axis=1)\nx = tf.concat([x_1, x_2, x_3,x_4], axis=1)\noutputs = clayer_2(x)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nopt = Adam(learning_rate=0.001)\nmodel.compile(\n    optimizer=opt,\n    loss=sparse_categorical_crossentropy,\n    metrics=['accuracy'],\n)\nbs = 8\nn_epoch = 10\nmodel.fit(\n    q_train_images,\n    y_train,\n    batch_size=bs,\n    epochs=n_epoch,\n    validation_data=(q_test_images, y_test),\n)\n\nI am omitting the data preparation part, downloaded MNIST, perfored quantum convolution exactly like in tutorial and developed the model above.\nThe above model has total 9550 trainable parameters  model.summary()the training accuracy of 0.8452 and validation accuracy of 0.7580.\nThe corresponding the classical model having same number of trainable parameters (9550) is:\ncmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(784,)),\n  tf.keras.layers.Dense(12,activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\n\ncmodel.compile(\n    optimizer=opt,\n    loss=sparse_categorical_crossentropy,\n    metrics=['accuracy'], )\ncmodel.fit(\n    x_train,\n    y_train,\n    batch_size=8,\n    epochs=10,\n    validation_data=(x_test, y_test),\n)\n\nThe training accuracy in purely classical model is 0.9750 and validation accuracy is 0.8890.\n\nwhy does both hybrid and classical model have the same number of trainable parameters?\nAlthough the convolution is performed using quantum circuit, still a very simple classical model performs way better than hybrid model, and classical convolution NN with the same trainable parameters would be even better, I believe. Is there any way that hybrid networks can be made close to classical CNN\u2019s, if not better?\n\n\n\n\n Tom_Bromley:\n\nFor now, your options are to use a smaller dataset (number of images, or resolution) as well as to make sure you are squeezing the best performance from your computer. Make sure that you are using the backprop or adjoint differentiation methods, since this will provide a significant speedup during training (note that you may already be using backprop).\n\n\nI tried adjoint, no significant effect on time being taken to perform quantum convolution.\nThanks for the help\u2026", "link": "https://discuss.pennylane.ai//t/quantum-neural-networks-quanvolutional-nn/1111/3"}, "3": {"author": "Tom_Bromley", "date": "1623678566012", "content": "Hey @Muhammad_Kashif, thanks for sharing!\nLooking at the code you shared, the model-setup part seems to make the output of the model independent of the qlayers. For the following:\ninputs = tf.keras.Input(shape=(784,))\nkeras.layers.Flatten(),\nx = clayer_1(inputs)\nx_1, x_2, x_3,x_4 = tf.split(x, 4, axis=1)\nx_1 = qlayer_1(x_1)\nx_2 = qlayer_2(x_2)\nx_3 = qlayer_2(x_3)\nx_4 = qlayer_2(x_4)\n\n\nx_1, x_2, x_3,x_4 = tf.split(x, 4, axis=1)\nx = tf.concat([x_1, x_2, x_3,x_4], axis=1)\noutputs = clayer_2(x)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nIf I understand correctly, isn\u2019t the second line of x_1, x_2, x_3,x_4 = tf.split(x, 4, axis=1) taking x as an input and hence bypassing the outputs of the quantum layers? I believe the quantum part of the code actually isn\u2019t being called, since I had to update the following lines to get the KerasLayer to evaluate:\nreturn qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliX(2))\n\nand\nweight_shapes = {\"weights\": (n_layers, n_qubits, 3)}   \n\nThe way I normally approach these problems is to slowly introduce the quantum part to the model without worrying about performance. E.g.,\n\nSet up model with all classical layers and check it trains\nIntroduce the simplest quantum circuit to one part of the model. Check that the model outputs and that you can access its gradient.\nScale the model up by making the quantum part more complex.\n\nI think it might be an idea to avoid the splitting into 4 quantum circuits here (at first), and just see if you can pass through one quantum layer successfully.", "link": "https://discuss.pennylane.ai//t/quantum-neural-networks-quanvolutional-nn/1111/4"}, "4": {"author": "SuFong_Chien", "date": "1623811045837", "content": "Hi\nI just got a paper last night. It is worth thinking about the issue of QNN vs CNN. I just scanned through the paper. It seems that they put a lots of efforts in the work.\n\u201cThe dilemma of quantum neural networks\u201d\n\n\narxiv.org\n\n\n\n2106.04975.pdf 5\n1265.65 KB\n\n\n\n\n\n1", "link": "https://discuss.pennylane.ai//t/quantum-neural-networks-quanvolutional-nn/1111/5"}, "5": {"author": "Muhammad_Kashif", "date": "1623836312916", "content": "Hi @SuFong_Chien,\nThanks for sharing the paper, it definitely would be quite helpful moving forward.\nHi @Tom_Bromley,\nFollowing the suggestions I only used one quantum layer and it seems to be working since the training is alittle slower in comparison with classical. Just a couple of simple questions based on the previous conversation in this thread:\n\n\nIn tutorials what is n_layers (only used while defining weight_shapes) and weight_shapes, in the first tutorial weight_shapes is two parameters and in the second one, it has three-parameter.  Does it depend on the no. of qubits used, if yes then what of we want to lets say more than 10 qubits, what would be the weight_shapes then?\n\n\nWoud the different data embedding techniques like amplitude embedding, angle embedding among others effect the underlying model\u2019s performance? and also what could be the potential effect of StronglyEntanglingLayers or BasicEntanglingLayers on model performance?\n\n\nwhile printing the model summary in keras (for a model with quantum layers) does not show any zero trainable paramters for quantum layer and \u201cunused\u201d notification as well, why is that so? Below is the model code and corresponding screenshot.\nCode:\nqlayer_1 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\ninputs = tf.keras.Input(shape=(784,))\nx = tf.keras.layers.Dense(2, activation=\"relu\")(inputs)\nx = qlayer_1(x)\noutputs = tf.keras.layers.Dense(10, activation='softmax')(x)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs) \nmodel.summary()\n\nOutput summary:\n\nThanks for the help.", "link": "https://discuss.pennylane.ai//t/quantum-neural-networks-quanvolutional-nn/1111/6"}, "6": {"author": "Tom_Bromley", "date": "1623854258836", "content": "Hey @Muhammad_Kashif,\n\nIn tutorials what is n_layers (only used while defining weight_shapes) and weight_shapes, in the first tutorial weight_shapes is two parameters and in the second one, it has three-parameter. Does it depend on the no. of qubits used, if yes then what of we want to lets say more than 10 qubits, what would be the weight_shapes then?\n\nThe weight_shapes parameter is intended to let the qml.qnn.KerasLayer know the shapes of the trainable parameters in the QNode. It should be a dictionary that maps argument name to shape, for example:\n@qml.qnode(dev)\ndef qnode(inputs, w1, w2, w3):\n    ...\n    qml.RX(w1, wires=0)\n    qml.Rot(w2, wires=1)\n    qml.templates.StronglyEntanglingLayers(w3, wires=range(2))\n    ...\n\nIn this case, we should have weight_shapes = {\"w1\": 1, \"w2\": 3, \"w3\": (n_layers, 2, 3)}. It is easy to see this for w1 and w2, since w1 feeds into the single-parameter RX gate and w2 feeds into the three-parameter Rot gate. The shape of w3 is a bit more complicated because it feeds into StronglyEntanglingLayers. In this case, the shape must be (n_layers, n_wires, 3). For StronglyEntanglingLayers, we have multiple layers that look like:\nimage2683\u00d71054 216 KB\nEach qubit has a Rot gate applied followed by an entangling block. We must hence specify the number of layers and number of wires. Since Rot has three parameters, the overall shape is (n_layers, n_wires, 3).\n\nWoud the different data embedding techniques like amplitude embedding, angle embedding among others effect the underlying model\u2019s performance? and also what could be the potential effect of StronglyEntanglingLayers or BasicEntanglingLayers on model performance?\n\nDefinitely! There is a lot of room to play about with different embeddings and layers - check out the literature above to get more of an understanding.\n\nwhile printing the model summary in keras (for a model with quantum layers) does not show any zero trainable paramters for quantum layer and \u201cunused\u201d notification as well, why is that so? Below is the model code and corresponding screenshot\n\n That\u2019s odd.  I just tried the code below and the summary printed ok:\nimport pennylane as qml\nimport tensorflow as tf\n\nn_qubits = 2\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\nn_layers = 6\nweight_shapes = {\"weights\": (n_layers, n_qubits)}\n\nqlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\n\nclayer_1 = tf.keras.layers.Dense(4)\nqlayer_1 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nqlayer_2 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nclayer_2 = tf.keras.layers.Dense(2, activation=\"softmax\")\n\n# construct the model\ninputs = tf.keras.Input(shape=(2,))\nx = clayer_1(inputs)\nx_1, x_2 = tf.split(x, 2, axis=1)\nx_1 = qlayer_1(x_1)\nx_2 = qlayer_2(x_2)\nx = tf.concat([x_1, x_2], axis=1)\noutputs = clayer_2(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\nmodel.predict(tf.ones((5, 2)))\n\nwith the result\n>>> model.summary()\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 2)]          0                                            \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 4)            12          input_1[0][0]                    \n__________________________________________________________________________________________________\ntf.split (TFOpLambda)           [(None, 2), (None, 2 0           dense[0][0]                      \n__________________________________________________________________________________________________\nkeras_layer_1 (KerasLayer)      (None, 2)            12          tf.split[0][0]                   \n__________________________________________________________________________________________________\nkeras_layer_2 (KerasLayer)      (None, 2)            12          tf.split[0][1]                   \n__________________________________________________________________________________________________\ntf.concat (TFOpLambda)          (None, 4)            0           keras_layer_1[0][0]              \n                                                                 keras_layer_2[0][0]              \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 2)            10          tf.concat[0][0]                  \n==================================================================================================\nTotal params: 46\nTrainable params: 46\nNon-trainable params: 0\n__________________________________________________________________________________________________\n\n(note the code is adapted from this 3 tutorial).", "link": "https://discuss.pennylane.ai//t/quantum-neural-networks-quanvolutional-nn/1111/7"}, "7": {"author": "Muhammad_Kashif", "date": "1623928343032", "content": "Hi @Tom_Bromley,\nThanks for your input on weight-shape argument. it was quite helpful. I have a few more questions, sorry but as I am progressing step by step, questions/confusions arise. Thanks to this forum which helps get them clear.\nThe n_layer=n argument basically cascades the quantum circuit (stronglyEntanglingLayer, BasicEntanglingLayer or customized circuit), right? the other way of doing this can be to setn_layer=1,  and then create as many quantum layers as we want and then add them to model, it will do the same, right? what is more preferred and maybe more useful, since the n_layer argument is also passed as in weight_shapes.\nBoth the procedures above to add Q-layers cascade the Q-circuits, if we need to have parallel quantum circuits we need to split the first classical neuron layer and connect to subsequent quantum layers, right?\nBasisEmbedding can only be performed when the input data is onehotencoded, not otherwise, right? if yes, would other embedding techniques (AmplitudeEmbedding and AngleEmbedding) would be equivalent to one-hot encoded data as BasisEmbedding?\nDoes the qubits measurements like expval, probs etc would effect the overall model performance?\nif hybrid neural networks are run on quantum processors (IBM devices for instance), would it potentially reduce the training time, since we have classical layers as well in the network which could be hard to compute for quantum processors just like Q-layers for classical computers?\nRegarding the summary printing the same code you shared in previous message as a demo for printing summary is not working if we remove the following command model.predict(tf.ones((5, 2))) and the error that pops up is below:\n\nScreenshot%20(389)1489\u00d7601 31.4 KB\n\nThanks for the great help\u2026", "link": "https://discuss.pennylane.ai//t/quantum-neural-networks-quanvolutional-nn/1111/8"}, "8": {"author": "Tom_Bromley", "date": "1623931749796", "content": "Hey @Muhammad_Kashif,\n\nThe  n_layer=n argument basically cascades the quantum circuit ( stronglyEntanglingLayer , BasicEntanglingLayer or customized circuit), right?\n\nRight, the StronglyEntanglingLayers and similar layers simply define a fundamental unit circuit block and them stamps out repetitions (with different parameters) based on the shape of their input weights argument. This is the argument that you must specify the shape of in weight_shapes when creating your KerasLayer.\n\nthe other way of doing this can be to set n_layer=1 , and then create as many quantum layers as we want and then add them to model, it will do the same, right? what is more preferred and maybe more useful, since the n_layer argument is also passed as in weight_shapes .\n\nYou could set n_layer=1 and create multiple KerasLayer, but there would be multiple intermediate measurements where classical information is extracted and then put back into the next circuit. This may indeed work, but is different to using a single KerasLayer with many StronglyEntanglingLayers, which keeps everything on the quantum side. The problem may be the nomenclature is slightly confusing - we have quantum layers (e.g., StronglyEntanglingLayers) which are repetitions of circuit blocks all on the quantum side, and we also have layers in the sense of interfacing with the rest of Keras.\n\nBoth the procedures above to add Q-layers cascade the Q-circuits, if we need to have parallel quantum circuits we need to split the first classical neuron layer and connect to subsequent quantum layers, right?\n\nI think so, I believe this is also the standard approach in an all classical network where you have one layer splitting into parallel layers.\n\nBasisEmbedding can only be performed when the input data is onehotencoded , not otherwise, right? if yes, would other embedding techniques ( AmplitudeEmbedding and AngleEmbedding ) would be equivalent to one-hot encoded data as BasisEmbedding ?\n\nYes, the input data to BasisEmbedding can only be a binary string. You can also get AmplitudeEmbedding to behave the same by inputting a unit vector (which corresponds to the binary string).\n\nDoes the qubits measurements like expval , probs etc would effect the overall model performance?\n\nMost likely! Both the measurement type and observable (e.g., Z or XZ for example) will have an effect. We typically have gone for [qml.expval(qml.PauliZ(i)) for i in range(wires)].\n\nif hybrid neural networks are run on quantum processors (IBM devices for instance), would it potentially reduce the training time, since we have classical layers as well in the network which could be hard to compute for quantum processors just like Q-layers for classical computers?\n\nNote that the whole model isn\u2019t run on a quantum or classical processor, we simply split up so that a classical processor helps evaluate the gradient of classical layers and a quantum processor for the quantum layers. So the main choice in this setting is which device to execute your quantum circuit on - e.g., built in PennyLane simulators or plugin devices such as hardware backends.\n\nRegarding the summary printing the same code you shared in previous message as a demo for printing summary is not working if we remove the following command model.predict(tf.ones((5, 2))) and the error that pops up is below:\n\nI had a similar error if the model.predict(tf.ones((5, 2))) line isn\u2019t run. This is an easy way to build the model. If you\u2019re still getting that error with that line included, it may be a case of upgrading your version of TensorFlow perhaps?", "link": "https://discuss.pennylane.ai//t/quantum-neural-networks-quanvolutional-nn/1111/9"}, "9": {"author": "SuFong_Chien", "date": "1623939558527", "content": "Hi Tom\nSuddenly, I have two questions in mind for any QNNs. First, the classical one can keep all the trained weights that forms a model to be used for prediction. How does this work in QNN? Second question is that can QNN be trained in real time and use the model on the spot for prediction?", "link": "https://discuss.pennylane.ai//t/quantum-neural-networks-quanvolutional-nn/1111/10"}, "10": {"author": "nathan", "date": "1623963461827", "content": "Hi @SuFong_Chien,\nYes, both of the things you ask about, which are common in classical ML, are also possible with quantum models.\n\n\nOne can certainly save the trained weights of a model, even if it involves running on a quantum computer. After all, the weights are still classical variables! There are no conceptual barriers to this. One point to keep in mind is that classical ML libraries are older and more heavily developed than QML libraries, so while there is no barrier to saving quantum models & parameters, QML libraries are not quite as fully featured in this department as classical ML libraries. For sure you could manually save a quantum model\u2019s parameters, but automatic methods for doing this might not be available quite yet\n\n\nYou can definitely use a QML model in an online learning setting as you describe. However, since access to quantum computers can be costly, with today\u2019s devices it might be more economical to update the model as sizable enough batches of training data come in, rather than continually update a model\u2019s parameters in real time \n\n1", "link": "https://discuss.pennylane.ai//t/quantum-neural-networks-quanvolutional-nn/1111/11"}}