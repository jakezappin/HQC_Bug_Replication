{"0": {"author": "Muhammad_Kashif", "date": "1624880867344", "content": "Hi,\nI was trying the diff-method = \"adjoint\" with AmplitudeEmbedding but it does not seem to be working (error-attached screenshot) however, it works fine with AngleEmbedding. And backprop is working with both.\n\nScreenshot%20(3)1014\u00d7350 23.5 KB\n\nBelow is my code:\nn_train = 10000\nn_test=3000\n\nmnist_dataset = keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = mnist_dataset.load_data()\nx_train = x_train[:n_train]\ny_train = y_train[:n_train]\nx_test = x_test[:n_test]\ny_test = y_test[:n_test]\nx_train, x_test = (x_train / 255.0), (x_test / 255.0)\n\n\nx_train = x_train.reshape(-1, 784) # 784 = 28x28\nx_test = x_test.reshape(-1, 784)\nx_test.shape\n\nn_qubits = 1\ndev = qml.device(\"default.qubit\",  wires=n_qubits)\n\n@qml.qnode(dev, interface = \"tf\", diff_method=\"adjoint\")\ndef qnode(inputs, weights):\n    qml.templates.AmplitudeEmbedding(inputs, wires=range(n_qubits), pad_with=0.,  normalize = True)\n#     qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits),rotation = qml.RY)\n#     qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\nn_layers = 1\n# weight_shapes = {\"weights\": (n_layers, n_qubits, 3)}\n\nweight_shapes = {\"weights\": (n_layers, n_qubits)}\n# re-define the layers\n\nqlayer_1 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nqlayer_2 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nqlayer_3 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nqlayer_4 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\n\n\ninputs = tf.keras.Input(shape=(784,))\n\nx = tf.keras.layers.Dense(4)(inputs)\n\n\nx_1, x_2, x_3, x_4 = tf.split(x, 4, axis=1)\nx_1 = qlayer_1(x_1)\nx_2 = qlayer_2(x_2)\nx_3 = qlayer_3(x_3)\nx_4 = qlayer_4(x_4)\nx = tf.concat([x_1, x_2, x_3, x_4 ], axis=1)\n\noutputs =  tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n\n\nfrom tensorflow.keras.optimizers import SGD, Adam\nopt = Adam(learning_rate=0.01)\nmodel.compile(opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\nhistory = model.fit(x_train, y_train, epochs=100, batch_size=16, validation_data=(x_test, y_test))\n\nIs the model above computes quantum gradients as well and optimize the loss, since I can not see any significant difference in performance when compared with its classical counterpart, except the convergence time of hybrid model (above) is significantly higher that classical one.\nMoreover, if we increase the dataset size (currently MNIST (10k,3k)), should the percent increase of convergence time of hybrid model should be less than that of classical model (that is not the case with above model), because that is what quantum computation promises, faster computation?\nis there any way that I can run this same model (above) on IBM real quantum device to better compare the performance and convergence time. I am curious if the quantum processor would recognize the keras commands like compile, fit etc\u2026\nAny help would be appreciated.\nthanks", "link": "https://discuss.pennylane.ai//t/differentiation-method-and-amplitude-embedding/1153/1"}, "1": {"author": "theodor", "date": "1624903906658", "content": "Hi @Muhammad_Kashif,\nThank you for posting your questions here in the forum. Quantum computing has potential to provide significant speed-ups in certain cases, although it\u2019s very much still a research question whether quantum machine learning can perform better than its classical counterpart, and, if so, where it excels. You shouldn\u2019t expect any improvements by running quantum simulations, like this one, and it\u2019s expected that a classical simulation would optimize faster.\nUnfortunately, there\u2019s no quantum hardware that would be able to use Keras intrinsically, although you could attempt to run the circuit on hardware while still using Keras to do the optimizations classically. If you want to use the IBM quantum device with PennyLane, you can read more about it here 2.\nRegarding the issue when using the adjoint method, I\u2019m not sure why that is. I had to set the floating point precision for Keras to float64 (with tf.keras.backend.set_floatx('float64')) to get it to work with backprop, though. Thanks for bringing it to our attention. \nLet me know if you have any further questions!", "link": "https://discuss.pennylane.ai//t/differentiation-method-and-amplitude-embedding/1153/2"}, "2": {"author": "Muhammad_Kashif", "date": "1624963552199", "content": "Hi @theodor,\nThanks for answering.\nI tried running the same model (previous message in this thread) using the tutorial you directed. After loading my account token etc, I added the following line: all the rest of the code is same.\ndev = qml.device('qiskit.ibmq', wires=1, backend = 'ibmq_manila')\nand tried running the model using model.fit but it is stuck (screenshot below) for around 24 hours. I am not sure if I am doing some mistake or i am in queue or what? Does the above line mean to run the quantum circuit on quantum processor?\nI am really curious if there is any speed improvement if we run hybrid network on quantum computer.\nScreenshot of stucked simulation on real quantum device:\n\nScreenshot%20(5)1022\u00d7270 10.8 KB\n\nregarding the diff_method, the backprop is working with both (amplitude and angle embedding) but adjoint is not working with amplitude embedding. Please let me know if there is any progress on this issue.\nthanks for the help.", "link": "https://discuss.pennylane.ai//t/differentiation-method-and-amplitude-embedding/1153/3"}, "3": {"author": "theodor", "date": "1624991512126", "content": "Hi @Muhammad_Kashif. It\u2019s likely that the job is stuck in a queue waiting for access to the quantum device. Either way, it\u2019ll run much slower on quantum hardware devices since there will need to be a lot of slow device calls for hardware-evaluated gradients. Unfortunately, I wouldn\u2019t expect any real improvements running on current hardware devices, even though it\u2019s always exciting to experiment with it.\nRegarding using the adjoint method, I believe it might actually have to do with AmplitudeEmbedding not being differentiable, and thus complaining when attempting gradient-based optimization methods. I\u2019m not sure why it doesn\u2019t complain when using the \u201cbackprop\u201d differentiation method. A work-around could be using the M\u00f6tt\u00f6nen state preparation method 14 instead, which can be seen as a decomposition of an amplitude embedding.\nLet me know if this works out!", "link": "https://discuss.pennylane.ai//t/differentiation-method-and-amplitude-embedding/1153/4"}, "4": {"author": "Muhammad_Kashif", "date": "1624880867344", "content": "Hi,\nI was trying the diff-method = \"adjoint\" with AmplitudeEmbedding but it does not seem to be working (error-attached screenshot) however, it works fine with AngleEmbedding. And backprop is working with both.\n\nScreenshot%20(3)1014\u00d7350 23.5 KB\n\nBelow is my code:\nn_train = 10000\nn_test=3000\n\nmnist_dataset = keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = mnist_dataset.load_data()\nx_train = x_train[:n_train]\ny_train = y_train[:n_train]\nx_test = x_test[:n_test]\ny_test = y_test[:n_test]\nx_train, x_test = (x_train / 255.0), (x_test / 255.0)\n\n\nx_train = x_train.reshape(-1, 784) # 784 = 28x28\nx_test = x_test.reshape(-1, 784)\nx_test.shape\n\nn_qubits = 1\ndev = qml.device(\"default.qubit\",  wires=n_qubits)\n\n@qml.qnode(dev, interface = \"tf\", diff_method=\"adjoint\")\ndef qnode(inputs, weights):\n    qml.templates.AmplitudeEmbedding(inputs, wires=range(n_qubits), pad_with=0.,  normalize = True)\n#     qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits),rotation = qml.RY)\n#     qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\nn_layers = 1\n# weight_shapes = {\"weights\": (n_layers, n_qubits, 3)}\n\nweight_shapes = {\"weights\": (n_layers, n_qubits)}\n# re-define the layers\n\nqlayer_1 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nqlayer_2 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nqlayer_3 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\nqlayer_4 = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits)\n\n\ninputs = tf.keras.Input(shape=(784,))\n\nx = tf.keras.layers.Dense(4)(inputs)\n\n\nx_1, x_2, x_3, x_4 = tf.split(x, 4, axis=1)\nx_1 = qlayer_1(x_1)\nx_2 = qlayer_2(x_2)\nx_3 = qlayer_3(x_3)\nx_4 = qlayer_4(x_4)\nx = tf.concat([x_1, x_2, x_3, x_4 ], axis=1)\n\noutputs =  tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n\n\nfrom tensorflow.keras.optimizers import SGD, Adam\nopt = Adam(learning_rate=0.01)\nmodel.compile(opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\nhistory = model.fit(x_train, y_train, epochs=100, batch_size=16, validation_data=(x_test, y_test))\n\nIs the model above computes quantum gradients as well and optimize the loss, since I can not see any significant difference in performance when compared with its classical counterpart, except the convergence time of hybrid model (above) is significantly higher that classical one.\nMoreover, if we increase the dataset size (currently MNIST (10k,3k)), should the percent increase of convergence time of hybrid model should be less than that of classical model (that is not the case with above model), because that is what quantum computation promises, faster computation?\nis there any way that I can run this same model (above) on IBM real quantum device to better compare the performance and convergence time. I am curious if the quantum processor would recognize the keras commands like compile, fit etc\u2026\nAny help would be appreciated.\nthanks", "link": "https://discuss.pennylane.ai//t/differentiation-method-and-amplitude-embedding/1153/5"}, "5": {"author": "Muhammad_Kashif", "date": "1624963552199", "content": "Hi @theodor,\nThanks for answering.\nI tried running the same model (previous message in this thread) using the tutorial you directed. After loading my account token etc, I added the following line: all the rest of the code is same.\ndev = qml.device('qiskit.ibmq', wires=1, backend = 'ibmq_manila')\nand tried running the model using model.fit but it is stuck (screenshot below) for around 24 hours. I am not sure if I am doing some mistake or i am in queue or what? Does the above line mean to run the quantum circuit on quantum processor?\nI am really curious if there is any speed improvement if we run hybrid network on quantum computer.\nScreenshot of stucked simulation on real quantum device:\n\nScreenshot%20(5)1022\u00d7270 10.8 KB\n\nregarding the diff_method, the backprop is working with both (amplitude and angle embedding) but adjoint is not working with amplitude embedding. Please let me know if there is any progress on this issue.\nthanks for the help.", "link": "https://discuss.pennylane.ai//t/differentiation-method-and-amplitude-embedding/1153/6"}}