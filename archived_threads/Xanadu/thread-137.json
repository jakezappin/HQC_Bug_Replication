{"0": {"author": "Andre_Sequeira", "date": "1606954377088", "content": "Hi,\ni have the following quantum circuit. I got the error\n\u201cTypeError: Grad only applies to real scalar-output functions. Try jacobian, elementwise_grad or holomorphic_grad.\u201d\nwhile trying to optimize the cost function. What can\u2019t i do this?\nThank you in advance.\nn_qubits = 4 # 4 actions for lunar lander \ndevice = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(device)\ndef qcircuit(weights, input = None):\n    AngleEmbedding(input, wires=range(n_qubits))\n    SEL(weights, wires=range(n_qubits))\n    \n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\ndef softmax(x):\n    return [np.exp(i) / np.sum(np.exp(i)) for i in x]\n\ndef one_hot(labels, num_labels):\n    one_hot_diag_matix = np.identity(num_labels)\n    return [one_hot_diag_matix[i] for i in labels]\n\ndef cross_entropy_loss(dist, labels, num_labels):\n    p = softmax(dist)\n    one_hot_labels = one_hot(labels,num_labels)\n    \n    results = []\n    for pd,l in zip(p,one_hot_labels):\n        results.append(-np.sum([l[i]*np.log(pd[i]) for i in range(num_labels)]))\n\n    return np.mean(results)\n\ndef cost(weights, labels, inputs):\n    predictions = [qcircuit(weights, input=i) for i in inputs]\n    return cross_entropy_loss(predictions, labels, inputs.shape[1])\n\n\nmax_steps = 60\nopt = qml.AdamOptimizer(0.3)\nnlayers = 1\n\nnp.random.seed(42)\n\ninputs = np.random.random((10,4))\noutput = np.random.choice([0,1],10)\nweights = 2*np.pi*np.random.random((nlayers,n_qubits,3))\n\nfor step in range(max_steps):\n    weights = opt.step(lambda w: cost(w,output,inputs), weights)\n    print(\"{}\\n{}\".format(step,weights))\n    print(\"Cost at step {} ---> {}\".format(cost(weights,output, inputs)))", "link": "https://discuss.pennylane.ai//t/grad-only-applies-to-real-scalar-output-functions/708/1"}, "1": {"author": "josh", "date": "1606980215398", "content": "Hi @Andre_Sequeira!\nI am able to get your code running by replacing the np.mean(result) with np.mean(np.array(result)). For the autodifferentiation of np.mean to work, the input should (as far as I can tell) always be a NumPy array.\nThe full code is below:\nimport pennylane as qml\nfrom pennylane import numpy as np\n\nn_qubits = 4 # 4 actions for lunar lander\ndevice = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(device)\ndef qcircuit(weights, input = None):\n    qml.templates.AngleEmbedding(input, wires=range(n_qubits))\n    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\ndef softmax(x):\n    return [np.exp(i) / np.sum(np.exp(i)) for i in x]\n\ndef one_hot(labels, num_labels):\n    one_hot_diag_matix = np.identity(num_labels)\n    return [one_hot_diag_matix[i] for i in labels]\n\ndef cross_entropy_loss(dist, labels, num_labels):\n    p = softmax(dist)\n    one_hot_labels = one_hot(labels,num_labels)\n\n    results = []\n    for pd,l in zip(p,one_hot_labels):\n        results.append(-np.sum([l[i]*np.log(pd[i]) for i in range(num_labels)]))\n\n    return np.mean(np.array(results))\n\ndef cost(weights, labels, inputs):\n    predictions = [qcircuit(weights, input=i) for i in inputs]\n    return cross_entropy_loss(predictions, labels, inputs.shape[1])\n\n\nmax_steps = 60\nopt = qml.AdamOptimizer(0.3)\nnlayers = 1\n\nnp.random.seed(42)\n\ninputs = np.random.random((10,4))\noutput = np.random.choice([0,1],10)\nweights = qml.init.strong_ent_layers_normal(n_layers=nlayers, n_wires=n_qubits)\n\nfor step in range(max_steps):\n    weights, cost_value = opt.step_and_cost(lambda w: cost(w,output,inputs), weights)\n    print(\"{}\\n{}\".format(step,weights))\n    print(\"Cost at step {} ---> {}\".format(step, cost_value))\n\nLet me know if this works!\nNote that I also made an additional change; I replaced opt.step with opt.step_and_cost(), which will avoid the overhead of computing the cost function twice. This is a new feature of PennyLane v0.13, released last week 1.", "link": "https://discuss.pennylane.ai//t/grad-only-applies-to-real-scalar-output-functions/708/2"}, "2": {"author": "Andre_Sequeira", "date": "1606995679050", "content": "Hi @josh, thank you so much for your help. I can run the code now \n\n\n\n josh:\n\nNote that I also made an additional change; I replaced opt.step with opt.step_and_cost() , which will avoid the overhead of computing the cost function twice. This is a new feature of PennyLane v0.13, released last week.\n\n\nAmazing ! We were all been hoping for this for a while now. Keep on the good work!3", "link": "https://discuss.pennylane.ai//t/grad-only-applies-to-real-scalar-output-functions/708/3"}, "3": {"author": "Andre_Sequeira", "date": "1606954377088", "content": "Hi,\ni have the following quantum circuit. I got the error\n\u201cTypeError: Grad only applies to real scalar-output functions. Try jacobian, elementwise_grad or holomorphic_grad.\u201d\nwhile trying to optimize the cost function. What can\u2019t i do this?\nThank you in advance.\nn_qubits = 4 # 4 actions for lunar lander \ndevice = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(device)\ndef qcircuit(weights, input = None):\n    AngleEmbedding(input, wires=range(n_qubits))\n    SEL(weights, wires=range(n_qubits))\n    \n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\ndef softmax(x):\n    return [np.exp(i) / np.sum(np.exp(i)) for i in x]\n\ndef one_hot(labels, num_labels):\n    one_hot_diag_matix = np.identity(num_labels)\n    return [one_hot_diag_matix[i] for i in labels]\n\ndef cross_entropy_loss(dist, labels, num_labels):\n    p = softmax(dist)\n    one_hot_labels = one_hot(labels,num_labels)\n    \n    results = []\n    for pd,l in zip(p,one_hot_labels):\n        results.append(-np.sum([l[i]*np.log(pd[i]) for i in range(num_labels)]))\n\n    return np.mean(results)\n\ndef cost(weights, labels, inputs):\n    predictions = [qcircuit(weights, input=i) for i in inputs]\n    return cross_entropy_loss(predictions, labels, inputs.shape[1])\n\n\nmax_steps = 60\nopt = qml.AdamOptimizer(0.3)\nnlayers = 1\n\nnp.random.seed(42)\n\ninputs = np.random.random((10,4))\noutput = np.random.choice([0,1],10)\nweights = 2*np.pi*np.random.random((nlayers,n_qubits,3))\n\nfor step in range(max_steps):\n    weights = opt.step(lambda w: cost(w,output,inputs), weights)\n    print(\"{}\\n{}\".format(step,weights))\n    print(\"Cost at step {} ---> {}\".format(cost(weights,output, inputs)))", "link": "https://discuss.pennylane.ai//t/grad-only-applies-to-real-scalar-output-functions/708/4"}}