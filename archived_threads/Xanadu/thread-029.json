{"0": {"author": "angelinaG", "date": "1580116411412", "content": "I am curious to understand why does the IBMQDevice keep executing the code endlessly?\nI am referring to the Quantum transfer learning code (ants vs. bees classification) from (Mari et al., 2019 Link:https://arxiv.org/pdf/1912.08278.pdf 6\ncode link: https://pennylane.ai/qml/app/tutorial_quantum_transfer_learning.html 9).\nThough I specify the number_of_epochs = 1 and the shots=1 for \u2018ibmqx2\u2019 device, the execution seems endless on the quantum hardware.\nPlus the fact that I am unable to track the training progress on my system (this only worked with the simulator).\nAm I missing some code segment to get back the results from the quantum hardware?\nAt present I only replaced the \u2018default.qubit\u2019 device to the actual ibm machine i.e.\nFrom, p_device = qml.device(\u201cdefault.qubit\u201d, wires=n_qubits)\nTo, p_device = IBMQDevice(wires=n_qubits, backend=\u2018ibmqx2\u2019, shots=1)\nI am a novice in quantum computing, please pardon my query. I assumed 1 shot = 1 run on the quantum hardware.\nOn checking the IBMQ account, it displays the number of shots =1 correctly yet it seems to be executing for a lot of runs i.e. I could see 415 results (with status: COMPLETED) displayed for that particular job.\nDoes that have any connection with the stability of the actual quantum device? Or is the learning rate and the decay in the learning rate responsible for this?\nFurther details:\nThe following piece of code seems to execute endlessly\nmodel_hybrid = train_model(\nmodel_hybrid, loss_function, optimizer_hybrid, exp_lr_scheduler, num_epochs=num_epochs\n)\nCould you please help me understand the same?\nThank you.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/1"}, "1": {"author": "andreamari", "date": "1580142927894", "content": "Hi @angelinaG, thanks for your post!\nUsing a real device can take a long time especially if the device is busy (long queues of IBM users) so, probably, what you are reporting is normal. However I would like to give you some tips which could be useful:\n\nIn our paper we first trained the model with a simulator and then we only executed it (with fixed parameters) on a real device. This is quite easier with respect to training. This is the code that we used: https://github.com/XanaduAI/quantum-transfer-learning/tree/master/quantum_processors 17\n\nYou could first try to use the IBM could simulator, just to check if everything runs smoothly with your settings of the IBM plugin. If I remember correctly, this can be done by just replacing the keyword ibmqx2 with qasm_simulator.\nI think that it is normal that you see many jobs even if shots=1. Even in this case, the number of jobs is at least equal to the number of expectation values that you need to compute. If you classify many input images or if you train many parameters, you need to evaluate many expectation values. So this looks normal.\nYou linked the transfer learning tutorial however, if you are interested in reproducing the results of the paper, you may find more useful the actual quantum transfer learning repository:  https://github.com/XanaduAI/quantum-transfer-learning 6\n\n2", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/2"}, "2": {"author": "angelinaG", "date": "1580186335197", "content": "Thank you so much Dr. Andrea Mari for this explanation.\nThe link https://github.com/XanaduAI/quantum-transfer-learning/tree/master/quantum_processors 11 is what I was looking for.\nI shall try that out.\nAlso, I missed mentioning that I was able to reproduce your results using the simulator on PennyLane.\nSince I was trying to train the model on the quantum hardware it seemed like an endless execution. I understand that I can use the saved weights obtained by training on the simulator which will save time.\nI also wish to acknowledge Dr. Maria Schuld for her timely inputs and direction to reach out to you! I shall keep you posted with the results of the experiment.\nThank you once again!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/3"}, "3": {"author": "angelinaG", "date": "1580312421967", "content": "I was able to successfully execute the code on the IBMQ machine.1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/4"}, "4": {"author": "angelinaG", "date": "1600173517513", "content": "I was waiting for this moment to announce that with the prompt responses received from the Xanadu-PennyLane team, special mention to @Maria_Schuld, @andreamari, and @josh (for liking the post), I was able to publish the results of this experiment in the \u201cInternational Journal of Quantum Information\u201d Link to the paper\u2013> https://www.worldscientific.com/doi/10.1142/S0219749920500240 13\nThank you so much for all the support.1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/5"}, "5": {"author": "josh", "date": "1600174234831", "content": "Congrats @angelinaG! 1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/6"}, "6": {"author": "angelinaG", "date": "1600178772881", "content": "Thank you so much Josh ", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/7"}, "7": {"author": "Jerry2001Qu", "date": "1603589131577", "content": "Hey, I was wondering what it would take to train this Transfer Learning code on IBM\u2019s QCs?\nFrom my understanding, it would currently take >512 jobs to calculate the gradients (due to the 512xN_Qubits fully connected layer before the qnet):\n\nDo you think freezing that layer would allow us to calculate gradients in a reasonable time? Perhaps initializing those weights through a classical pretraining routine.1 Reply", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/8"}, "8": {"author": "Jerry2001Qu", "date": "1603589496930", "content": "Also, are there QCs out there that can run that many jobs (>10000) in a reasonable time? Like, through a paid/corporate IBM quantum computer?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/9"}, "9": {"author": "angelinaG", "date": "1603591495319", "content": "Hi @Jerry2001Qu,\nWell, this code that you are referring to is part of the dressed quantum circuit. So, in the dressed quantum circuit, we have a hybrid classical-quantum-classical connection, i.e. a classical pre-processing layer, a quantum network and a classical post-processing layer. What you observe as the nn.Linear layers (PyTorch implementation) are actually classical layers running on the classical system itself. Here, the last but the final layer of the ResNet18 model, comprising 512 output neurons (or connections) is passed to the classical sequential layer, namely nn.Linear(), which outputs 4 neurons (values for the input qubits, i.e. nn.Linear(512, nqubits)).\nThe next layer is the actual quantum network, which accepts only 4 inputs and produces 4 outputs. So, the 4 classical neurons (obtained from the previous classical layer) are then embedded in the quantum circuit by performing single-qubit rotations and a Hadamard gate. After embedding them, the quantum variational layer (comprising 6 layers) operates on the qubits and finally the output is measured and passed onto the classical post processing layer of the dressed quantum circuit.\nSo, the last nn.Linear layer accepts the 4 output quantum states (measured on the classical register using the Pauli-Z matrix) and finally produces the 2 output states (nn.Linear(4, 2) = nn.Linear(nqubits, nclasses)) for classifying ants vs. bees as mentioned in the illustrated example by Mari et al. (2019).  For further details, you can also refer to my paper mentioned on the forum to see how we applied Mari et al.'s method to detecting image splicing forgery.\nIn short, essentially only 4 qubit states are being processed iteratively on the qauntum simulator and the processor.\nHope this helps. Thank you.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/10"}, "10": {"author": "Jerry2001Qu", "date": "1603637131978", "content": "Then, why does it take >100 jobs to calculate the gradient for a single training example? If it was just calculating parameter shifts for the RY gates, that\u2019d be around N_QubitsxQ_Depthx2 jobs, from my understanding. However, even when I strip down the model to 2 qubits, and a depth of 3, it\u2019s still going over 100 jobs for a single training example (batch size 1).", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/11"}, "11": {"author": "Tom_Bromley", "date": "1603726925997", "content": "Hi @Jerry2001Qu, and thanks @angelinaG for your answer!\nWe recently introduced a new attribute to the device: dev.num_executions, which makes it easy to track the number of device executions. You could do this on simulator before trying to run on hardware. This feature can be accessed by installing 1 the development version of PennyLane.\nFor example, the following shows a benchmark of the number of device executions on a 4-qubit, 6-layer circuit:\nimport pennylane as qml\nimport torch\n\nnqubits = 4\nnlayers = 6\ndev = qml.device(\"default.qubit\", wires=nqubits)\n\n\n@qml.qnode(dev, interface=\"torch\")\ndef qcircuit(inputs, weights):\n    for i in range(nqubits):\n        qml.Hadamard(wires=i)\n        qml.RY(inputs[i], wires=i)\n    qml.templates.BasicEntanglerLayers(weights, wires=range(nqubits))\n    return [qml.expval(qml.PauliZ(i)) for i in range(nqubits)]\n\n\nweight_shapes = {\"weights\": (nlayers, nqubits)}\ninputs = torch.ones(nqubits, requires_grad=True)\n\nqlayer = qml.qnn.TorchLayer(qcircuit, weight_shapes)\n\nout = torch.sum(qlayer(inputs))\nout.backward()\n\nprint(f\"Number of executions: {dev.num_executions}\")\n\nn_exec_basic = nqubits * nlayers * 2\nn_ry = nqubits * 2\nn_expected = n_ry + n_exec_basic + 1  # the 1 comes from the forward pass\n\nprint(f\"Expected number of executions: {dev.num_executions}\")\n\nThe result is 57 device executions. We can also look at the dressed quantum circuit:\nclayer1 = torch.nn.Linear(512, 4)\nclayer2 = torch.nn.Linear(4, 2)\n\nhybrid = torch.nn.Sequential(clayer1, qlayer, clayer2)\ninputs = torch.ones(512, requires_grad=True)\n\ndev._num_executions = 0\n\nout = torch.sum(qlayer(inputs))\nout.backward()\n\nprint(f\"Number of executions: {dev.num_executions}\")\n\nThis also gives 57 executions, so it doesn\u2019t look like the hybrid element is increasing things (as expected).\nIn terms or training on IBMQ, we had a discussion on improving performance on another thread 3. I would say that this is quite a heavy task for optimization on hardware right now. One thing you could consider is training on simulator and testing (i.e., forward passes, which are much cheaper) on hardware.1 Reply3", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/12"}, "12": {"author": "Jerry2001Qu", "date": "1603728975139", "content": "Awesome! Thanks for the help @Tom_Bromley\nMay I ask, what is n_ry?\nI think I understand n_exec_basic (to do param shift for the BasicEntanglerLayers I assume).\nBut I don\u2019t understand where the executions for n_ry comes from.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/13"}, "13": {"author": "Tom_Bromley", "date": "1603729821374", "content": "Yes, n_exec_basic is equal to the number of gates in the BasicEntanglerLayers multiplied by 2.\nHowever, we also want to differentiate with respect to the RY gates which are used to input the data. We hence have to do a forward and backward shift (for the parameter shift rule) to evaluate the gradient when the input parameters are included, which is something we need to do if the quantum circuit is placed within a larger hybrid model. The n_ry parameter is just the number of circuit executions due to finding the gradient with respect to the input parameters: # of RY gates (=# of qubits = 4) * 2 (for parameter shift rule).1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/14"}, "14": {"author": "angelinaG", "date": "1603761337560", "content": "Thank you @Tom_Bromley. I shall check this feature and revert in case of further queries.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/15"}, "15": {"author": "dancbeaulieu", "date": "1627502059868", "content": "Hi, I am having an issue getting \u201chttps://github.com/XanaduAI/quantum-transfer-learning/blob/master/quantum_processors/run_on_QPU.py 1\u201d to run on IBM Quantum hardware. I am not sure what I am doing wrong. My only modification to the code is where the connection to the IBM Q network takes place:\nprovider = IBMQ.load_account()\nIBMQ.get_provider(hub=\u2018HUB\u2019, group=\u2018GROUP\u2019, project=\u2018PROJECT\u2019)\ndev = qml.device(\u2018qiskit.ibmq\u2019, wires=n_wires, backend=\u2018ibmq_bogota\u2019, provider=provider, shots=100)\nIt never runs on the quantum hardware. I get results in the notebook but it never executes. What am I doing wrong? I am correctly loading quantum_weights.pt.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/16"}, "16": {"author": "Tom_Bromley", "date": "1627505005921", "content": "Hey @dancbeaulieu!\n\nMy only modification to the code is where the connection to the IBM Q network takes place\n\nYes the code you\u2019ve added looks great!\n\nIt never runs on the quantum hardware. I get results in the notebook but it never executes.\n\nTo help me understand, is your issue that:\n\nThe whole script runs but you can\u2019t see the jobs executed when you visit the jobs board on the IBMQ website?\nThe script runs up to a point but then exits out with an error?\nThe script hangs/takes forever to run?\n", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/17"}, "17": {"author": "dancbeaulieu", "date": "1627519771876", "content": "There are no errors, but when I get to this part of the script runs 1/39 iterations, regardless of the number of epochs I input. Also, it looks like even though I am invoking the IBM quantum hardware, it never appears to run on the IBM hardware. I am in a position where it runs, I get no errors, but it doesn\u2019t seem to be running on any IBM Quantum hardware. Can you give me any advice about what I can do to get it to actually run on IBM Quantum hardware?\nThe following print statements produce no output:\nprint(\n\u201cResults of the model testing on a real quantum processor.\u201d,\nfile=open(\u201cresults_\u201d + backend + \u201c.txt\u201d, \u201cw\u201d),\n)\nprint(\"QPU backend: \" + backend, file=open(\u201cresults_\u201d + backend + \u201c.txt\u201d, \u201ca\u201d))\nAnd neither do the next set of print statements:\nprint(\"\\nTest Loss: {:.4f} Test Acc: {:.4f}        \".format(epoch_loss, epoch_acc))\nLog to file\nprint(\n\"\\nTest Loss: {:.4f} Test Acc: {:.4f}        \".format(epoch_loss, epoch_acc),\nfile=open(\u201cresults_\u201d + backend + \u201c.txt\u201d, \u201ca\u201d),\n)\nHowever, I do get this counter for iterations, which is oddly set at X/39 and I can\u2019t change the number of iterations. I am baffled.\nIter: 2/39", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/18"}, "18": {"author": "Tom_Bromley", "date": "1627560033149", "content": "Hey @dancbeaulieu!\nMy recommendation would be to make a separate script that does a simple run on the quantum hardware and confirms everything is set up ok. You can then make sure the contents of the larger transfer learning script, where you load the device, match up with the script we know runs successfully.\nYou could try running the following to see if you get an output:\nimport pennylane as qml\nfrom qiskit import IBMQ\n\nIBMQ.load_account()\nprovider = IBMQ.get_provider(hub=\"HUB\", group=\"GROUP\", project=\"PROJECT\")\n\nbackend = provider.backends()[0].name()\nprint(f\"Running on backend {backend}\")\n\ndev = qml.device(\"qiskit.ibmq\", backend=backend, wires=1,  provider=provider, shots=2000)\n\n@qml.qnode(dev)\ndef f(x):\n    qml.RX(x, wires=0)\n    return qml.expval(qml.PauliZ(0))\n\nprint(f(0.5))\n\nWe should hopefully see this code print an output result and be visible as a job on IBMQ.2 Replies", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/19"}, "19": {"author": "dancbeaulieu", "date": "1627563546110", "content": "Hi, the code you sent me runs on quantum hardware, as does some other simple code I ran on actual quantum hardware \u201cibm_lagos\u201d, and it showed up in the IBM Q administration logs. It works, everything ran successfully. Its the transfer learning that I can\u2019t figure out, there are no errors, messages, or logs to analyze. So the issue is in the transfer learning code, and I\u2019m not sure what\u2019s going wrong.\nOutput:\n/Users/dabeaulieu/opt/anaconda3/envs/qnlp/lib/python3.8/site-packages/pennylane_qiskit/qiskit_device.py:315: UserWarning: verbose is not a recognized runtime option and may be ignored by the backend. self._current_job = self.backend.run(qcirc, shots=self.shots, **self.run_args)\n0.809", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/20"}, "20": {"author": "Tom_Bromley", "date": "1627679460232", "content": "Hey @dancbeaulieu!\nGlad that you\u2019re set up ok for sampling from the hardware, but I\u2019m not sure what the issue is with integrating the transfer learning code. I think the only solution here is to share the full script that you are running.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/21"}, "21": {"author": "dancbeaulieu", "date": "1627848260553", "content": "Hello,\nHere is the code I am using, hope you can help me figure this out. I have the PT weights file from the GitHub link above.\n#!/usr/bin/env python\ncoding: utf-8\nCopyright 2019 Xanadu Quantum Technologies Inc.\nLicensed under the Apache License, Version 2.0 (the \u201cLicense\u201d);\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\nhttp://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \u201cAS IS\u201d BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\u201c\u201d\u201cRunning a hybrid image classifier on IBM or Rigetti quantum processors.\u201d\"\"\nimport matplotlib.pyplot as plt\nPyTorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision\nfrom torchvision import datasets, models, transforms\nPennylane\nimport pennylane as qml\nfrom pennylane import numpy as np\nOther tools\nimport time\nimport os\nimport copy\nimport qiskit\nfrom qiskit import  QuantumCircuit, transpile, assemble, IBMQ#, Aer\nfrom qiskit.visualization import *\nfrom qiskit import IBMQ\nos.environ[\u201cOMP_NUM_THREADS\u201d] = \u201c1\u201d\nos.environ[\u201cCUDA_VISIBLE_DEVICES\u201d] = \u201c1\u201d\nSetting of the main parameters of the network model and of the training process.\nThese should match the topology of the saved pre-trained model (quantum_weights_pt).\nn_qubits = 4                # number of qubits\nstep = 0.0004               # learning rate\nbatch_size = 4              # number of samples for each training step\nnum_epochs = 1             # number of training epochs\nq_depth = 6                 # depth of the quantum circuit (number of variational layers)\ngamma_lr_scheduler = 0.1    # learning rate reduction applied every 10 epochs.\nn_quantum_layers = 15       # Keep 15 even if not all are used.\nq_delta = 0.01              # Initial spread of random quantum weights\nrng_seed = 0                # seed for random number generator\nstart_time = time.time()    # start of the computation timer\ndata_dir = \u201cdata/hymenoptera_data\u201d  # path of dataset\nn_wires = 4\nprovider = IBMQ.load_account()\n#Changed my details for hub, group and project because of security concerns\nIBMQ.get_provider(hub=\u2018hub\u2019, group=\u2018group\u2019, project=\u2018project\u2019)\ndev2 = qml.device(\u2018qiskit.ibmq\u2019, wires=n_wires, backend=\u2018ibmq_bogota\u2019, provider=provider, shots=100)\nChoose between the two quantum backends: \u2018ibm\u2019 or \u2018rigetti\u2019.\n========= QPU ==========\nbackend = \u201cibm\u201d\nbackend = \u2018rigetti\u2019\n========================\nSet the chosen backend as a PennyLane device.\nif backend == \u201cibm\u201d:\n#token = \u201c\u201d  # Insert your personal IBM token. Remove the token when sharing your code!\ndev = qml.device(\u2018qiskit.ibmq\u2019, wires=n_wires, backend=\u2018ibmq_qasm_simulator\u2019)\n#if backend == \u201crigetti\u201d:\ndev = qml.device(\u201cforest.qpu\u201d, device=\u201cAspen-4-4Q-A\u201d, shots=1024)\nprint(\"Device capabilities: \", dev.capabilities()[\u201cbackend\u201d])\nConfigure PyTorch to use CUDA, only if available. Otherwise simply use the CPU.\nprint(\u201cInitializing backend device\u2026\u201d)\ndevice = torch.device(\u201ccuda:0\u201d if torch.cuda.is_available() else \u201ccpu\u201d)\nDataset loading\ndata_transforms = {\n\u201ctrain\u201d: transforms.Compose(\n[\n# transforms.RandomResizedCrop(224), # uncomment for data augmentation\n# transforms.RandomHorizontalFlip(), # uncomment for data augmentation\ntransforms.Resize(256),\ntransforms.CenterCrop(224),\ntransforms.ToTensor(),\n# Normalize input channels using mean values and standard deviations of ImageNet.\ntransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n]\n),\n\u201cval\u201d: transforms.Compose(\n[\ntransforms.Resize(256),\ntransforms.CenterCrop(224),\ntransforms.ToTensor(),\ntransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n]\n),\n}\nget_ipython().system(\u2018pwd\u2019)\nimage_datasets = {\nx: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms) for x in [\u201ctrain\u201d, \u201cval\u201d]\n}\ndataset_sizes = {x: len(image_datasets) for x in [\u201ctrain\u201d, \u201cval\u201d]}\nclass_names = image_datasets[\u201ctrain\u201d].classes\nInitialize dataloader\ntorch.manual_seed(rng_seed)\ndataloaders = {\nx: torch.utils.data.DataLoader(image_datasets, batch_size=batch_size, shuffle=True)\nfor x in [\u201ctrain\u201d, \u201cval\u201d]\n}\nFunction to plot images\ndef imshow(inp, title=None):\n\u201c\u201d\u201cDisplay image from tensor.\nArgs:\ninp (tensor): input image\ntitle (string): title of the image\n\u201c\u201d\u201d\ninp = inp.numpy().transpose((1, 2, 0))\n# We apply the inverse of the initial normalization operation.\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\ninp = std * inp + mean\ninp = np.clip(inp, 0, 1)\nplt.imshow(inp)\nif title is not None:\nplt.title(title)\nHybrid transfer learning model (classical-to-quantum).\n\nWe first define some quantum layers that will comprise the quantum circuit.\ndef H_layer(nqubits):\n\u201c\u201d\u201cLayer of single-qubit Hadamard gates.\nArgs:\nnqubits (int): number of qubits\n\u201c\u201d\u201d\nfor idx in range(nqubits):\nqml.Hadamard(wires=idx)\ndef RY_layer(w):\n\u201c\u201d\u201cLayer of parametrized qubit rotations around the y axis.\nArgs:\nw (tensor): list of rotation angles; one for each qubit\n\u201c\u201d\u201d\nfor idx, element in enumerate(w):\nqml.RY(element, wires=idx)\ndef entangling_layer(nqubits):\n\u201c\u201d\u201cLayer of CNOTs followed by another shifted layer of CNOT.\nArgs:\nnqubits (int): number of qubits\n\u201c\u201d\u201d\n# In other words it should apply something like :\n# CNOT  CNOT  CNOT  CNOT\u2026  CNOT\n#   CNOT  CNOT  CNOT\u2026  CNOT\nfor i in range(0, nqubits - 1, 2):  # loop over even indices: i=0,2,\u2026N-2\nqml.CNOT(wires=[i, i + 1])\nfor i in range(1, nqubits - 1, 2):  # loop over odd indices:  i=1,3,\u2026N-3\nqml.CNOT(wires=[i, i + 1])\nLet us define the quantum circuit by using the PennyLane qnode decorator .\nThe structure is that of a typical variational quantum circuit:\n1. All qubits are first initialized in a balanced superposition of up and down states,\nthen they are rotated according to the input parameters (local embedding);\n2. Successively a sequence of trainable rotation layers and constant entangling layers is applied.\nThis block is responsible for the main computation necessary to solve the classification problem.\n3. Eventually, for each qubit, the local expectation value of the Z operator is measured.\nThis produces a classical output vector, suitable for additional post-processing.\n@qml.qnode(dev2, interface=\u201ctorch\u201d)\ndef q_net(q_in, q_weights_flat):\n\u201c\u201d\u201cQuantum cricuit\nArgs:\nq_in (tensor): input features\nq_weights_flat (tensor): variational parameters\nReturns:\ntuple: expectation values of PauliZ for each qubit\n\u201c\u201d\u201d\n# Reshape weights\nq_weights = q_weights_flat.reshape(n_quantum_layers, n_qubits)\n# Start from state |+> , unbiased w.r.t. |0> and |1>\nH_layer(n_qubits)\n\n# Embed features in the quantum node\nRY_layer(q_in)  \n\n# Sequence of trainable variational layers\nfor k in range(q_depth):\n    entangling_layer(n_qubits)\n    RY_layer(q_weights[k + 1])\n\n# Expectation values in the Z basis\nreturn [qml.expval(qml.PauliZ(j)) for j in range(n_qubits)]\n\nWe can now define a custom torch.nn.Module representing a dressed quantum circuit.\nThis is is a concatenation of:\n1. A classical pre-processing layer (nn.Linear)\n2. A classical activation function (torch.tanh)\n3. A constant np.pi/2.0 scaling factor.\n2. The previously defined quantum circuit (q_net)\n2. A classical post-processing layer (nn.Linear)\n\nThe input of the module is a batch of vectors with 512 real parameters (features)\nand the output is a batch of vectors with two real outputs (associated with the two\nclasses of images: ants and bees).\nclass Quantumnet(nn.Module):\ndef init(self):\nsuper().init()\nself.pre_net = nn.Linear(512, n_qubits)\nself.q_params = nn.Parameter(q_delta * torch.randn(n_quantum_layers * n_qubits))\nself.post_net = nn.Linear(n_qubits, 2)\ndef forward(self, input_features):\n    \"\"\"Full classical-quantum network.\n        Args:\n            self\n            input_features (tensor): input image\n        Returns:\n            tuple: output logits of the hybrid network\n        \"\"\"\n    pre_out = self.pre_net(input_features)\n    q_in = torch.tanh(pre_out) * np.pi / 2.0\n    \n    # Apply the quantum circuit to each element of the batch, and append to q_out\n    q_out = torch.Tensor(0, n_qubits)\n    q_out = q_out.to(device)\n    for elem in q_in:\n        q_out_elem = q_net(elem, self.q_params).float().unsqueeze(0)\n        q_out = torch.cat((q_out, q_out_elem))\n    return self.post_net(q_out)\n\nWe are finally ready to build our full hybrid classical-quantum network. We follow the transfer learning approach.\nFirst load the classical pre-trained network ResNet18 from the torchvision.models zoo.\nThe model is downloaded from Internet and it may take a long time (only the first time).\nmodel_hybrid = torchvision.models.resnet18(pretrained=True)\nFreeze all the weights since they should not be trained.\nfor param in model_hybrid.parameters():\nparam.requires_grad = False\nReplace the last fully connected layer with our trainable dressed quantum circuit (Quantumnet).\nmodel_hybrid.fc = Quantumnet()\nUse CUDA or CPU according to the \u201cdevice\u201d object.\nmodel_hybrid = model_hybrid.to(device)\nLoad model from file\nmodel_hybrid.fc.load_state_dict(torch.load(\u201cquantum_weights.pt\u201d, map_location=\u201ccpu\u201d))\nWe apply the model to the test dataset to compute the associated loss and accuracy.\ncriterion = nn.CrossEntropyLoss()\nrunning_loss = 0.0\nrunning_corrects = 0\nn_batches = dataset_sizes[\u201cval\u201d] // batch_size\nit = 0\nprint(\n\u201cResults of the model testing on a real quantum processor.\u201d,\nfile=open(\u201cresults_\u201d + backend + \u201c.txt\u201d, \u201cw\u201d),\n)\nprint(\"QPU backend: \" + backend, file=open(\u201cresults_\u201d + backend + \u201c.txt\u201d, \u201ca\u201d))\nfor inputs, labels in dataloaders[\u201cval\u201d]:\nmodel_hybrid.eval()\ninputs = inputs.to(device)\nlabels = labels.to(device)\nbatch_size_ = len(inputs)\nwith torch.set_grad_enabled(False):\noutputs = model_hybrid(inputs)\n, preds = torch.max(outputs, 1)\nloss = criterion(outputs, labels)\nrunning_loss += loss.item() * batch_size\nbatch_corrects = torch.sum(preds == labels.data).item()\nrunning_corrects += batch_corrects\nprint(\u201cIter: {}/{}\u201d.format(it + 1, n_batches + 1), end=\"\\r\", flush=True)\n# log to file\nprint(\n\u201cIter: {}/{}\u201d.format(it + 1, n_batches + 1),\nend=\"\\r\",\nflush=True,\nfile=open(\u201cresults_\u201d + backend + \u201c.txt\u201d, \u201ca\u201d),\n)\nit += 1\nepoch_loss = running_loss / dataset_sizes[\u201cval\u201d]\nepoch_acc = running_corrects / dataset_sizes[\u201cval\u201d]\nprint(\"\\nTest Loss: {:.4f} Test Acc: {:.4f}        \".format(epoch_loss, epoch_acc))\nLog to file\nprint(\n\"\\nTest Loss: {:.4f} Test Acc: {:.4f}        \".format(epoch_loss, epoch_acc),\nfile=open(\u201cresults_\u201d + backend + \u201c.txt\u201d, \u201ca\u201d),\n)\n#!pwd\n#torch.save(model_hybrid.state_dict(), \u2018modelcnn.pt\u2019)\nCompute and visualize the predictions for a batch of test data.\nThe figure is saved as a .png file in the working directory.\nimages_so_far = 0\nnum_images = batch_size\nfig = plt.figure(\u201cPredictions\u201d)\nmodel_hybrid.eval()\nwith torch.no_grad():\nfor i, (inputs, labels) in enumerate(dataloaders[\u201cval\u201d]):\ninputs = inputs.to(device)\nlabels = labels.to(device)\noutputs = model_hybrid(inputs)\n, preds = torch.max(outputs, 1)\nfor j in range(inputs.size()[0]):\nimages_so_far += 1\nax = plt.subplot(num_images // 2, 2, images_so_far)\nax.axis(\u201coff\u201d)\nax.set_title(\"[{}]\".format(class_names[preds[j]]))\nimshow(inputs.cpu().data[j])\nif images_so_far == num_images:\nfig.savefig(\"predictions\" + backend + \u201c.png\u201d)\nbreak\nif images_so_far == num_images:\nbreak", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/22"}, "22": {"author": "antalszava", "date": "1627990434212", "content": "Dear @dancbeaulieu,\nThank you for posting the exact code snippet!\nJust to make sure: when creating the provider object that is then passed as provider=provider to qml.device, are IBMQ specific details being used instead of the placeholder strings? So instead of explicitly passing hub='HUB', group='GROUP', project='PROJECT', is 'HUB', 'GROUP', etc. substituted with a valid IBMQ hub, group, etc.?\nCurious, because I managed to send a circuit to IBMQ with the snippet above to the Bogota IBMQ machine by having  dev2 = qml.device('qiskit.ibmq', wires=n_wires, backend='ibmq_bogota', shots=100). At the time, the job was in the queue for 7 minutes and ran for ~10 seconds. It also appeared well in IBMQ Experience.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/23"}, "23": {"author": "_risto", "date": "1628011754288", "content": "Hi @Tom_Bromley\nWhy do I get ModuleNotFoundError: No module named \u2018pennylane\u2019 when running the tutorial on lab.quantum-computing?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/24"}, "24": {"author": "antalszava", "date": "1628093966233", "content": "Hi @_risto,\nThat will likely be due to some installation issues. Could you check the output of pip freeze? Does PennyLane appear in the output?2 Replies", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/25"}, "25": {"author": "dancbeaulieu", "date": "1628094397283", "content": "Pennylane and Pennylane-qiskit both appear:\nPennyLane==0.16.0\nPennyLane-qiskit==0.16.0", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/26"}, "26": {"author": "_risto", "date": "1628096220690", "content": "\n\n\n antalszava:\n\npip freeze\n\n\nYes it does (among other things), when I wrote it in PowerShell, but I am opening my jupyter notebook ipynb in qiskit quantum lab.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/27"}, "27": {"author": "_risto", "date": "1628268239306", "content": "Hi @antalszava\nAny idea how to fix this? I am running the code on qiskit quantum lab directly.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/28"}, "28": {"author": "Tom_Bromley", "date": "1628277472273", "content": "@_risto, you could try executing the following command at the top of your notebook in IBM quantum lab to install PennyLane:\n!pip install pennylane\n!pip install pennylane_qiskit\n", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/29"}, "29": {"author": "_risto", "date": "1628542053175", "content": "Hi @Tom_Bromley\nThank you. It worked. When importing the data (data dir = \u2026/_data/hymenoptera_data), do I need to create a Docker file? It says there is no ```\n\u2018/home/jovyan\u2019 file, however one could create one from Docker? I know it is a different platform, so just as inquiry perhaps, any information would be helpful.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/30"}, "30": {"author": "antalszava", "date": "1628542649371", "content": "Hi @_risto,\nIt seems that something is going wrong with the path where the input data file was created for the demo. Is this error raised when running the demonstration in a Jupyter notebook in Qiskit Quantum Lab? It is strange that \u2018/home/jovyan\u2019  appears in the error.\nPerhaps a solution would be to create the file by first closer inspecting the directory structure that is used with the Jupyter notebook:\nimport os\n\nos.getcwd()\n\nThis will help to see what the current working directory is. Then, the correct directory structure and file could be created using commands from the Jupyter notebook.\nNot sure if creating a Docker file and using a Docker container would be necessary.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/31"}, "31": {"author": "_risto", "date": "1628543319854", "content": "Hi @antalszava\nThanks for the answer. I get:\n\u2018/home/jovyan\u2019\nYes, the jupyter notebook is running via ibmq lab.quantum. When running just jupyter, I have no problems with importing data.\nWhen I use os.path.abspath I get: FileNotFoundError: [Errno 2] No such file or directory: \u2018/home/jovyan/C:\\Users\\risto\\Desktop\\quantum_computing\\Quantum transfer learning_bees\\_data\\hymenoptera_data/train\u2019", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/32"}, "32": {"author": "dancbeaulieu", "date": "1628553437241", "content": "I was able to solve my problem by changing the backend from IBMQ_BOGOTA to IBM_LAGOS. No idea why that makes any difference. It ran both ways, but when I ran on IBMQ_BOGOTA it ran instantly and didn\u2019t access the IBMQ system or leave and logs, so believe it was executing locally and not leaving a log or any information on the IBMQ backend. When I ran on IBM_LAGOS it worked, put me in the queue for the QPU, and was present in the IBMQ backend logs.2", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/33"}, "33": {"author": "_risto", "date": "1628556977687", "content": "What do you mean by that? To create an account on IBM Nigeria and run it over there?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/34"}, "34": {"author": "dancbeaulieu", "date": "1628561177900", "content": "IBM_LAGOS is the name of a quantum machine, unfortunately I can no longer get my jobs to run on the IBMQ system. Was previously trying to use IBMQ_BOGOTA (a different quantum machine name). Was able to get them running a few times, but no longer.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/35"}, "35": {"author": "antalszava", "date": "1628627161052", "content": "@_risto the error message seems to be somewhat related to a mix between Linux and Windows paths \nFollowing up on @dancbeaulieu\u2019s suggestion, changing the backend can be done when creating the device in PennyLane:\ndev = qml.device('qiskit.ibmq', wires=2, backend='ibmq_lagos')\n\nThis assumes that the 'ibmq_lagos' backend is available.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/36"}, "36": {"author": "_risto", "date": "1628630039499", "content": "Hi @antalszava\nI have tried that, but still get the error: FileNotFoundError: [Errno 2] No such file or directory: '/home/jovyan/C:\u2026", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/37"}, "37": {"author": "antalszava", "date": "1628705630533", "content": "Hi @_risto,\nJust to confirm: do you have the required folder structure in the IBMQ quantum lab system? Tried the demo and after creating the folder structure, the initial FileNotFoundError: [Errno 2] No such file or directory: '../_data/hymenoptera_data/train' error was resolved.\nIt\u2019s worth noting, that I was only able to create folders & files from within the same folder where the notebook was. Therefore, I changed the path declaration to data_dir = \"_data/hymenoptera_data\".\nCould you maybe execute !ls -la in one of the cells and submit the output?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/38"}, "38": {"author": "_risto", "date": "1628706441740", "content": "Hi @antalszava\nI get:\ntotal 473\ndrwxrwxr-x 1 jovyan 1000      0 Aug  2 20:47  .\ndrwxr-xr-x 1 root   root   4096 Jan 27  2021  \u2026\ndrwxr-xr-x 1 jovyan 1000      0 Aug  2 20:47  .cache\ndrwxr-xr-x 1 jovyan 1000      0 Aug  2 20:53  .config\ndrwxr-xr-x 1 jovyan 1000      0 Aug  2 20:53  .ipynb_checkpoints\ndrwxr-xr-x 1 jovyan 1000      0 Aug  2 20:47  .ipython\nlrwxrwxrwx 1 jovyan 1000     13 Aug 11 18:15  .jupyter -> /tmp/.jupyter\ndrwxr-xr-x 1 jovyan 1000      0 Aug  2 20:47  .local\ndrwxr-xr-x 1 jovyan 1000      0 Aug 11 18:15  .qiskit\nlrwxrwxrwx 1 jovyan 1000     20 Aug 11 18:15  qiskit-textbook -> /tmp/qiskit-textbook\nlrwxrwxrwx 1 jovyan 1000     25 Aug 11 18:15  qiskit-tutorials -> /tmp/qiskit-iqx-tutorials\n-rw-r\u2013r-- 1 jovyan 1000 186366 Aug 11 18:19  resnet152_bees_qbits4_batch4_IBMQ.ipynb\n-rw-r\u2013r-- 1 jovyan 1000  11267 Aug  3 17:29  Untitled1.ipynb\ndrwxr-xr-x 1 jovyan 1000      0 Aug  4 16:54 \u2018Untitled Folder\u2019\n-rw-r\u2013r-- 1 jovyan 1000 275498 Aug  4 17:07 \u2018Wide ResNet-101-2_4qbits.ipynb\u2019\nWhat do you mean by: required folder structure in the IBMQ quantum lab system? It is in the same folder as other ipynb resnet152 files, thus the same structure in regards to hymenoptera data.\n\u2502\u2500\u2500 tutorials\n\u2502 \u251c\u2500\u2500 _data\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500 hymenoptera_data\n\u2502 \u251c\u2500\u2500 quantum_transfer_learning\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500 tutorial_quantum_transfer_learning.ipynb\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500 tutorial_quantum_transfer_learning_IBMQ.ipynb", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/39"}, "39": {"author": "antalszava", "date": "1628712450637", "content": "\nrequired folder structure in the IBMQ quantum lab system\n\nIt would be the folder structure of the data required by the demo:\n\u2502 _data\n\u2502 \u251c\u2500\u2500 hymenoptera_data\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500 train\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500  \u251c\u2500\u2500 ants\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500  \u251c\u2500\u2500 bees\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500 val\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500  \u251c\u2500\u2500 ants\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500  \u251c\u2500\u2500 bees\nBased on the path data_dir = \"../_data/hymenoptera_data\", the following folder structure should indeed work well:\n\u2502 _data\n\u2502 \u251c\u2500\u2500 hymenoptera_data\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500 train\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500  \u251c\u2500\u2500 ants\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500  \u251c\u2500\u2500 bees\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500 val\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500  \u251c\u2500\u2500 ants\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500  \u251c\u2500\u2500 bees\n\u2502 quantum_transfer_learning\n\u2502 \u251c\u2500\u2500 tutorial_quantum_transfer_learning.ipynb\nHowever, based on your output, I\u2019m not sure I see tutorial_quantum_transfer_learning.ipynb. Is the tutorial in resnet152_bees_qbits4_batch4_IBMQ.ipynb?\nAlso, checking the folder one level up, I get the following output:\n!ls ..\n\njovyan\n\nTherefore, I\u2019ve changed the line data_dir = \u201c\u2026/_data/hymenoptera_data\u201d to data_dir = \"_data/hymenoptera_data\". This should work with folder structure for example as follows:\n\u2502 _data\n\u2502 \u251c\u2500\u2500 hymenoptera_data\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500 train\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500  \u251c\u2500\u2500 ants\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500  \u251c\u2500\u2500 bees\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500 val\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500  \u251c\u2500\u2500 ants\n\u2502 \u251c\u2500\u2500 \u251c\u2500\u2500  \u251c\u2500\u2500 bees\n\u2502 tutorial_quantum_transfer_learning.ipynb\nAssuming that tutorial_quantum_transfer_learning.ipynb is the notebook with the tutorial that was created on IBMQ quantum lab.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/40"}, "40": {"author": "_risto", "date": "1628716394559", "content": "So now I can\u2019t run anything because I am getting : RequestsApiError: \u2018401 Client Error: Unauthorized for url: https://auth.quantum-computing.ibm.com/api/users/loginWithToken. Login failed., Error code: 3446.\u2019  It worked fine a while ago. Even after changing to other backends. Have also tried to create a new token, then included IBMQ.save_account('YOUR API KEY', overwrite=True) , but still.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/41"}, "41": {"author": "antalszava", "date": "1628771892550", "content": "Hi @_risto,\nThat sounds really odd \nJust tried a simple circuit run and it worked well with:\ndev = qml.device('qiskit.ibmq', wires=2, backend='ibmq_qasm_simulator', ibmqx_token=token)\nA couple of thoughts:\n\nWas it not working for 'ibmq_qasm_simulator' either?\nWas the new key created by clicking on the refresh button here? (the  button with two arrows) \n\nWas it not working after trying a bit later either? Perhaps it could have been some temporary service issues.\n", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/42"}, "42": {"author": "_risto", "date": "1628795501960", "content": "Now I get: No such file or directory: \u2018\u2026/_data/hymenoptera_data/train\u2019 eventhough this folder was not changed and worked with every notebook I\u2019ve run on Jupyter.\nLol \nAny ideas why?\nI get same result for \u2026/_data/hymenoptera_data/train and _data/hymenoptera_data/train", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/43"}, "43": {"author": "antalszava", "date": "1628991040371", "content": "Hi @_risto,\nI\u2019m afraid I\u2019m not sure how to assist without knowing more about the details of the situation.\n\nIs that still on quantum lab?\nCould you send the output of ls -Rla from the same directory where the jupyter notebook exists to verify that the correct directories are there?\n\nThe previous output didn\u2019t seem to have worked, so seeing this error would not come as a surprise. Also, please note the name of the jupyter notebook that is being run.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/44"}, "44": {"author": "_risto", "date": "1629136207500", "content": "Hi @antalszava\nI get a very long list, with this at the end:\n./.local/share/jupyter/runtime:\ntotal 3\ndrwx-----T 1 jovyan 1000   0 Aug  2 20:47 ./\ndrwxr-xr-x 1 jovyan 1000   0 Aug  2 20:47 \u2026/\n-rw------- 1 jovyan 1000 314 Aug 16 17:27 jpserver-7.json\n-rw-r\u2013r-- 1 jovyan 1000 486 Aug 16 17:27 jpserver-7-open.html\n-rw------T 1 jovyan 1000 263 Aug 16 17:33 kernel-ed807a6a-6b2e-47c1-b6a1-3a1ccd056125.json\n./.qiskit:\ntotal 2\ndrwxr-xr-x 1 jovyan 1000   0 Aug 16 17:27 ./\ndrwxrwxr-x 1 jovyan 1000   0 Aug  2 20:47 \u2026/\n-rw-r\u2013r-- 1 jovyan 1000 207 Aug 16 17:27 qiskitrc\nlrwxrwxrwx 1 jovyan 1000  26 Aug 16 17:27 settings.conf -> /tmp/.qiskit/settings.conf\n\u2018./Untitled Folder\u2019:\ntotal 1\ndrwxr-xr-x 1 jovyan 1000 0 Aug  4 16:54 ./\ndrwxrwxr-x 1 jovyan 1000 0 Aug  2 20:47 \u2026/\nThis is the full error when importing data:\nTraceback (most recent call last):\nFile \u201c\u201d, line 24, in \nimage_datasets = {\nFile \u201c\u201d, line 25, in \nx if x == \u201ctrain\u201d else \u201cvalidation\u201d: datasets.ImageFolder(\nFile \u201c/opt/conda/lib/python3.8/site-packages/torchvision/datasets/folder.py\u201d, line 253, in init\nsuper(ImageFolder, self).init(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\nFile \u201c/opt/conda/lib/python3.8/site-packages/torchvision/datasets/folder.py\u201d, line 126, in init\nclasses, class_to_idx = self._find_classes(self.root)\nFile \u201c/opt/conda/lib/python3.8/site-packages/torchvision/datasets/folder.py\u201d, line 164, in _find_classes\nclasses = [d.name for d in os.scandir(dir) if d.is_dir()]\nFileNotFoundError: [Errno 2] No such file or directory: \u2018_data/hymenoptera_data/train\u20192 Replies", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/45"}, "45": {"author": "Maria_Schuld", "date": "1629201429214", "content": "Hey @_risto, and well done for your perseverance trying to run a tutorial in quantum lab.\nBut I am wondering if your questions are really PennyLane related, or if it is about paths in quantum lab (with which the IBMQ team may be better positioned to provide help)?\nIf you think they are PennyLane related (i.e. you cannot reproduce the error with just any file of that format), I would be really grateful if you could boil them back down to a few lines of code, and state how you run them - I lost a bit the overview what\u2019s actually happening\u2026", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/46"}, "46": {"author": "antalszava", "date": "1629206977329", "content": "Hi @_risto,\nJust to reply to this, it doesn\u2019t seem like the  _data does exist, at least from the part of the output that you\u2019ve attached. If that\u2019s the case, then that will be the reason for the FileNotFoundError that you see.\nAs Maria mentioned, kudos for the patience with this! ", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/47"}, "47": {"author": "dancbeaulieu", "date": "1633003955208", "content": "Hi,\nIs there any code that shows the creation of the \u2018quantum_weights.pt\u2019 file used in https://github.com/XanaduAI/quantum-transfer-learning/blob/master/quantum_processors/run_on_QPU.py 3? I am having issues getting Pennylane to run on quantum hardware even when saving my files then loading my weights based on simulator. Any code you could share where the quantum_weights.pt file gets created?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/48"}, "48": {"author": "Tom_Bromley", "date": "1633090343900", "content": "Hi @dancbeaulieu,\nAs far as I recall, quantum_weights.pt is a modified version of the quantum_ants_bees.pt generated in this file. What issues are you facing when saving and loading weights? Note that the network topologies in the saved and loaded models must agree.1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-code-mari-et-al-2019-ibmqdevice-endless-execution/325/49"}}