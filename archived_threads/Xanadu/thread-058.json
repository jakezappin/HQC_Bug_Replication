{"0": {"author": "Einar_Gabbassov", "date": "1636489542815", "content": "Dear Pennylane team,\nI have a 30 qubit circuit where all qubits are inter-entangled. The total number of gates is somewhere around 8000. This circuit should complete running in about 12 days on 4 cores.\nI would like to know if there are ways to speedup the computation.\n\n\nFor example, would it make sense to run the circuit on a GCP instance with a GPU or an instance with no GPU but many cores? What is the best hardware configuration for this case?\n\n\nWould you recommend AWS simulators instead of default qubit device running on a GCP instance. Will there be a significant speedup for executing the circuit?\n\n", "link": "https://discuss.pennylane.ai//t/running-30-qubit-highly-entangled-circuit/1474/1"}, "1": {"author": "CatalinaAlbornoz", "date": "1636497542209", "content": "Hi @Einar_Gabbassov, it\u2019s great that you\u2019re tackling a big problem!\nThe first thing I would suggest is changing the device from default.qubit to lightning.qubit. This will increase your speed by three times or more.\nI will look into the other questions or see if someone else has an answer.1 Reply", "link": "https://discuss.pennylane.ai//t/running-30-qubit-highly-entangled-circuit/1474/2"}, "2": {"author": "Kuma-quant", "date": "1636515157000", "content": "Hi @Einar_Gabbassov.\nIt depends on the problem (and circuit) you want to solve.\nAs you said, SV1 simulator in AWS might be faster in case of single execution of circuit (i.e. it doesn\u2019t require any iterations).\nBut in case of variational quantum algorithms (e.g. VQE,QAOA,QNN), in which quantum and classical comuputation should be iterated,  communication delay between SV1 and your laptop accumulates and it becomes siginificant problem.\nThis is critical in case of QNN, because QNN may require huge number of iterations than VQE and QAOA.\nMoreover, SV1 only supports slow gradieint calculation rule of parameter-shift to date(?).\nThis is critical if your circuit have many variational paramters.\nFrom my experience, in < 15 qubits, local simulator on your laptop is sometimes faster than SV1 for variational quantum algorithms.\n30 qubits might be good target to compare SV1 and local simulator.", "link": "https://discuss.pennylane.ai//t/running-30-qubit-highly-entangled-circuit/1474/3"}, "3": {"author": "Einar_Gabbassov", "date": "1636519495365", "content": "@CatalinaAlbornoz @Kuma-quant thank you for your replies.\nFortunately, this big circuit does not require any iterations on the parameters. I just need to run it and sample the device.\nIn the case I use lightning.qubit device (or even default.qubit) what is the best hardware configuration for running my circuit (e.g. have more CPU cores or may be one core but a powerful GPU)?\nMy apologies for such basic question, but I could not find any info on parallelization of the pennylane simulators.\nP.S. I guess, simulators do a lot of matrix multiplications so it seems like a GPU could be pretty handy?", "link": "https://discuss.pennylane.ai//t/running-30-qubit-highly-entangled-circuit/1474/4"}, "4": {"author": "Maria_Schuld", "date": "1636537803789", "content": "Hey @Einar_Gabbassov,\nto also add my 2 cents, I benchmarked AWS\u2019 SV1 simulator as a PennyLane device a few months back and the setting you describe seems very well suited to it. I used much shorter circuits, but in my case the runtime grew surprisingly little with the number of qubits in the regime of 25-32 qubits. Also, with that much entanglement, I doubt you get an advantage of a tensor network simulator\u2026and running lightning.qubit locally will reach its limits, even if you could put it onto the GPU.\nAs @Kuma-quant says, the latency is large and optimisation with many different sequential runs can be cumbersome at this stage for remote simulators, but if it is a wide&deep circuit you want to be simulated only once, the massive parallelisation of the backend should be exactly what you are looking for (and the few seconds of sending the job will not make a difference).\nMaybe try and see if it fits the bill?1", "link": "https://discuss.pennylane.ai//t/running-30-qubit-highly-entangled-circuit/1474/5"}, "5": {"author": "NikSchet", "date": "1638304280262", "content": "\n\n\n CatalinaAlbornoz:\n\nlightning.qubit\n\n\nFor this defined qnode:\n@qml.qnode(dev, interface=\"tf\", diff_method=\"backprop\")\ndef qnode(inputs, weights):\n    for i in range(blocks):\n        qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n       qml.templates.StronglyEntanglingLayers(weights[i], wires=range(n_qubits)) \n    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n\nWhen i set\ndev = qml.device(\"default.qubit.tf\", wires=n_qubits) \n\ni get much faster speed/epoch than with the suggested\ndev = qml.device(\"lightning.qubit\", wires=n_qubits) \n\nAny idea why? Thanks in advance!\np.s. In the second case i have to remove : interface=\"tf\", diff_method=\"backprop\" from the Qnode so it runs properly.\np.s.2 the maximum number of qubits i can run on my PC is 17Qubits (more qubits result to an error). Is there a way i can push to 20 Qubits? [just wondering]", "link": "https://discuss.pennylane.ai//t/running-30-qubit-highly-entangled-circuit/1474/6"}, "6": {"author": "CatalinaAlbornoz", "date": "1638380899853", "content": "Hi @NikSchet, this is very unusual. We are looking into why this may be happening.\nAbout pushing to 20 qubits it really depends on the machine you\u2019re using. You could try running on GPU if you have one.", "link": "https://discuss.pennylane.ai//t/running-30-qubit-highly-entangled-circuit/1474/7"}, "7": {"author": "NikSchet", "date": "1638384138648", "content": "Thank you very much. Do i need to make certain changes to run on GPU instead of CPU? somehow i cannot find something relevant in the website (sorry if that was obvious and i missed it).", "link": "https://discuss.pennylane.ai//t/running-30-qubit-highly-entangled-circuit/1474/8"}, "8": {"author": "Trevor_Vincent", "date": "1638391022033", "content": "Hi @NikSchet,\nThank you for your interest in Pennylane! Can you try running lightning.qubit with diff_method=\u201cadjoint\u201d? This might speed it up.\nRegarding the 17 qubits problem, this is a bit weird, you should be able to simulate more on a modern desktop. Can you post the error message you get when you try to increase the qubits along with your environment specs (e.g. pennylane version, lightning version, OS, CPU model, RAM)? Also if it\u2019s not too much trouble, can you post the full python script?\nThanks,\nTrevor", "link": "https://discuss.pennylane.ai//t/running-30-qubit-highly-entangled-circuit/1474/9"}, "9": {"author": "NikSchet", "date": "1638396809833", "content": "Thank you for the fast reply. I used the suggested diff_method and i got indeed much faster speeds. What is the difference between\n1.\n\ndev = qml.device(\"lightning.qubit\", wires=n_qubits)\n@qml.qnode(dev, interface=\"tf\", diff_method=\"backprop\")\n\n\nand 2.\n\ndev = qml.device(\"lightning.qubit\", wires=n_qubits) \n@qml.qnode(dev, interface=\"tf\", diff_method=\u201cadjoint\u201d)\n\n\nWith second option i was able to push up to 19 qubits with (Windows 10, AMD Ryzen 7 5800x, Nvidia 3060 8gb, Gskill 32Gb ram [ultrafast]). Pennylane version 0.18.0 (i do not use pytorch lightning)\nBeyond that qubit number the kernel just dies or i get the error : \u201cMemoryError: bad allocation\u201d on a jupyter notebook opened in edge browser (Anaconda distribution).\nMaybe i can push to higher qubit number if i make changes to batch size?\nThe script i am running can be found here: https://github.com/nsansen/Quantum-Machine-Learning/blob/main/QML%20-%20HYBRID%20v6.1%20-%20%20Transfer%20Learning.ipynb 6\n[note that this is a transfer learning script i first pre-train (hot-starting) the classical part and then i train the Hybrid at section 4.3]", "link": "https://discuss.pennylane.ai//t/running-30-qubit-highly-entangled-circuit/1474/10"}, "10": {"author": "Trevor_Vincent", "date": "1638480412750", "content": "Hi @NikSchet,\nReally cool script, thank you for providing it, we will analyze it for potential memory problems. One thing you can do is upgrade pennylane/pennylane-lightning to their newest versions, perhaps this might help with the 19-qubit problem. Also if you have access to linux, pennylane-lightning should be even faster than on windows because it will have OpenMP support. Perhaps making changes to the batch size will help as well, as you suggest.\nRegarding the difference between \u201cbackprop\u201d and \u201cadjoint\u201d. These are two different methods of computing the gradient. Pennylane-lightning has a heavily optimized adjoint method, so we prefer it\u2019s use for now. You can also try diff_method=\u201cbest\u201d and that will default to \u201cadjoint\u201d for lightning. A more detailed explanation for backprop and adjoint are here: https://pennylane.ai/qml/demos/tutorial_backprop.html 2 and here: https://pennylane.ai/qml/demos/tutorial_adjoint_diff.html 5", "link": "https://discuss.pennylane.ai//t/running-30-qubit-highly-entangled-circuit/1474/11"}, "11": {"author": "NikSchet", "date": "1638613132682", "content": "Thank you very much!!", "link": "https://discuss.pennylane.ai//t/running-30-qubit-highly-entangled-circuit/1474/12"}}