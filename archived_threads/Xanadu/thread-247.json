{"0": {"author": "hsim", "date": "1619549905553", "content": "Hi,\nI was trying to use the quantum natural gradient (QNG) optimizer on a toy VQE problem where the ansatz employs user-defined gates \u2018XX\u2019 and \u2018YY\u2019 (defined below).\nWhen trying to take an optimizer step, I got the following error: \u201cValueError: solve1: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (m,m),(m)->(m) (size 3 is different from 4)\u201d coming from\nnp.linalg.solve(self.metric_tensor, grad_flat)\n\nI didn\u2019t encounter this error when using a circuit with Pennylane-defined gates. I think the error might be because I use the same parameter for both XX and YY gates but wasn\u2019t sure how to fix this error.\nThis was my code:\nfrom pennylane import numpy as np\nimport pennylane as qml\n\ndev = qml.device(\"default.qubit\", wires=2)\ndev.operations.update({\"XX\", \"YY\"})\n\ndef circuit(params, wires=[0, 1]):\n    qml.PauliX(wires=wires[1])\n    qml.RZ(params[0], wires=wires[0])\n    qml.RZ(params[1], wires=wires[1])\n    XX(params[2], wires=wires)\n    YY(params[2], wires=wires)\n\ncoeffs = [1, 1]\nobs = [qml.PauliX(0), qml.PauliZ(1)]\nH = qml.Hamiltonian(coeffs, obs)\ncost_fn = qml.ExpvalCost(circuit, H, dev)\n\ninit_params = np.random.uniform(size=3)\n\nopt = qml.QNGOptimizer(stepsize=0.01, diag_approx=False)\n\nparams, prev_energy = opt.step_and_cost(cost_fn, init_params)\n\nAnd the two user-defined gates are:\nclass XX(qml.operation.Operation):\n    num_params = 1 \n    num_wires = 2 \n    par_domain = \"R\" \n    grad_method = \"A\" \n    generator = [np.kron(X, X), -0.5]\n    \n    @staticmethod\n    def _matrix(*params):\n        return np.cos(params[0]/2)*np.eye(4) + 1.j*np.sin(params[0]/2)*np.kron(X,X)\n\nclass YY(qml.operation.Operation):\n    num_params = 1 \n    num_wires = 2 \n    par_domain = \"R\" \n    grad_method = \"A\"\n    generator = [np.kron(Y, Y), -0.5]\n    \n    @staticmethod\n    def _matrix(*params):\n        return np.cos(params[0]/2)*np.eye(4) + 1.j*np.sin(params[0]/2)*np.kron(Y,Y)\n\n\n Solved by josh in post #4 \n\n\n                No worries @hsim! \nI\u2019ve generalized my previous answer to account for ExpvalCost: \ndef quantum_jacobian(qnode):\n    \"\"\"Returns a function that computes the purely\n    quantum Jacobian of a QNode\"\"\"\n    if isinstance(qnode, qml.ExpvalCost):\n        qnodes = qnode.qnodes\n        coeffs = qnode.hamilto\u2026\n              \n", "link": "https://discuss.pennylane.ai//t/quantum-natural-gradient-optimizer-with-user-defined-gates/1006/1"}, "1": {"author": "josh", "date": "1619587633202", "content": "Hi @hsim!\nThe issue here is that the metric tensor is only defined for the quantum circuit gate arguments, while the optimizer is instead optimizing the QNode arguments.\nThis is a bit of subtlety\u2014in most cases, there is a 1-1 mapping between QNode arguments and gate arguments, so this issue doesn\u2019t arise! As you note, however, the repeated parameter between the XX and YY breaks this 1-1 mapping.\nIn other words: the optimizer is assuming that the object it is optimizing is a pure quantum circuit with a well-defined metric tensor with respect to QNode arguments, which is not the case.\n\nWorkarounds\nOne workaround is to write out the QNG optimization manually using qml.metric_tensor (which extracts the metric tensor of the underlying quantum circuit), but extend it to take into account classical processing between QNode args and gate args.\nThis is pretty simple to do.\nLet\n\n\nx\\in \\mathbb{R}^m be the QNode parameters\n\n\nf: \\mathbb{R}^m \\rightarrow \\mathbb{R}^n be the function representing the transformation from QNode arguments to gate arguments,\n\n\nq: \\mathbb{R}^n \\rightarrow \\mathbb{R} be the quantum function,\n\n\nC = q \\circ f:  \\mathbb{R}^m\\rightarrow \\mathbb{R} the overall cost function, and\n\n\ng^{-1} be the pseudo-inverse of the Fubini-Study metric tensor of q.\n\n\nOur cost function is therefore C(x) = q(f(x)), with a (quantum) natural gradient of\n\n\\nabla_{\\text{NatGrad}}~C(x) =\\mathbf{J}_q(x) ~ g^{-1} ~\\mathbf{J}_f(x).\n\nWe can use the qml.transforms.classical_jacobian() transform to extract \\mathbf{J}_f(x),  qml.metric_tensor() to extract g, and the (not well documented) qnode.qtape.jacobian method to extract \\mathbf{J}_q(x):\nfrom pennylane import numpy as np\nimport pennylane as qml\nfrom scipy.linalg import pinvh\n\ndev = qml.device(\"default.qubit\", wires=2)\n\n@qml.qnode(dev)\ndef circuit(params, wires=[0, 1]):\n    qml.Hadamard(wires=wires[0])\n    qml.Hadamard(wires=wires[1])\n    qml.RZ(params[0], wires=wires[0])\n    qml.RZ(params[0], wires=wires[1])\n    qml.CNOT(wires=[0, 1])\n    qml.RZ(params[1], wires=wires[1])\n    qml.CRX(params[2], wires=wires)\n    qml.CRY(params[2], wires=wires)\n    return qml.expval(qml.PauliY(0))\n\ninit_params = np.array([0.1, 0.2, 0.3])\n\n# extract Jf(x)\nJf = qml.transforms.classical_jacobian(circuit)(init_params)\n\n# extract Jq(x)\ncircuit.construct([init_params], {})\nJq = circuit.qtape.jacobian(params=Jf @ init_params, device=dev)\n\n# extract g\ng= qml.metric_tensor(circuit)(init_params)\n\n# compute the natural gradient\nprint(\"NatGad =\", Jq @ pinvh(g) @ Jf)\n\nOr, writing this as a function:\ndef natgrad(qnode):\n    Jf = qml.transforms.classical_jacobian(qnode)\n    g= qml.metric_tensor(circuit)\n    dev = qnode.device\n\n    def _natgrad(params):\n        qnode.construct([params], {})\n        gate_params = Jf(params) @ params\n        Jq = circuit.qtape.jacobian(params=gate_params, device=dev)\n        return Jq @ pinvh(g(params)) @ Jf(params)\n\n    return _natgrad\n\nnatgrad(circuit)(init_params)\n\n\nNote: in the case where J_f = I, this reduces down to our standard natural gradient result:\n@qml.qnode(dev)\ndef circuit(params, wires=[0, 1]):\n    qml.Hadamard(wires=wires[0])\n    qml.Hadamard(wires=wires[1])\n    qml.RZ(params[0], wires=wires[0])\n    # qml.RZ(params[0], wires=wires[1])\n    qml.CNOT(wires=[0, 1])\n    qml.RZ(params[1], wires=wires[1])\n    qml.CRX(params[2], wires=wires)\n    # qml.CRY(params[2], wires=wires)\n    return qml.expval(qml.PauliY(0))\n\nprint(\"Our extended natgrad = \", natgrad(circuit)(init_params))\n\ng = qml.metric_tensor(circuit)(init_params)\nprint(\"Standard natgrad =\", pinvh(g) @ qml.grad(circuit)(init_params))\n\n\nAdditional thoughts:\n\n\nWe should add a qml.transforms.quantum_jacobian function to make it easier to extract the quantum portion of the Jacobian directly \n\n\nLong term, it may make sense to build this directly into PennyLane. That is, re-position QNG as a gradient method, rather than an optimization technique.\n\n1", "link": "https://discuss.pennylane.ai//t/quantum-natural-gradient-optimizer-with-user-defined-gates/1006/2"}, "2": {"author": "hsim", "date": "1619619422843", "content": "Thanks, @josh!\nHow would I extend this for qml.ExpvalCost which, if I understood correctly, uses a collection of QNodes?", "link": "https://discuss.pennylane.ai//t/quantum-natural-gradient-optimizer-with-user-defined-gates/1006/3"}, "3": {"author": "josh", "date": "1619623013657", "content": "No worries @hsim!\nI\u2019ve generalized my previous answer to account for ExpvalCost:\ndef quantum_jacobian(qnode):\n    \"\"\"Returns a function that computes the purely\n    quantum Jacobian of a QNode\"\"\"\n    if isinstance(qnode, qml.ExpvalCost):\n        qnodes = qnode.qnodes\n        coeffs = qnode.hamiltonian.coeffs\n\n        def _jacobian(*args, **kwargs):\n            jacs = [quantum_jacobian(q)(*args, **kwargs) for q in qnodes]\n            return qml.math.sum([c * j for c, j in zip(coeffs, jacs)], axis=0)\n\n        return _jacobian\n\n    dev = qnode.device\n\n    def _jacobian(*args, **kwargs):\n        qnode.construct(args, kwargs)\n        params = qml.math.stack(qnode.qtape.get_parameters())\n\n        def func(params):\n            return qml.math.stack(qnode.qtape.execute(params=params, device=dev))\n\n        return qml.jacobian(func)(params)\n\n    return _jacobian\n\n\ndef natgrad(qnode):\n    \"\"\"Returns a function that computes\n    the natural gradient of a QNode\"\"\"\n    Jq = quantum_jacobian(qnode)\n    g = qml.metric_tensor(qnode)\n\n    if isinstance(qnode, qml.ExpvalCost):\n        qnode = qnode.qnodes[0]\n\n    Jf = qml.transforms.classical_jacobian(qnode)\n\n    def _natgrad(*args, **kwargs):\n        mt = g(*args, **kwargs)\n        c = Jf(*args, **kwargs)\n        q = Jq(*args, **kwargs)\n        ng = qml.math.dot(q, pinvh(mt))\n        return qml.math.squeeze(qml.math.dot(ng, c))\n\n    return _natgrad\n\nWith these functions defined, the following now works:\ndev = qml.device(\"default.qubit\", wires=2)\n\ndef circuit(params, wires=[0, 1]):\n    qml.Hadamard(wires=wires[0])\n    qml.Hadamard(wires=wires[1])\n    qml.RZ(params[0], wires=wires[0])\n    qml.RZ(params[0], wires=wires[1])\n    qml.CNOT(wires=[0, 1])\n    qml.RZ(params[1], wires=wires[1])\n    qml.CRX(params[2], wires=wires)\n    qml.CRY(params[2], wires=wires)\n\ncoeffs = [1, 1]\nobs = [qml.PauliX(0), qml.PauliZ(1)]\nH = qml.Hamiltonian(coeffs, obs)\n\ncircuit = qml.ExpvalCost(circuit, H, dev, interface=\"autograd\")\ninit_params = np.array([0.1, 0.2, 0.3])\n\n>>> print(\"Cost function=\", circuit(init_params))\nCost function= 0.8501644188535566\n>>> print(\"Our extended natgrad = \", natgrad(circuit)(init_params))\nOur extended natgrad =  [ -0.79210435   0.666934   -44.93205788]\n\nDisclaimer: I\u2019ve tested that this produces the correct output when parameters are not repeated, but have not tested it otherwise!Solution", "link": "https://discuss.pennylane.ai//t/quantum-natural-gradient-optimizer-with-user-defined-gates/1006/4"}, "4": {"author": "hsim", "date": "1619549905553", "content": "Hi,\nI was trying to use the quantum natural gradient (QNG) optimizer on a toy VQE problem where the ansatz employs user-defined gates \u2018XX\u2019 and \u2018YY\u2019 (defined below).\nWhen trying to take an optimizer step, I got the following error: \u201cValueError: solve1: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (m,m),(m)->(m) (size 3 is different from 4)\u201d coming from\nnp.linalg.solve(self.metric_tensor, grad_flat)\n\nI didn\u2019t encounter this error when using a circuit with Pennylane-defined gates. I think the error might be because I use the same parameter for both XX and YY gates but wasn\u2019t sure how to fix this error.\nThis was my code:\nfrom pennylane import numpy as np\nimport pennylane as qml\n\ndev = qml.device(\"default.qubit\", wires=2)\ndev.operations.update({\"XX\", \"YY\"})\n\ndef circuit(params, wires=[0, 1]):\n    qml.PauliX(wires=wires[1])\n    qml.RZ(params[0], wires=wires[0])\n    qml.RZ(params[1], wires=wires[1])\n    XX(params[2], wires=wires)\n    YY(params[2], wires=wires)\n\ncoeffs = [1, 1]\nobs = [qml.PauliX(0), qml.PauliZ(1)]\nH = qml.Hamiltonian(coeffs, obs)\ncost_fn = qml.ExpvalCost(circuit, H, dev)\n\ninit_params = np.random.uniform(size=3)\n\nopt = qml.QNGOptimizer(stepsize=0.01, diag_approx=False)\n\nparams, prev_energy = opt.step_and_cost(cost_fn, init_params)\n\nAnd the two user-defined gates are:\nclass XX(qml.operation.Operation):\n    num_params = 1 \n    num_wires = 2 \n    par_domain = \"R\" \n    grad_method = \"A\" \n    generator = [np.kron(X, X), -0.5]\n    \n    @staticmethod\n    def _matrix(*params):\n        return np.cos(params[0]/2)*np.eye(4) + 1.j*np.sin(params[0]/2)*np.kron(X,X)\n\nclass YY(qml.operation.Operation):\n    num_params = 1 \n    num_wires = 2 \n    par_domain = \"R\" \n    grad_method = \"A\"\n    generator = [np.kron(Y, Y), -0.5]\n    \n    @staticmethod\n    def _matrix(*params):\n        return np.cos(params[0]/2)*np.eye(4) + 1.j*np.sin(params[0]/2)*np.kron(Y,Y)\n\n\n Solved by josh in post #4 \n\n\n                No worries @hsim! \nI\u2019ve generalized my previous answer to account for ExpvalCost: \ndef quantum_jacobian(qnode):\n    \"\"\"Returns a function that computes the purely\n    quantum Jacobian of a QNode\"\"\"\n    if isinstance(qnode, qml.ExpvalCost):\n        qnodes = qnode.qnodes\n        coeffs = qnode.hamilto\u2026\n              \n", "link": "https://discuss.pennylane.ai//t/quantum-natural-gradient-optimizer-with-user-defined-gates/1006/5"}, "5": {"author": "josh", "date": "1619587633202", "content": "Hi @hsim!\nThe issue here is that the metric tensor is only defined for the quantum circuit gate arguments, while the optimizer is instead optimizing the QNode arguments.\nThis is a bit of subtlety\u2014in most cases, there is a 1-1 mapping between QNode arguments and gate arguments, so this issue doesn\u2019t arise! As you note, however, the repeated parameter between the XX and YY breaks this 1-1 mapping.\nIn other words: the optimizer is assuming that the object it is optimizing is a pure quantum circuit with a well-defined metric tensor with respect to QNode arguments, which is not the case.\n\nWorkarounds\nOne workaround is to write out the QNG optimization manually using qml.metric_tensor (which extracts the metric tensor of the underlying quantum circuit), but extend it to take into account classical processing between QNode args and gate args.\nThis is pretty simple to do.\nLet\n\n\nx\\in \\mathbb{R}^mx\u2208Rm be the QNode parameters\n\n\nf: \\mathbb{R}^m \\rightarrow \\mathbb{R}^nf:Rm\u2192Rn be the function representing the transformation from QNode arguments to gate arguments,\n\n\nq: \\mathbb{R}^n \\rightarrow \\mathbb{R}q:Rn\u2192R be the quantum function,\n\n\nC = q \\circ f:  \\mathbb{R}^m\\rightarrow \\mathbb{R}C=q\u2218f:Rm\u2192R the overall cost function, and\n\n\ng^{-1}g\u22121 be the pseudo-inverse of the Fubini-Study metric tensor of qq.\n\n\nOur cost function is therefore C(x) = q(f(x))C(x)=q(f(x)), with a (quantum) natural gradient of\n\n\\nabla_{\\text{NatGrad}}~C(x) =\\mathbf{J}_q(x) ~ g^{-1} ~\\mathbf{J}_f(x).\n\u2207NatGrad\u00a0C(x)=Jq(x)\u00a0g\u22121\u00a0Jf(x).\nWe can use the qml.transforms.classical_jacobian() transform to extract \\mathbf{J}_f(x)Jf(x),  qml.metric_tensor() to extract gg, and the (not well documented) qnode.qtape.jacobian method to extract \\mathbf{J}_q(x)Jq(x):\nfrom pennylane import numpy as np\nimport pennylane as qml\nfrom scipy.linalg import pinvh\n\ndev = qml.device(\"default.qubit\", wires=2)\n\n@qml.qnode(dev)\ndef circuit(params, wires=[0, 1]):\n    qml.Hadamard(wires=wires[0])\n    qml.Hadamard(wires=wires[1])\n    qml.RZ(params[0], wires=wires[0])\n    qml.RZ(params[0], wires=wires[1])\n    qml.CNOT(wires=[0, 1])\n    qml.RZ(params[1], wires=wires[1])\n    qml.CRX(params[2], wires=wires)\n    qml.CRY(params[2], wires=wires)\n    return qml.expval(qml.PauliY(0))\n\ninit_params = np.array([0.1, 0.2, 0.3])\n\n# extract Jf(x)\nJf = qml.transforms.classical_jacobian(circuit)(init_params)\n\n# extract Jq(x)\ncircuit.construct([init_params], {})\nJq = circuit.qtape.jacobian(params=Jf @ init_params, device=dev)\n\n# extract g\ng= qml.metric_tensor(circuit)(init_params)\n\n# compute the natural gradient\nprint(\"NatGad =\", Jq @ pinvh(g) @ Jf)\n\nOr, writing this as a function:\ndef natgrad(qnode):\n    Jf = qml.transforms.classical_jacobian(qnode)\n    g= qml.metric_tensor(circuit)\n    dev = qnode.device\n\n    def _natgrad(params):\n        qnode.construct([params], {})\n        gate_params = Jf(params) @ params\n        Jq = circuit.qtape.jacobian(params=gate_params, device=dev)\n        return Jq @ pinvh(g(params)) @ Jf(params)\n\n    return _natgrad\n\nnatgrad(circuit)(init_params)\n\n\nNote: in the case where J_f = IJf=I, this reduces down to our standard natural gradient result:\n@qml.qnode(dev)\ndef circuit(params, wires=[0, 1]):\n    qml.Hadamard(wires=wires[0])\n    qml.Hadamard(wires=wires[1])\n    qml.RZ(params[0], wires=wires[0])\n    # qml.RZ(params[0], wires=wires[1])\n    qml.CNOT(wires=[0, 1])\n    qml.RZ(params[1], wires=wires[1])\n    qml.CRX(params[2], wires=wires)\n    # qml.CRY(params[2], wires=wires)\n    return qml.expval(qml.PauliY(0))\n\nprint(\"Our extended natgrad = \", natgrad(circuit)(init_params))\n\ng = qml.metric_tensor(circuit)(init_params)\nprint(\"Standard natgrad =\", pinvh(g) @ qml.grad(circuit)(init_params))\n\n\nAdditional thoughts:\n\n\nWe should add a qml.transforms.quantum_jacobian function to make it easier to extract the quantum portion of the Jacobian directly \n\n\nLong term, it may make sense to build this directly into PennyLane. That is, re-position QNG as a gradient method, rather than an optimization technique.\n\n1", "link": "https://discuss.pennylane.ai//t/quantum-natural-gradient-optimizer-with-user-defined-gates/1006/6"}}