{"0": {"author": "NikSchet", "date": "1655835741786", "content": "Hello!\nI would like to build a siamese quantum neural network (as inputs I would like to start with MNIST dataset). My main problem is the Differencing layer (see picture). In the differencing layer we calculate the difference of these two dense layers and output the result to a single neuron with sigmoid activation function(0 to 1).\nAny ideas on how to implement that? Thank you in advance! (any ideas on the general architecture would be appreciated)\np.s. for more information on siamese neural networks: Siamese Networks. Line by line explanation for beginners | by Krishna Prasad | Towards Data Science 4\n\n1_eMehqF0SloigS1tppMEiEw856\u00d7510 65.9 KB\n", "link": "https://discuss.pennylane.ai//t/siamese-q-neural-networks/1988/1"}, "1": {"author": "CatalinaAlbornoz", "date": "1655846720641", "content": "Hi @NikSchet,\nIn the link that you shared there is a code example for this siamese layer. My suggestion would be that you first test the code as it is and then start changing aspects of it.\nIf you want to add a quantum layer you can follow the example of our demo on turning quantum nodes into Keras layers. You would create a qnode, turn it into a Keras layer using qml.qnn.KerasLayer, and then add it to the sequential model.\nOnce you get this working then I would suggest exploring a dataset change if that\u2019s your goal. We have an example using the MNIST dataset here 1, although using this dataset is probably not ideal if you\u2019re trying to measure performance. This blog post 1 by Maria Schuld has a great explanation on why always using MNIST may not be the best path forward.\nI hope this helps you and let me know if you have any questions while building this neural network!1", "link": "https://discuss.pennylane.ai//t/siamese-q-neural-networks/1988/2"}, "2": {"author": "NikSchet", "date": "1655835741786", "content": "Hello!\nI would like to build a siamese quantum neural network (as inputs I would like to start with MNIST dataset). My main problem is the Differencing layer (see picture). In the differencing layer we calculate the difference of these two dense layers and output the result to a single neuron with sigmoid activation function(0 to 1).\nAny ideas on how to implement that? Thank you in advance! (any ideas on the general architecture would be appreciated)\np.s. for more information on siamese neural networks: Siamese Networks. Line by line explanation for beginners | by Krishna Prasad | Towards Data Science 4\n\n1_eMehqF0SloigS1tppMEiEw856\u00d7510 65.9 KB\n", "link": "https://discuss.pennylane.ai//t/siamese-q-neural-networks/1988/3"}}