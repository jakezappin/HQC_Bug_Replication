{"0": {"author": "RX1", "date": "1665388568007", "content": "image1093\u00d7606 13.1 KB\nimage1157\u00d7278 37.5 KB\nimage1220\u00d7784 110 KB\nimage1148\u00d7756 106 KB\nimage945\u00d7887 62.4 KB\nWe study the case AA and find that the training is invalid, the trained parameters are the same as the initialized parameters, I wonder why?\nimage1297\u00d7974 24.3 KB\n\nStep 0 done.\n[tensor([[ 0.22291946, -0.11248928,  0.04565372, \u2026,  0.06703037,\n-0.02766389,  0.08405803],\n[ 0.08830776,  0.0598873 ,  0.08355277, \u2026, -0.03754032,\n0.03460176,  0.02242945]], requires_grad=True), tensor([[ 0.11442182, -0.17605075, -0.01458899],\n[-0.13463645, -0.11874351, -0.0132903 ],\n[ 0.03468135, -0.05576273,  0.01454365],\n[-0.10994996, -0.01509634,  0.07580086]], requires_grad=True)]\nStep 1 done.\n[tensor([[ 0.22291946, -0.11248928,  0.04565372, \u2026,  0.06703037,\n-0.02766389,  0.08405803],\n[ 0.08830776,  0.0598873 ,  0.08355277, \u2026, -0.03754032,\n0.03460176,  0.02242945]], requires_grad=True), tensor([[ 0.11442182, -0.17605075, -0.01458899],\n[-0.13463645, -0.11874351, -0.0132903 ],\n[ 0.03468135, -0.05576273,  0.01454365],\n[-0.10994996, -0.01509634,  0.07580086]], requires_grad=True)]\nStep 2 done.\n[tensor([[ 0.22291946, -0.11248928,  0.04565372, \u2026,  0.06703037,\n-0.02766389,  0.08405803],\n[ 0.08830776,  0.0598873 ,  0.08355277, \u2026, -0.03754032,\n0.03460176,  0.02242945]], requires_grad=True), tensor([[ 0.11442182, -0.17605075, -0.01458899],\n[-0.13463645, -0.11874351, -0.0132903 ],\n[ 0.03468135, -0.05576273,  0.01454365],\n[-0.10994996, -0.01509634,  0.07580086]], requires_grad=True)]\nStep 3 done.\n[tensor([[ 0.22291946, -0.11248928,  0.04565372, \u2026,  0.06703037,\n-0.02766389,  0.08405803],\n[ 0.08830776,  0.0598873 ,  0.08355277, \u2026, -0.03754032,\n0.03460176,  0.02242945]], requires_grad=True), tensor([[ 0.11442182, -0.17605075, -0.01458899],\n[-0.13463645, -0.11874351, -0.0132903 ],\n[ 0.03468135, -0.05576273,  0.01454365],\n[-0.10994996, -0.01509634,  0.07580086]], requires_grad=True)]\nStep 4 done.\n[tensor([[ 0.22291946, -0.11248928,  0.04565372, \u2026,  0.06703037,\n-0.02766389,  0.08405803],\n[ 0.08830776,  0.0598873 ,  0.08355277, \u2026, -0.03754032,\n0.03460176,  0.02242945]], requires_grad=True), tensor([[ 0.11442182, -0.17605075, -0.01458899],\n[-0.13463645, -0.11874351, -0.0132903 ],\n[ 0.03468135, -0.05576273,  0.01454365],\n[-0.10994996, -0.01509634,  0.07580086]], requires_grad=True)]\nStep 5 done.\n[tensor([[ 0.22291946, -0.11248928,  0.04565372, \u2026,  0.06703037,\n-0.02766389,  0.08405803],\n[ 0.08830776,  0.0598873 ,  0.08355277, \u2026, -0.03754032,\n0.03460176,  0.02242945]], requires_grad=True), tensor([[ 0.11442182, -0.17605075, -0.01458899],\n[-0.13463645, -0.11874351, -0.0132903 ],\n[ 0.03468135, -0.05576273,  0.01454365],\n[-0.10994996, -0.01509634,  0.07580086]], requires_grad=True)]\n\nWe found out that the training is ineffective, the parameters generated by each iteration do not change and therefore cannot be dichotomized.\n@Maria_Schuld\n@manu_manohar\n@Andre_Tavares", "link": "https://discuss.pennylane.ai//t/why-does-the-embedding-metric-learning-case-not-work/2211/1"}, "1": {"author": "Maria_Schuld", "date": "1665399046298", "content": "Hey @RX1! The demo was taken down years ago, I wonder where you found it? \nThe reason was a bug: the training data and test data was accidentally identical. But when fixing the bug, the results of the demo didn\u2019t work out so easily any more (more precisely, the hybrid model overfitted). I simply didn\u2019t have the time to rewrite the demo, so it was removed\u2026\nIn other words, you are using this outdated code at your own risk ", "link": "https://discuss.pennylane.ai//t/why-does-the-embedding-metric-learning-case-not-work/2211/2"}, "2": {"author": "RX1", "date": "1665399398954", "content": "emmm\u2026 . well, thanks for the answer, I followed you on Google Scholar. Is there any task about QNN or VQA for MNIST dichotomization? I\u2019m trying to study it.", "link": "https://discuss.pennylane.ai//t/why-does-the-embedding-metric-learning-case-not-work/2211/3"}, "3": {"author": "isaacdevlugt", "date": "1665494123705", "content": "Hey @RX1,\nThere are some PennyLane demos that use the MNIST dataset here:\nUsing quantum convolutional neural networks 3\nA demo made by the community 4\nUsing a quantum GAN 2", "link": "https://discuss.pennylane.ai//t/why-does-the-embedding-metric-learning-case-not-work/2211/4"}, "4": {"author": "Jonathan_Kim1", "date": "1665804522275", "content": "Hi @RX1 ,\nI\u2019ve been looking into this demo for a while now and the reason it doesn\u2019t train is because the most recent versions of pennylane don\u2019t seem to be able to recognize the hybrid mix of parameters as being trainable parameters. If you use version 0.18.0 of pennylane, it should train.\nHowever, as @Maria_Schuld pointed out, it does overfit greatly on the image data.  I\u2019ve tried ommiting the ResNet-18 and carrying out various degrees of PCA on the pixel data, as well as carrying out PCA directly on the ResNet-18 output features but this does not improve the generalization (the level of dimensional reduction is likely too extreme).\nIt actually does work pretty well on datasets that have a greater number of training samples than the number of features per sample, though - I used the UCI ML Breast Cancer Diagnostic dataset which has 30 clinical features associated with each sample and around 500 total samples (around 300 of which are training samples), and it generalizes pretty well with test set precision, recall and F1 scores all above 0.96 (if you apply PCA to the 30 features). Test set cost of course doesn\u2019t go as low as it did for the original overfitting image data, but it\u2019s not too bad - I\u2019ve found it can go as low as about 0.25.\nAs far as I can tell, with the current circuit, the method should work well with other datasets, again as long as you keep the number of features representing each sample to be substantially lower than the number of training samples - I imagine it could work with image data too, but perhaps only with a significant number of training images. Each image in the MNIST dataset is fairly simple, and the number of samples is quite large so I can see it possibly working quite well with this approach, particularly after moderate dimensional reduction.\nI\u2019ve submitted the PCA breast cancer version of the demo as a new pull request to the pennylane qml repo, hoping it can maybe be used a revived/revised version of the old demo. For now, you can find it in this fork 3.1", "link": "https://discuss.pennylane.ai//t/why-does-the-embedding-metric-learning-case-not-work/2211/5"}, "5": {"author": "RX1", "date": "1665388568007", "content": "image1093\u00d7606 13.1 KB\nimage1157\u00d7278 37.5 KB\nimage1220\u00d7784 110 KB\nimage1148\u00d7756 106 KB\nimage945\u00d7887 62.4 KB\nWe study the case AA and find that the training is invalid, the trained parameters are the same as the initialized parameters, I wonder why?\nimage1297\u00d7974 24.3 KB\n\nStep 0 done.\n[tensor([[ 0.22291946, -0.11248928,  0.04565372, \u2026,  0.06703037,\n-0.02766389,  0.08405803],\n[ 0.08830776,  0.0598873 ,  0.08355277, \u2026, -0.03754032,\n0.03460176,  0.02242945]], requires_grad=True), tensor([[ 0.11442182, -0.17605075, -0.01458899],\n[-0.13463645, -0.11874351, -0.0132903 ],\n[ 0.03468135, -0.05576273,  0.01454365],\n[-0.10994996, -0.01509634,  0.07580086]], requires_grad=True)]\nStep 1 done.\n[tensor([[ 0.22291946, -0.11248928,  0.04565372, \u2026,  0.06703037,\n-0.02766389,  0.08405803],\n[ 0.08830776,  0.0598873 ,  0.08355277, \u2026, -0.03754032,\n0.03460176,  0.02242945]], requires_grad=True), tensor([[ 0.11442182, -0.17605075, -0.01458899],\n[-0.13463645, -0.11874351, -0.0132903 ],\n[ 0.03468135, -0.05576273,  0.01454365],\n[-0.10994996, -0.01509634,  0.07580086]], requires_grad=True)]\nStep 2 done.\n[tensor([[ 0.22291946, -0.11248928,  0.04565372, \u2026,  0.06703037,\n-0.02766389,  0.08405803],\n[ 0.08830776,  0.0598873 ,  0.08355277, \u2026, -0.03754032,\n0.03460176,  0.02242945]], requires_grad=True), tensor([[ 0.11442182, -0.17605075, -0.01458899],\n[-0.13463645, -0.11874351, -0.0132903 ],\n[ 0.03468135, -0.05576273,  0.01454365],\n[-0.10994996, -0.01509634,  0.07580086]], requires_grad=True)]\nStep 3 done.\n[tensor([[ 0.22291946, -0.11248928,  0.04565372, \u2026,  0.06703037,\n-0.02766389,  0.08405803],\n[ 0.08830776,  0.0598873 ,  0.08355277, \u2026, -0.03754032,\n0.03460176,  0.02242945]], requires_grad=True), tensor([[ 0.11442182, -0.17605075, -0.01458899],\n[-0.13463645, -0.11874351, -0.0132903 ],\n[ 0.03468135, -0.05576273,  0.01454365],\n[-0.10994996, -0.01509634,  0.07580086]], requires_grad=True)]\nStep 4 done.\n[tensor([[ 0.22291946, -0.11248928,  0.04565372, \u2026,  0.06703037,\n-0.02766389,  0.08405803],\n[ 0.08830776,  0.0598873 ,  0.08355277, \u2026, -0.03754032,\n0.03460176,  0.02242945]], requires_grad=True), tensor([[ 0.11442182, -0.17605075, -0.01458899],\n[-0.13463645, -0.11874351, -0.0132903 ],\n[ 0.03468135, -0.05576273,  0.01454365],\n[-0.10994996, -0.01509634,  0.07580086]], requires_grad=True)]\nStep 5 done.\n[tensor([[ 0.22291946, -0.11248928,  0.04565372, \u2026,  0.06703037,\n-0.02766389,  0.08405803],\n[ 0.08830776,  0.0598873 ,  0.08355277, \u2026, -0.03754032,\n0.03460176,  0.02242945]], requires_grad=True), tensor([[ 0.11442182, -0.17605075, -0.01458899],\n[-0.13463645, -0.11874351, -0.0132903 ],\n[ 0.03468135, -0.05576273,  0.01454365],\n[-0.10994996, -0.01509634,  0.07580086]], requires_grad=True)]\n\nWe found out that the training is ineffective, the parameters generated by each iteration do not change and therefore cannot be dichotomized.\n@Maria_Schuld\n@manu_manohar\n@Andre_Tavares", "link": "https://discuss.pennylane.ai//t/why-does-the-embedding-metric-learning-case-not-work/2211/6"}}