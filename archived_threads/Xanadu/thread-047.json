{"0": {"author": "Kuma-quant", "date": "1639963951111", "content": "I\u2019m interested in quantum supervised machine learnings such as QSVM.\nThe QSVM takes a lot of time for training because  N*(N-1)/2 individual circuits exectutions are required.\nKernel-based training of quantum models with scikit-learn \u2014 PennyLane 4\nAssume the number of traning data is 1,000, the number of circuit execution is as large as 500,000.\nTherefore, the training step takes huge time even if I use Pennylane.\nMy question is, can I parallelize  circuit executions?\nIn case of SV1 remote simulator in AWS, I confirmed that parallerization is possible.  Because SV1 natively supports parallelization.\nBut I want to parallelize the circuit executions for local simulators.\nI have tried QNodeCollection class with dask, however, no acceleration was obsereved as follows,\npennylane is v0.20.0\nimport pennylane as qml\nfrom pennylane import numpy as np\nn_qubits = 20\ndev = qml.device('lightning.qubit', wires=n_qubits)\n@qml.qnode(dev)\ndef circuit():\n    for i in range(n_qubits):\n        qml.Hadamard(wires=i)\n    return qml.expval(qml.PauliZ(0))\n\n# one circuit execution\n%time circuit() \n\nWall time: 220 ms\nNum_of_circuits = 2\n# construct qnodes for two circuit executions\ncircuits = qml.QNodeCollection([circuit]*Num_of_circuits)\n# two circuit executions\n%time circuits(parallel=True)\n\nWall time: 592 ms\nThe above time is almost two times larger than that of one circuit exectuion\u2026\nIs there a technique for parallelization?\nThis may be python-help rather than pennylane-help\u2026", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/1"}, "1": {"author": "ankit27kh", "date": "1640000137841", "content": "Hey @Kuma-quant, you can use JAX and the various functionalities it provides to speed up your simulations significantly. This demo 33 might help.", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/2"}, "2": {"author": "mlxd", "date": "1640000586965", "content": "Hi @Kuma-quant thanks for the question on this.\nWhen you say parallelization here, I assume you mean parallelization over data \u2014 ie different inputs to the same circuits. If you intend on doing model parallelism (ie distributed parts of the same computation over multiple cores), it may be best to explore the use of the PyTorch or TensorFlow interfaces. Also, given the example has many iterative steps, it will not in general be possible to parallelize between iterations. That being said, if parallel circuit evaluations are needed, we can explore this as follows:\n\nFirstly, the QNodeCollection Dask support remains experimental. The existing Dask support offloads operations as threads to the chosen device. This works fine in the provided example from https://pennylane.readthedocs.io/en/stable/code/api/pennylane.QNodeCollection.html as the chosen devices exist on separate processes (Rigetti QVMs as listed). However, since we are using the device within the same process here, we may hit the usual threading problem that Python users tend to hit: the GIL. It may be possible to direct the Dask backend to use processes rather than threads, though the recommended approach from the Dask docs is to favour the distributed backend for these problems (https://docs.dask.org/en/latest/how-to/deploy-dask/single-machine.html#use-the-distributed-scheduler). We are currently working on a native Dask-distributed capable backend that will allow parallelization across multiple machines. However, this is still under active development.\nIt may be possible to offload tasks using the Python multiprocessing 5 module, and I think this may be the preferred way to go here if you wish to carry out multiple executions on your local machine. I have adapted your supplied script to examine a few cases with some heavier circuits: (i) a single execution of a parametric circuit, (ii) serial execution using the same QNodeCollection you have examined, and (iii) offloading the operations to a multiprocessing Pool.\n\nimport pennylane as qml\nfrom pennylane import numpy as np\nn_qubits = 20\nfrom multiprocessing import Pool, Lock\nfrom timeit import default_timer as timer\n\ndev = qml.device('lightning.qubit', wires=n_qubits)\nx_params, y_params = np.random.rand(n_qubits), np.random.rand(n_qubits)\nNum_of_circuits = 20\n\n# timing results data\ntimings = {}\n\n@qml.qnode(dev)\ndef circuit1(x, y):\n    for i in range(n_qubits):\n        qml.Hadamard(wires=i)\n        qml.RX(x[i], wires=i)\n        qml.RY(y[i], wires=i)\n        qml.CNOT(wires=[i, (i+1)%n_qubits])\n    return [qml.var(qml.PauliZ(i)) for i in range(n_qubits)]\n\n# Used for async offloading as decorators do not play nicely with multiproc async\ndef process_f(x,y):\n    return circuit1(x,y)\n\n# Callback from async operation to add results to array\ndef collect_result(result):\n    lock.acquire()\n    try:\n        results_mp.append(result)\n    finally:\n        lock.release()\n\n# Data for Multiprocessing env Pool and Lock must be created below required functions\nresults_mp = []\npool = Pool(4) # assumes 4 available physical cores\nlock = Lock()\n\n# one circuit execution\ntry:\n    start_1 = timer()\n    circuit1(x_params, y_params) \n    end_1 = timer()\n    timings[\"single\"] = end_1 - start_1\nexcept Exception as e:\n    print(f\"Failed to run single execution: {e}\")\n\n# construct qnodes for Num_of_circuits circuit executions\ncircuits = qml.QNodeCollection([circuit1]*Num_of_circuits)\n\n# Explicitly time serial execution\ntry:\n    start_s = timer()\n    results_s = circuits(x_params, y_params)\n    end_s = timer()\n    timings[\"serial\"] = end_s - start_s\nexcept Exception as e:\n    print(f\"Failed to run serial code: {e}\")\n\n# time parallel execution using multiprocessing pool\ntry:\n    start_mp = timer()\n    futures = [pool.apply_async(process_f, args=(x_params,y_params), callback=collect_result) for x in range(Num_of_circuits)]\n    # Synchronize when finished\n    pool.close()\n    pool.join()\n    end_mp = timer()\n    timings[\"multiproc\"] = end_mp - start_mp\nexcept Exception as e:\n    print(f\"Failed to run multiprocessing code: {e}\")\n\nprint(f\"Elapsed times: {timings}\")\n\nOn my machine, I have >4 cores available, so my execution gives:\nElapsed times: {'single': 0.6598089630133472, 'serial': 12.97552589897532, 'multiproc': 4.972487455990631}\nwhich is roughly a 2.5x speedup, over the serial execution (I made sure to attempt timing the overheads involved also). However, there can be many sharp-edges with this type of workflow, and you may have limited success (see https://bugs.python.org/issue25053 for an example of a race-condition bug in the Pool). Though, it may help you with your example.\nFeel free to follow-up if the above does not help with your problem, or if it does, we\u2019d be happy to know.", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/3"}, "3": {"author": "Kuma-quant", "date": "1640617986739", "content": "Thanks, @ankit27kh and @mlxd !!\nI\u2019m trying two methods.\n\n\nmultiprocessing module\n\njax and the jax.jit\n\n\nRewriting my code for multiprocessing seems a tough work for me\u2026\nOn the other hand, Rewriting my code for jax was easy for me.\nHere is a part of sample code.\nThen I got siginificant speed up by jax!\n\nX_train_jnp = device_put(X_train)\ny_train_jnp = device_put(y_train)\n\n@qml.qnode(dev, interface=\"jax\")\ndef kernel(x1, x2):\n    \"\"\"The quantum kernel.\"\"\"\n    #S(x=x1)\n    for i in range(n_qubits):\n        qml.RX(x1[i%n_dim], wires=[i]) \n    for i in range(n_qubits):\n        qml.CNOT(wires=[i,(i+1)%n_qubits])\n    \n    #S^dagger(x=x2)\n    for i in range(n_qubits-1,-1,-1):\n        qml.CNOT(wires=[i,(i+1)%n_qubits])\n    for i in range(n_qubits-1,-1,-1):\n        qml.RX(-1*x2[i%n_dim], wires=[i]) \n    return qml.expval(qml.Hermitian(projector, wires=range(n_qubits))) \n\njit_kernel = jax.jit(kernel)\n\ndef kernel_matrix(A, B):\n    \"\"\"Compute the matrix whose entries are the kernel\n       evaluated on pairwise data from sets A and B.\"\"\"\n    return np.array([[jit_kernel(a, b) for b in B] for a in A])\n\n%time svm = SVC(kernel=kernel_matrix).fit(X_train_jnp, y_train_jnp)\n\nThe processing time w/o jit was 41 sec.\nThe processing time w/ jit was 21.8 msec.\nAmazing!\nMoreover,\nThe processing time w/o jit but w/ lightning.qubit was ~4 sec.\nTherefore, jax with jax.jit was the fastest method!", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/4"}, "4": {"author": "Kuma-quant", "date": "1641090723679", "content": "Unfortunately, the acceleration I have observed would be just \u201ccache\u201d\u2026\nUp to 10 qubits, I can\u2019t find improvement by jax compared with lightning.qubit although jax.jit and jax.vmap was also used.\nIn case of >12 qubits, jax consumed almost all of RAM in my PC.\nI beleieve that acceleration by jax will be realized if I use more resources such as multiple-GPU with jax.pmap.\nI want to test multiprocessing.", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/5"}, "5": {"author": "mlxd", "date": "1641552558534", "content": "Hi @Kuma-quant thanks for the feedback. Mapping code to run in parallel can always be fraught with some challenges. In this case, JAX is fantastic when we can reuse the JIT compiled code (as an example, with calculating gradients the circuit can be re-executed multiple times, with different provided parameters). However, when opting for a single execution, it may not work as well, since the JIT process only compiles with the first run of the code (so you factor in compilation AND runtime).\nThough, I am surprised to hear the JAX engine is eating all available RAM. I wonder if this is the compilation process of JAX, or something on our side. Can you provide an example of your code that caused this to happen? Also, any details on your working machine (OS, CPU, available RAM) would be great.\nIf you have access to a CUDA-capable GPU, you can always make use of the TF or Torch GPU support to run your circuit. While the use here is more for backpropagation gradient calculations of the circuit, it may be useful to try it out and see if it helps (https://pennylane.readthedocs.io/en/stable/introduction/interfaces/torch.html#gpu-and-cuda-support 1).\nAs for mapping the problem to multiprocessing, we are currently putting together a device that should allow this to be more seamless.", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/6"}, "6": {"author": "Kuma-quant", "date": "1643361987483", "content": "@mlxd\nI found a bug in my code and fixed it.\nNow jax shows siginificant speed up!\nI have evaluated 10^6 circuits with 10 qubits.\npennylane w/lightning.qubit -> 20~30 sec.  \npennylane w/jax.jit -> ~10 sec.  \npennylane w/jax.jit and jax.vmap -> ~2 sec.  \nqiskit_machine_learning -> ~2 sec.\n\nSiginificant speed up was achieved by jax.jit and jax.vmap.\nI also found that qiskit_machine_learning is also very fast.\n(I have used \u201cQuantum Kernel\u201d class in qiskit_machine_learning.)\nI don\u2019t know the reason\u2026\nThanks all!!", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/7"}, "7": {"author": "CatalinaAlbornoz", "date": "1643403876485", "content": "Hi @Kuma-quant, I\u2019m glad you could fix your problem!\nIt\u2019s interesting to see the speed comparison that you made.\nThanks for sharing it!\nWe will take a look and hopefully we can understand why this is happening.", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/8"}, "8": {"author": "CatalinaAlbornoz", "date": "1643651890422", "content": "Hi @Kuma-quant.\nWe\u2019re looking into why this is happening and it would be very helpful for us if you could share your full code. You should be able to share it here as a Python file.\nPlease let me know if you have any questions or issues sharing your code.", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/9"}, "9": {"author": "Kuma-quant", "date": "1643849650191", "content": "Hi @CatalinaAlbornoz -san,\nHere are python codes to compare pennylane+lightning, pennylane+jax.jit, pennylane+jax.jit+jax.vmap, and qiskit-ml.\nqiskit_machine_learning should be installed in advance.\nThe assumed use-case is QSVM with quantum kernel.\nThe number of circuits for kernel evaluation is 102x102 = 10^4.\n[Main results]\npennylane+lightning : 26.5 sec.\npennylane+jax.jit : 12.4 sec.\npennylane+jax.jit+jax.vmap: 2.13 sec.\nqiskit-ml : 1.34sec.\nSorry. My codes would not be beautiful.\n(1) Pennylane+lightning\nimport pennylane as qml\nfrom pennylane import numpy as np\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import make_classification\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nnp.random.seed(1)\n\nX, y = make_classification(n_features=2, n_redundant=0, n_informative=1, n_clusters_per_class=1, n_samples=1024)\n\n# scaling the inputs is important since the embedding we use is periodic\nscaler = StandardScaler().fit(X)\nX_scaled = scaler.transform(X)\n\n# scaling the labels to -1, 1 is important for the SVM and the\n# definition of a hinge loss\ny_scaled = 2 * (y - 0.5)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, train_size=0.1)\n\nn_qubits = 10\ndev = qml.device(\"lightning.qubit\", wires=n_qubits)\nn_dim = len(X_train[0])\n\n@qml.qnode(dev)\ndef kernel(x1, x2):\n    \"\"\"The quantum kernel.\"\"\"\n    #S(x=x1)\n    for i in range(n_qubits):\n        qml.Hadamard(wires=[i])\n        qml.RZ(x1[i%n_dim], wires=[i])     \n    #S^dagger(x=x2)\n    for i in range(n_qubits-1,-1,-1):\n        qml.RZ(-1*x2[i%n_dim], wires=[i]) \n        qml.Hadamard(wires=[i])\n    return qml.probs(wires=range(n_qubits))\n\ndef kernel_matrix(A, B):\n    \"\"\"Compute the matrix whose entries are the kernel\n       evaluated on pairwise data from sets A and B.\"\"\"\n    return np.array([[kernel(a, b)[0] for b in B] for a in A])\n\nprint(np.shape(X_train)[0],'x',np.shape(X_train)[0],'kernel_matrix','with', n_qubits,'qubits circuits')\n%time kernel_matrix(X_train,X_train)\n\n\n102 x 102 kernel_matrix with 10 qubits circuits CPU times: user 26.4 s, sys: 78.1 ms, total: 26.5 s Wall time: 26.5 s\n(2) Pennylane+jax.jit\nNote: jax might not work well on Windows.\n# Added to silence some warnings.\nfrom jax.config import config\nconfig.update(\"jax_enable_x64\", True)\n\nimport jax\nfrom jax import device_put, jit\nimport pennylane as qml\nfrom jax import numpy as np\n\nfrom sklearn.svm import SVC\nimport numpy as vnp\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_classification\nimport matplotlib.pyplot as plt\n\nvnp.random.seed(1)\n\nX, y = make_classification(n_features=2, n_redundant=0, n_informative=1, n_clusters_per_class=1, n_samples=1024)\n\n# scaling the inputs is important since the embedding we use is periodic\nscaler = StandardScaler().fit(X)\nX_scaled = scaler.transform(X)\n\n# scaling the labels to -1, 1 is important for the SVM and the\n# definition of a hinge loss\ny_scaled = 2 * (y - 0.5)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, train_size=0.1)\n\n\n\nn_qubits = 10\ndev = qml.device(\"default.qubit\", wires=n_qubits)\nn_dim = len(X_train[0])\n\nX_train = device_put(X_train)\ny_train = device_put(y_train)\n\n@qml.qnode(dev, interface=\"jax\")\ndef kernel(x1, x2):\n    \"\"\"The quantum kernel.\"\"\"\n    #S(x=x1)\n    for i in range(n_qubits):\n        qml.Hadamard(wires=[i])\n        qml.RZ(x1[i%n_dim], wires=[i]) \n    \n    #S^dagger(x=x2)\n    for i in range(n_qubits-1,-1,-1):\n        qml.RZ(-1*x2[i%n_dim], wires=[i]) \n        qml.Hadamard(wires=[i])\n    return qml.probs(wires=range(n_qubits))\n\njit_kernel = jax.jit(kernel)\n\ndef kernel_matrix(A, B):\n    \"\"\"Compute the matrix whose entries are the kernel\n       evaluated on pairwise data from sets A and B.\"\"\"\n    return np.array([[jit_kernel(a, b).block_until_ready()[0] for b in B] for a in A])\n\nprint(np.shape(X_train)[0],'x',np.shape(X_train)[0],'kernel_matrix','with', n_qubits,'qubits circuits')\n%time kernel_matrix(X_train,X_train)\n\n102 x 102 kernel_matrix with 10 qubits circuits CPU times: user 12 s, sys: 219 ms, total: 12.3 s Wall time: 12.4 s\n(3) Pennylane+jax.jit+jax.vmap\n# Added to silence some warnings.\nfrom jax.config import config\nconfig.update(\"jax_enable_x64\", True)\n\nimport jax\nfrom jax import device_put, jit\nimport pennylane as qml\nfrom jax import numpy as np\n\nfrom sklearn.svm import SVC\nimport numpy as vnp\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_classification\nimport matplotlib.pyplot as plt\n\nvnp.random.seed(1)\n\nX, y = make_classification(n_features=2, n_redundant=0, n_informative=1, n_clusters_per_class=1, n_samples=1024)\n\n# scaling the inputs is important since the embedding we use is periodic\nscaler = StandardScaler().fit(X)\nX_scaled = scaler.transform(X)\n\n# scaling the labels to -1, 1 is important for the SVM and the\n# definition of a hinge loss\ny_scaled = 2 * (y - 0.5)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, train_size=0.1)\n\n\n\nn_qubits = 10\ndev = qml.device(\"default.qubit\", wires=n_qubits)\nn_dim = len(X_train[0])\n\n@qml.qnode(dev, interface=\"jax\")\ndef kernel(x1, x2):\n    \"\"\"The quantum kernel.\"\"\"\n    #S(x=x1)\n    for i in range(n_qubits):\n        qml.Hadamard(wires=[i])\n        qml.RZ(x1[i%n_dim], wires=[i]) \n    \n    #S^dagger(x=x2)\n    for i in range(n_qubits-1,-1,-1):\n        qml.RZ(-1*x2[i%n_dim], wires=[i]) #S(x)\n        qml.Hadamard(wires=[i])\n    return qml.probs(wires=range(n_qubits))\n\nvectorized_kernel = jax.vmap(kernel)\njit_vectorized_kernel = jax.jit(vectorized_kernel)\n\n# batching\nresult_0 = []\nresult_1 = []\nfor i in range(np.shape(X_train)[0]):\n    for k in range(np.shape(X_train)[0]):\n        result_0.append(X_train[i,:])\n        result_1.append(X_train[k,:])\nx0_batch = np.array(result_0)\nx1_batch = np.array(result_1)\n\nprint(np.shape(X_train)[0],'x',np.shape(X_train)[0],'kernel_matrix','with', n_qubits,'qubits circuits')\n%time my_kernel_matrix = jit_vectorized_kernel(x0_batch,x1_batch).block_until_ready()\n\n102 x 102 kernel_matrix with 10 qubits circuits CPU times: user 4.47 s, sys: 1.14 s, total: 5.61 s Wall time: 2.13 s\n(4) qiskit_machine_learning\nfrom sklearn.svm import SVC\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_classification\nimport matplotlib.pyplot as plt\n\nX, y = make_classification(n_features=2, n_redundant=0, n_informative=1, n_clusters_per_class=1, n_samples=1024)\n\n# scaling the inputs is important since the embedding we use is periodic\nscaler = StandardScaler().fit(X)\nX_scaled = scaler.transform(X)\n\n# scaling the labels to -1, 1 is important for the SVM and the\n# definition of a hinge loss\ny_scaled = 2 * (y - 0.5)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, train_size=0.1)\n\n\n\nn_qubits = 10\nn_dim = len(X_train[0])\n\nfrom qiskit import BasicAer\nfrom qiskit.circuit.library import ZZFeatureMap, ZFeatureMap, PauliFeatureMap\nfrom qiskit.utils import QuantumInstance, algorithm_globals\nfrom qiskit_machine_learning.algorithms import QSVC\nfrom qiskit_machine_learning.kernels import QuantumKernel\n\nn_reps = 1\ninput_data_dimension = n_dim\nn_duplicate = int(n_qubits/input_data_dimension)\n_X_train = np.tile(X_train, n_duplicate)\n\n\nadhoc_feature_map = ZFeatureMap(feature_dimension=n_qubits, reps=1)\nseed = 12345\nadhoc_backend = QuantumInstance(BasicAer.get_backend('statevector_simulator'), shots=1, seed_simulator=seed, seed_transpiler=seed)\nadhoc_kernel = QuantumKernel(feature_map=adhoc_feature_map, quantum_instance=adhoc_backend)\nprint(np.shape(X_train)[0],'x',np.shape(X_train)[0],'kernel_matrix','with', n_qubits,'qubits circuits')\n%time adhoc_kernel.evaluate(_X_train,_X_train)\n\n102 x 102 kernel_matrix with 10 qubits circuits CPU times: user 672 ms, sys: 266 ms, total: 938 ms Wall time: 1.34 s\nI hope that these codes are helpful for pennylane lovers.", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/10"}, "10": {"author": "CatalinaAlbornoz", "date": "1643899098198", "content": "Hi @Kuma-quant, thank you very much for sharing your code!\nYour code may be helpful for other PennyLane lovers and it might also help us make lightning faster.\nThank you again and keep enjoying PennyLane!", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/11"}, "11": {"author": "Guillermo_Valverde", "date": "1701690904701", "content": "Hello all.\nI found this post very useful. However, in the case of using Qiskit Machine Learning I find that the QuantumInstance function is deprecated. It still works but you get the Deprecated Warning. I have tried using the migration indicated by Qiskit, from Quantum instance to Sampler(), however, the training time goes from 250 ms to 1 min 36s. I share my code with you below. Does anyone know how this time can be reduced and this migration done more optimally?\nThank you so much.\nfrom sklearn.svm import SVC\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_classification\nimport matplotlib.pyplot as plt\nfrom qiskit.circuit.library import ZZFeatureMap\nfrom qiskit.primitives import Sampler\nfrom qiskit_algorithms.state_fidelities import ComputeUncompute\nfrom qiskit_machine_learning.kernels import FidelityQuantumKernel\nfrom qiskit import BasicAer\nfrom qiskit.circuit.library import ZZFeatureMap, ZFeatureMap, PauliFeatureMap\nfrom qiskit.utils import QuantumInstance, algorithm_globals\nfrom qiskit_machine_learning.algorithms import QSVC\nfrom qiskit_machine_learning.kernels import QuantumKernel\nn_qubits = 4\nn_dim = len(X_train[0])\nn_reps = 1\ninput_data_dimension = n_dim\nn_duplicate = int(n_qubits/input_data_dimension)\n_X_train = np.tile(X_train, n_duplicate)\nadhoc_feature_map = ZZFeatureMap(feature_dimension=4, reps=2, entanglement=\u201clinear\u201d)\nsampler = Sampler()\nfidelity = ComputeUncompute(sampler=sampler)\nadhoc_kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=adhoc_feature_map)\nprint(np.shape(X_train)[0],\u2018x\u2019,np.shape(X_train)[0],\u2018kernel_matrix\u2019,\u2018with\u2019, n_qubits,\u2018qubits circuits\u2019)\n%time adhoc_kernel.evaluate(_X_train,_X_train)", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/12"}, "12": {"author": "isaacdevlugt", "date": "1701706849116", "content": "Hey @Guillermo_Valverde, this might be a good question for the Qiskit team . There\u2019s a handful of places listed on their support page: Getting help | IBM Quantum Documentation\nIf you\u2019re interested in migrating your code to PennyLane, we\u2019d be happy to help! Heads up as well that there are a lot of changes coming to Qiskit next year: https://medium.com/qiskit/coming-soon-qiskit-1-0-9dac8ae16da7 1.", "link": "https://discuss.pennylane.ai//t/parallelization-of-circuit-executions/1566/10/13"}}