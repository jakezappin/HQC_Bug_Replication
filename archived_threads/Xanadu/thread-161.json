{"0": {"author": "snuffkin", "date": "1595297805247", "content": "Hi!\nI resize the MNIST images to 16x16 and run a quantum circuit.\nIf I use AmplitudeEmbedding and set analytic=False, I get a numpy error.\nI assume this is a probability accuracy issue.\nmnist_20200721_numpy_error.txt (31.6 KB) \u2192 Please change the file extension to \u201cipynb\u201d.\nIs there a workaround?\nerror message:\nValueError: probabilities do not sum to 1\n", "link": "https://discuss.pennylane.ai//t/numpy-says-probabilities-do-not-sum-to-1/487/1"}, "1": {"author": "Maria_Schuld", "date": "1595321175342", "content": "Hey snuffkin!\nYou uncovered a very interesting bug there!\nWhat seems to happen is that the conversion from tf tensors to numpy arrays creates an ndarray of data type float32. I suspect that with this lower precision, the automatic normalisation of the AmplitudeEmbedding method creates a quantum state vector which does not pass the  checks of numpy\u2019s  np.random.choice (which is used for sampling measurement results in \"default.qubit\") for a probability distribution to be normalised.\nAs a fix, you\u2019d need to convert your array to float64:\nn_qubits = 8\ndev = qml.device(\"default.qubit\", wires=n_qubits, shots=10, analytic=False)\n\n# quantum circuit\n@qml.qnode(dev)\ndef circuit(features=None):\n    qml.templates.AmplitudeEmbedding(features, range(n_qubits), normalize=True)\n    return qml.expval(qml.PauliZ(0))\n\ncircuit(features=x_train[0].flatten().astype('float64'))\n\nInterestingly, at least for the latest PL version I tested this with, assigning the training data point to a new variable seems to do the conversion automatically.\nn_qubits = 8\ndev = qml.device(\"default.qubit\", wires=n_qubits, shots=10, analytic=False)\nx = x_train[0].flatten()\nprint(x.dtype) #  'float64'\n\n# quantum circuit\n@qml.qnode(dev)\ndef circuit(features=None):\n    qml.templates.AmplitudeEmbedding(features, range(n_qubits), normalize=True)\n    return qml.expval(qml.PauliZ(0))\n\ncircuit(features=x)\n\nHope this helps!2", "link": "https://discuss.pennylane.ai//t/numpy-says-probabilities-do-not-sum-to-1/487/2"}, "2": {"author": "snuffkin", "date": "1595336651753", "content": "Hi @Maria_Schuld,\nThanks for your response!\nWith your support, my program works.\nPennyLane is easy to use and fun to use.", "link": "https://discuss.pennylane.ai//t/numpy-says-probabilities-do-not-sum-to-1/487/3"}, "3": {"author": "snuffkin", "date": "1595297805247", "content": "Hi!\nI resize the MNIST images to 16x16 and run a quantum circuit.\nIf I use AmplitudeEmbedding and set analytic=False, I get a numpy error.\nI assume this is a probability accuracy issue.\nmnist_20200721_numpy_error.txt (31.6 KB) \u2192 Please change the file extension to \u201cipynb\u201d.\nIs there a workaround?\nerror message:\nValueError: probabilities do not sum to 1\n", "link": "https://discuss.pennylane.ai//t/numpy-says-probabilities-do-not-sum-to-1/487/4"}}