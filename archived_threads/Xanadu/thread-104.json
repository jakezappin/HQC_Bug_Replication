{"0": {"author": "James_Ellis", "date": "1583772587790", "content": "Hi @andreamari, I have some questions regarding the ImageNet dataset.\nHas the Hymenoptera dataset already been trained on the truncated network?  i.e is it unseen data for the entire network or just the dressed circuit?\nAlso, why is q_delta set to 0.01?\nThanks\nJames", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/1"}, "1": {"author": "andreamari", "date": "1583793179286", "content": "Hi @James_Ellis,\nthe truncated network (ResNet18) is pre-trained on the full ImageNet dataset. Hymenoptera is a very small subset of ImageNet.\nSo, ResNet18 has seen the Hymenoptera dataset a little bit. However it is not optimized on Hymenoptera  but on the full ImageNet .\nNote that this is not necessary and (classical or quantum) transfer learning can be applied also to a completely new dataset. You can find an example of this scenario in this notebook 8, where we replace the Hymenoptera dataset with CIFAR (which is unrelated to ImageNet).2 Replies", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/2"}, "2": {"author": "James_Ellis", "date": "1583794835467", "content": "Thanks for the reply! I appreciate the help.\nIs there any reason why q_delta = 0.01?\nThanks", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/3"}, "3": {"author": "andreamari", "date": "1583843822585", "content": "Sorry, I forgot to reply about this.\nNo, there isn\u2019t any particular reason for the choice of q_delta.\nThis can be considered as one of the hyper-parameters of the model.\nThe only thing that one can say is that it shouldn\u2019t be be too small (risk of making the initial gradient null) and it shouldn\u2019t be too large (risk of numerical instability of the optimization algorithm).", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/4"}, "4": {"author": "James_Ellis", "date": "1584792147892", "content": "What is the purpose of apply Hadamard gates to each wire before embedding data? What would happen if we didn\u2019t take this approach.\nThanks for your help!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/5"}, "5": {"author": "andreamari", "date": "1584828332396", "content": "Hi @James_Ellis,\nsince in our model we measure in the Z basis, the purpose of the Hadamard gates is to initialize all the qubits in a state which is not biased towards Z=+1 or Z=-1.  Indeed the effect of H is to prepare the |+> state, for which the expectation value of Z is zero.\nWhat would happen if we remove the first layer of H gates? Probably the final result would be similar but maybe the training time would be longer because of the different initial condition. This is just a guess, but the best way to know is to try and see how it goes.2", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/6"}, "6": {"author": "_risto", "date": "1594884511720", "content": "Dear andreamari.\nThank you for your explanations. How can I use/upload my own image dataset instead of Hymenoptera? In what format do they need to be?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/7"}, "7": {"author": "andreamari", "date": "1594888823835", "content": "Hello @_risto,\nin this example we used PyTorch to load the dataset.\nSo if you want to use a different dataset you can have a look\nat the PyTorch documentation of torchvision.datasetslink. In particular, in our example we used the  torchvision.datasets.ImageFolder data loader link. In this case the dataset is loaded from a folder which contains images organized in subfolders associated to the different classes. For example, the Hymenoptera folder has this structure.2 Replies1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/8"}, "8": {"author": "_risto", "date": "1594901895793", "content": "Thank you for the prompt answer andreamari. Does this apply for loading a custom dataset for the following algorithm as well: https://pennylane.ai/qml/demos/tutorial_embeddings_metric_learning.html 3 ?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/9"}, "9": {"author": "nathan", "date": "1594922317052", "content": "Hi @_risto,\nThe embeddings and metric learning demo uses the Numpy interface instead of PyTorch, so data is loaded there using the function numpy.loadtxt() (you can see this in the \u201cData\u201d subsection).\nHowever, one could also implement that example fully using PyTorch. In that case, you could use PyTorch\u2019s built-in data loaders, as @andreamari describes above.1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/10"}, "10": {"author": "_risto", "date": "1595418924851", "content": "Hello andreamari.\nIs it possible to run this algorithm with 3d pictures / 3d object recontruction dataset?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/11"}, "11": {"author": "andreamari", "date": "1595427432149", "content": "Hi @_risto,\nin principle, it is possible to apply the quantum transfer learning trick to any classical problem. One has to find a good classical network which is good for the task of interest (or a similar generic task): e.g. 3D object reconstruction, 3D image classification, etc. Then one must replace some of the final layers of the classical network with a variational quantum circuit which can be trained for the specific task of interest.1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/12"}, "12": {"author": "_risto", "date": "1595850569756", "content": "Hi andreamari.\nWhat would be the minimum amount of data needed to train this network (let\u2019s say I am using either a ResNet18, ResNet50 or resNet151 network)? I have 159 cases, for each case 3 different modality of picture, which I was planning to divide roughly in - training : validation : testing = 7 : 2 : 1 ratio.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/13"}, "13": {"author": "andreamari", "date": "1595945910889", "content": "Hi @_risto,\ntransfer learning requires training only the final weights of the full network and so it is particularly convenient when the dataset is small. In your case the dataset very small  but it may still work. If data is not enough you may try reducing the complexity of the quantum layer, e.g., by using less qubits or less variational layers.1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/14"}, "14": {"author": "_risto", "date": "1596575645622", "content": "Hi again.\nWhile trying to run the code in the 1st paragraph of Dataset loading, I get the following error:\nNameError                                 Traceback (most recent call last)\n in \n1 data_transforms = {\n----> 2     \u201ctrain\u201d: transforms.Compose([\n3             # transforms.RandomResizedCrop(224),     # uncomment for data augmentation\n4             # transforms.RandomHorizontalFlip(),     # uncomment for data augmentation\n5             transforms.Resize(256),\nNameError: name \u2018transforms\u2019 is not defined\nI\u2019ve followed all the previous steps. I wanted to recreate the same experiment, just to see, how it goes.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/15"}, "15": {"author": "andreamari", "date": "1596614280163", "content": "Hi @_risto,\ndid you run the previous code blocks too?\nIt looks like the line from torchvision import datasets, transforms was not executed.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/16"}, "16": {"author": "_risto", "date": "1596745034402", "content": "Hi andreamari.\nYes, I did and have installed torchvision before, although I\u2019ve done it in jupyter notebook. Should I use some other program, like pycharm to run the whole code?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/17"}, "17": {"author": "andreamari", "date": "1596789318795", "content": "Hi @_risto,\nit should work both with a jupyter notebook and with a standard Python script.  I would suggest you to open a Python shell (or a Jupyter notebook ) and execute, one by one, the following 2 instructions (in a Jupyter notebook you can write them in 2 separate cells):\n\nfrom torchvision import transforms\nt = transforms\n\nDo you get any error?\nIf you get an error, there is a problem with the installation of torch or torchvision.\nOtherwise, you can try to execute each line of code from the tutorial, one by one, to see if and where you get the first error.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/18"}, "18": {"author": "_risto", "date": "1596884477757", "content": "Hey andremari.\nNo error. I did go step by step. Now I got\" NameError: name \u2018datasets\u2019 is not defined\", repeated what you have written but changed transforms to datasets, run the code again, get \u201cNameError: name \u2018os\u2019 is not defined\u201d. I went step by step. Is the whole code really 100% fully written on the page?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/19"}, "19": {"author": "andreamari", "date": "1596917085593", "content": "Hi @_risto,\nI am quite sure that this tutorial 2 is complete (no code missing).\nThe errors that you mention seem to be related to the non-execution of one or more import instructions. But if you are sure that this is not the case, I don\u2019t know how to help.\nOne last suggestion that just came to my mind is that you could try to download this Python script  which is equivalent the tutorial (actually the html page of the tutorial is automatically generated from this file).\nAfter downloading the script, you can try to execute it by running on a  terminal:\npython tutorial_quantum_transfer_learning.py.\nDepending on how Python was installed in your computer, you may need to use the command python3 instead of python.1 Reply1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/20"}, "20": {"author": "_risto", "date": "1597008175964", "content": "Dear andremari.\nWhen unzipping the hymenoptera.zip, does this subfolder has to be on my laptop, or somewhere else? I have extracted into the subfolder, but my on my laptop, all subfolder are divided by \u201c\u201d, not \u201c/\u201d like it says in the code. Is this Mac & Linux specific? I presume this is the reason I get FileNotFoundError: [WinError 3] The system cannot find the path specified: \u2018\u2026/_data/hymenoptera_data\\train\u2019", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/21"}, "21": {"author": "antalszava", "date": "1597071373110", "content": "Hi @_risto,\nThank you for your interest in the tutorial!\nCould you check if your folder structure matches the following:\n.\n\u2502\u2500\u2500 tutorials\n\u2502   \u251c\u2500\u2500 _data\n\u2502   \u251c\u2500\u2500 \u251c\u2500\u2500 hymenoptera_data\n\u2502   \u251c\u2500\u2500 quantum_transfer_learning\n\u2502   \u251c\u2500\u2500 \u251c\u2500\u2500 tutorial_quantum_transfer_learning.ipynb\nLet\u2019s assume that we have a general (arbitrarily named) tutorials folder. This folder could then contain a subfolder  quantum_transfer_learning with the tutorial_quantum_transfer_learning.ipynb file in it. The important thing would be to place the _data folder that we obtain after extraction into the general tutorials folder (on the same level as quantum_transfer_learning).\nWas able to reproduce your error when my folder structure did not look as above. Tried it on a Windows machine, os.path.join is used for creating the path and helping with platform-independence.\nLet us know how it goes!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/22"}, "22": {"author": "_risto", "date": "1597133205209", "content": "Hi antalszava\nYes, it matches. I still get : FileNotFoundError: [WinError 3] The system cannot find the path specified: \u2018\u2026/_data/hymenoptera_data\\train\u2019\nAfter extraction, I don\u2019t get the \u201c_data\u201d file, but \u201chymenoptera_data\u201d. I have created the \u201c_data\u201d folder and have put the \u201chymenoptera_data\u201d file inside it, according to the folder structure.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/23"}, "23": {"author": "antalszava", "date": "1597171055957", "content": "Hi @_risto,\nThanks for the follow-up!\nThe problem would, in that case, be related to in which directory the jupyter notebook command was issued. That directory will be used when the path is being constructed (as the path is relative), hence could lead to the error that you are experiencing.\nThere could be two solutions to this:\n\nexecuting the jupyter notebook command in the quantum_transfer_learning folder\nspecifying the absolute path to your data folder by changing the data_dir = \"../_data/hymenoptera_data\" line to: data_dir = os.path.abspath(r\"C:\\MyPath\\pl_tutorials\\_data\\hymenoptera_data\") where MyPath will be unique to your system.\n\nLet me know how it goes and if you have further questions!1 Reply", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/24"}, "24": {"author": "_risto", "date": "1597220398725", "content": "Hi antalszava.\nThank you for your answer.\n1.) Have tried that, but it doesn\u2019t work, as recent Anaconda installers have this box unchecked by default. I have tried to fix this using multiple solutions on stackoverflow, none of them worked.\n2.) Where do I even write this?\nI have tried other methods \u201crun a jupyter notebook in a folder\u201d from the web, none worked. When I tried this answer: https://stackoverflow.com/questions/35254852/how-to-change-the-jupyter-start-up-folder#40514875 2 , my laptop doesn\u2019t even have a \u201cC:\\Users\\username.jupyter\\jupyter_notebook_config.py\u201d file.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/25"}, "25": {"author": "antalszava", "date": "1597246979834", "content": "Hi @_risto,\nFor 2., it would be this line in the Python script 3. Once you have a local copy of the script, you can modify this line and try running the script.\nShould you have a notebook, you could modify this line there too.\nHope this helps!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/26"}, "26": {"author": "_risto", "date": "1597323624901", "content": "Hi antalszava.\nThank you for suggestions.\nI have managed to open/run file in jupyter notebook, but still get the same error. I have tried the second suggested method, but then get \u201cFileNotFoundError: [WinError 3] The system cannot find the path specified: \u2018C:\\MyPath\\pl_tutorials\\_data\\hymenoptera_data\\train\u2019\u201d.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/27"}, "27": {"author": "antalszava", "date": "1597328167720", "content": "Hi @_risto,\nThat\u2019s great to hear! \nJust to double-check: I notice that MyPath is still contained in the error message. In my previous comment MyPath was meant to serve as a placeholder inside of the string for the path. You\u2019ll have to use the absolute path of the hymenoptera_data folder on your system.\nWere you using a valid absolute path when receiving this error?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/28"}, "28": {"author": "_risto", "date": "1597397826527", "content": "Hi antalszava.\nIt worked,  ,  I got up to step \u201cmodel_hybrid = train_model(\nmodel_hybrid, criterion, optimizer_hybrid, exp_lr_scheduler, num_epochs=num_epochs\u201d when I get \u201cSyntaxError: unexpected EOF while parsing\u201d.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/29"}, "29": {"author": "antalszava", "date": "1597418376492", "content": "Hi @_risto,\nThat is really great news! \nOh I see! Could you make sure that you have the following in that step:\n  model_hybrid = train_model(\n    model_hybrid, criterion, optimizer_hybrid, exp_lr_scheduler, num_epochs=num_epochs\n)\n\nFrom your error message I\u2019d suspect that there is a ) character missing (and this would also explain the SyntaxError that you are getting).\nLet me know how it is!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/30"}, "30": {"author": "_risto", "date": "1597525703100", "content": "Hi antalszava.\nIt worked, thank you for help! I went s step further and test it with dataset of brain tumors, but after 20 ephos I\u2019ve noticed the val_loss increasing. I assume it is due to ResNet network, that is pre-trained  to non-brain-tumor dataset, although as I understand, this particular ResNet18 is trained from the whole ImageNet and should work on a new data. Why is it overfitting brain-tumor dataset?\nHow could I compare same ResNet with same data with classical ResNet : ResNet & quantum layer?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/31"}, "31": {"author": "antalszava", "date": "1597680269872", "content": "Hi @_risto,\nThat\u2019s great, happy that it worked out!\nIt\u2019s an interesting question! It is worth noting that questions of overfitting and generalisation are still unresolved in QML research. Therefore it would be difficult to say what exactly is amiss without delving more into your research problem. Could you perhaps elaborate further on how the comparison would be done between using ResNet with classical and quantum layers?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/32"}, "32": {"author": "_risto", "date": "1597749279506", "content": "Hi @antalszava\nI would like to compare classical network used as a base in this tutorial (ResNet) with one, where last layer is replaced with quantum circuit and another, where last layer is replaced by quantum embedding and metric learning in classifying different images (specific tumors, by types, grades and even by deletions of gene). Is that possible based on code provided in the tutorials? How do I test networks in % of accurately classified pictures or is this same as validation? How do I do test/valid in quantum embedding tutorial?\nIn addition, I looked at the other 3 classifier tutorials (who are based on iris dataset), but I presume coding only 4 features would not be enough to analyse more complex data?\nCheers,", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/33"}, "33": {"author": "antalszava", "date": "1597763971613", "content": "Hi @_risto,\nYes, this should all be possible with slight modifications of the demo. If you use the NumPy interface, you can just write your own function to measure the accuracy. Many examples can be found in ML tutorials as well (e.g. Image classification 1 or Training a Classifier 1). Hope this helps!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/34"}, "34": {"author": "_risto", "date": "1597843250963", "content": "Hi @antalszava\nThanky for the help.\nMay I ask, the iris dataset (3 classes) in other tutorials is preprocessed into this: https://raw.githubusercontent.com/XanaduAI/qml/master/demonstrations/variational_classifier/data/iris_classes1and2_scaled.txt 2 - how can I process any picture into this format?\nIn addition, it keeps happening, that subfolder with data is not found. I have tried to modified the code you have me for this particular tutorial, didn\u2019t work. Is there any general code / setup, which I can modify and replace it in the original tutorial code?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/35"}, "35": {"author": "antalszava", "date": "1597888480204", "content": "Hi @_risto,\nGenerally, for the rescaling of the data, tools like https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html could be used.\nThis can be useful so that\n\nData can be rescaled to have zero mean and a variance of 1\nFor images, one may want to do some convolutional layers first and then flatten before passing to a QNode\n\n\n\nSpecifying the path for the data\nOne could use the appdirs library 1  to specify the path to a file in a platform-independent way(should be installed by default, alternatively can be installed for example using pip: pip install appdirs).\nUsing the user_data_dir function from the appdirs library, we can point to pre-defined folders on each operating system. For a Unix based system, for example, this folder is going to be the /home/user/.local/share/ folder.\nOn my Unix based system locally, I executed the following commands in a shell terminal:\nmkdir /home/antal/.local/share/data\nmv iris.csv /home/antal/.local/share/data/\n\nFirst I\u2019ve created a data folder in /home/antal/.local/share/ and then moved the file for the Iris dataset (iris.csv) to this folder. This second step assumes that iris.csv is located in the directory where the commands were executed.\nAfter these changes, I could add in the following modifications to the tutorial at the related parts:\n# Additional imports required\nfrom appdirs import user_data_dir\nimport os\n\n# Querying the directory where data will be placed\n# For example `/home/antal/.local/share/data` on a Unix based system\ndirectory = user_data_dir(\"data\")\n\ndef load_and_process_data():\n\n    # Loading the data file\n    # os.path.join(directory, \"iris.csv\") will output\n    # for example `/home/antal/.local/share/data/iris.csv` on a Unix based system\n    data = np.loadtxt(os.path.join(directory, \"iris.csv\"), delimiter=\",\")\n\nThis is a potentially more general way of placing user data.\nHaving said that, the previously suggested approach of explicitly passing the absolute path of the data as a string should also work well (for this tutorial this should be passed as the first argument to the np.loadtxt function).2", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/36"}, "36": {"author": "antalszava", "date": "1597929346328", "content": "Another note on how the data file linked was created specifically (thanks to @Maria_Schuld for checking this!).\nAfter loading the very original data from the iris dataset, the first two features and the first two classes of flowers are extracted. After that, all features are shifted to the positive subspace (by subtracting the smallest example of a feature across the data) and are multiplied by 1/2.\nThe 1/2 multiplier is not of too much importance here, since the data lies safely within the period of [0,2pi], which is important because of the periodicity of a Pauli rotation.\nIn code:\ndata_original_feat1and2 = 0.5*(data_original_feat1and2 - np.min(data_original_feat1and2, axis=0)) \n\nHope this helps!1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/37"}, "37": {"author": "_risto", "date": "1598111857931", "content": "Hi @antalszava.\nThank you for the explanations. While running the quantum embedding tutorial, the following link is not valid anymore: https://github.com/PennyLaneAI/qml/blob/master/implementations/embedding_metric_learning/X_antbees.txt 1 .", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/38"}, "38": {"author": "antalszava", "date": "1598226542240", "content": "Hi @_risto,\nThank you for catching that! The file is now located at this address 5.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/39"}, "39": {"author": "_risto", "date": "1598311758777", "content": "Hi @antalszava\nJust to double-check. Again, if I want to take any image dataset, and make pre-extracted feature vectors of the images (like in the last link), do I need to use once already mentioned method: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html ? Or something else?1 Reply", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/40"}, "40": {"author": "antalszava", "date": "1598367274014", "content": "Hi @_risto,\nAs a general approach, that could be done indeed.\nWhen dealing with image datasets, as was hinted previously, feeding the input data into a convolutional neural network (CNN) is also very popular for image classification. Several architectures use convolutional networks (including ResNet).\nFor example in the Training a classifier 2 tutorial includes the creation of a CNN which is then put as a layer before calculating the loss in each step.1 Reply2", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/41"}, "41": {"author": "Qudsiaamir", "date": "1598453607394", "content": "Hi,\nI am trying out the  same approach of changing the last layer to a Quantum layer in NSPnet pretrained model which I got it from gluoncv in which the layers are defined using mxnet. As mxnet is not added to the interface list of Pennylane how to move forward?\nfor your reference I have added the models with respective changes. 41 Reply", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/42"}, "42": {"author": "_risto", "date": "1598456036452", "content": "Hi @antalszava\nThank you for explanation regarding CNN. I understand in theory what has to be done, but am having hard time writing the code. Is there a code written in once place, which was used to get this: https://raw.githubusercontent.com/PennyLaneAI/qml/master/demonstrations/embedding_metric_learning/X_antbees.txt 3 data?  Does simply removing the last layer of ResNet512 (or any other ResNet) give you the needed features vectors, or is there an additional modifications that need to be done?1 Reply", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/43"}, "43": {"author": "antalszava", "date": "1598471664507", "content": "Hi @Qudsiaamir,\nWelcome to the forum! \nThat\u2019s an interesting approach. Indeed, mxnet is not a supported interface by PennyLane at the moment. For differentiability purposes the QNode that gets created internally is specifically tailored to the framework that is being used (in this case that would be mxnet). This is needed so that trainable parameters are registered inside of PennyLane.\nCould perhaps the layers defined in mxnet be ported to TensorFlow using Keras or to Torch? Having interfaces and quantum layers for those frameworks (KerasLayer and TorchLayer), PennyLane could be used to define a quantum layer seamlessly.\nAnother, more experimental approach would be creating  a function that changes a QNode to be compatible with mxnet (see the Torch equivalent here 1). Although a bit more advanced, this would be a fun way of integrating PennyLane with mxnet and could even result in a new interface! \nIn either case, feel free to share more details on the specific task you\u2019re looking at (e.g. code snippets) and feel free to ask questions that might come up!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/44"}, "44": {"author": "antalszava", "date": "1598536736202", "content": "Hi @_risto,\nWe\u2019ve uploaded the specific script that was being used 3, this is similar method as the one used in transfer learning. Credits to @andreamari!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/45"}, "45": {"author": "_risto", "date": "1599576605402", "content": "Hi @antalszava.\nAfter running the code, I get TypeError: \u2018dict\u2019 object is not callable.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/46"}, "46": {"author": "theodor", "date": "1599601988571", "content": "Hi @_risto,\nThere was an issue with the script that has been fixed now. Just download the latest version of the script 1 and it should hopefully work fine. \nIf you have any other issues, feel free to message us here again!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/47"}, "47": {"author": "_risto", "date": "1599642529265", "content": "Hi @theodor\nThank you for the updated code. So, after getting the feature vectors, I have stored them in a specific subfolder (4 different subfolder for each txt file), as I will have to put my specific path in the code. When I try to run the code:\nX = np.loadtxt(\"embedding_metric_learning/X_antbees.txt\", ndmin=2)  #1  pre-extracted inputs\nY = np.loadtxt(\"embedding_metric_learning/Y_antbees.txt\")  # labels\nX_val = np.loadtxt(\n    \"embedding_metric_learning/X_antbees_test.txt\", ndmin=2\n)  # pre-extracted validation inputs\nY_val = np.loadtxt(\"embedding_metric_learning/Y_antbees_test.txt\")  # validation labels\n\n# split data into two classes\nA = X[Y == -1]\nB = X[Y == 1]\nA_val = X_val[Y_val == -1]\nB_val = X_val[Y_val == 1]\n\nprint(A.shape)\nprint(B.shape)\n\nwhere I have changed the loading txt data with my specific path, I get that permission to that folder is denied. I have tried to run jupyter as an admin, also run jupyter in conda as an admin, but it did not solve the problem.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/48"}, "48": {"author": "theodor", "date": "1599663412829", "content": "Hi @_risto. That seems to be an issue with your local folder permissions. I would recommend that you move the files into a folder where you have read/write permissions (e.g. your local Documents folder, depending on OS/distro). You could also look at how to change permissions for that specific folder.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/49"}, "49": {"author": "_risto", "date": "1599995708600", "content": "Hi @theodor\nAfter extracting the feature vectors from hymenoptera_data, the number of lines in antbees.txt file that I get doesn\u2019t match the number 153 (as it does in the antbees.txt file on github page).", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/50"}, "50": {"author": "josh", "date": "1600150576730", "content": "Hi @_risto, thanks for pointing this out \u2014 it turns out there was a bug in the script, that has now been corrected 3. Have a go using the updated script, and let us know if it works!2", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/51"}, "51": {"author": "_risto", "date": "1600175081257", "content": "Hi @josh\nThanks for the reply. Now I get 5 files (X_antbees_test.txt (1.9 MB) Y_antbees.txt (6.3 KB) Y_antbees_test.txt (4.0 KB) Y_antbees_train.txt (6.3 KB)  and X_antbees.txt, which was not uploaded, as it is empty) and error:\n\u201cboolean index did not match indexed array along dimension 0; dimension is 0 but corresponding boolean dimension is 244\u201d.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/52"}, "52": {"author": "sjahangiri", "date": "1600201279151", "content": "Hi @_risto.\nThe fifth file you are getting, Y_antbees_train.txt, is generated by the old script. Please note the the new script generates the following files:\n\n\nX_antbees.txt containing X_train\n\n\nY_antbees.txt containing Y_train\n\n\nX_antbees_test.txt containing X_val\n\n\nY_antbees_test.txt containing Y_val\n\n\nPlease also note that, in the new script, Y_train is computed using the train_data as:\nY_train = [1 if inp[1] == 0 else -1 for inp in train_data] which gives you the correct number of data points. The file Y_antbees.txt in the github folder is also updated with the new data.\nCould you please do the following steps and let us know about the results?\n\n\nCreate a new folder.\n\n\nDownload the hymenoptera_data  into your new folder.\n\n\nRun the new script image_to_resnet_output.py, downloaded from here, in your new folder.\n\n\nYou can run the new script either by copying its content to a new notebook or using python image_to_resnet_output.py  in a terminal. Please make sure that you run the script in the same folder that you have your hymenoptera_data. Then you will get 4 files: X_antbees.txt and Y_antbees.txt with 245 lines; X_antbees_test.txt and Y_antbees_test.txt with 153 lines.\nPlease let us know if you have any questions. Thanks.1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/53"}, "53": {"author": "_risto", "date": "1600244451431", "content": "Hi @sjahangiri.\nAfter the recommended changes I get\n(121, 512)\n(122, 512)\ninstead of\n(83, 512)\n(70, 512)\nConsequently the gram matrix does not separates the two clases:\n", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/54"}, "54": {"author": "Maria_Schuld", "date": "1600345317736", "content": "Hey _risto,\nLet me take over from @sjahangiri, since the bug is my fault \nYou are totally right, somehow the validation set is perfectly learnt by the pre-trained parameters, but not the training set  Very strange, and smells like a silly mistake somewhere. I will try to find it!1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/55"}, "55": {"author": "Maria_Schuld", "date": "1600434237899", "content": "Update: I just cannot find why the model works so well on the (new version of the) test data but not the training data. That is so odd, even if we accidentally trained on the test data before.\nI will have to retrain, which can take a day or two\u20264", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/56"}, "56": {"author": "Maria_Schuld", "date": "1600713123612", "content": "And another update: The bug with the data preparation uncovered a problem that will require a bit of research to fix.\nI took the demo off the webpage 4 in the meantime to avoid people running incorrect code. Will post here once this is fixed.3", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/57"}, "57": {"author": "_risto", "date": "1601214796632", "content": "In the meantime, may I ask, would it be possible to provide the code for the exactly the same ResNet18, which was used in Quantum Transfer & Embeddings learning algorithm, before the last layer was removed and replaced by the quantum circuit? (so one can compare the two - original : quantum)?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/58"}, "58": {"author": "Tom_Bromley", "date": "1601391429984", "content": "Hi @_risto,\nI\u2019m joining this thread a bit late, so apologies if repeating something you\u2019ve already discussed.\nHave you checked out the quantum transfer learning 2 repo? This is a great place to start if you want to dig deeper. I believe a relevant line in the tutorial 1 would be:\nmodel_hybrid = torchvision.models.resnet18(pretrained=True)\n\nSince the model is not quantum, you can also check out the Torch documentation.1", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/59"}, "59": {"author": "_risto", "date": "1604404730399", "content": "Hello. Just dropping by to ask, how the quantum embeddings demo is going on?\nCheers,\nRisto", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/60"}, "60": {"author": "antalszava", "date": "1604418070258", "content": "Hi @_risto,\nWe are looking into resolving the issues in the demo. Depending on the specific solution needed, this could take some time but will get back as soon as it\u2019s working. ", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/61"}, "61": {"author": "_risto", "date": "1605526252075", "content": "Hi @antalszava\nThanks for the update  Hopefully comes soon, eager to try the experiment. As I remember it was intent to use it as a last layer of ResNet18?\nCheers,\nRisto", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/62"}, "62": {"author": "glassnotes", "date": "1605549647621", "content": "Hi @_risto,  yes you\u2019re correct, the idea was to use this in ResNet18. The team is still working on resolving the issues in the demo, and we will let everyone here know when it\u2019s up and running!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/63"}, "63": {"author": "_risto", "date": "1606391674231", "content": "Hi. How does one find an address of a direct path in Linux?\nCheers,\nRisto", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/64"}, "64": {"author": "josh", "date": "1606394063189", "content": "Hi @_risto! Could you provide a few more details?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/65"}, "65": {"author": "_risto", "date": "1606395140264", "content": "Hi @josh.\nSure. In previous steps we have specified our path to data as following: changing  data_dir = \"../_data/hymenoptera_data\"  line to:  data_dir = os.path.abspath(r\"C:\\MyPath\\pl_tutorials\\_data\\hymenoptera_data\")  where  MyPath  will be unique to our system.\nWhere in Linux can I find this direct link / address of the folder \u201cr\"C:\\MyPath\\pl_tutorials_data\\hymenoptera_data\u201d\" in order to copy paste it into the code?\nCheers,\nRisto", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/66"}, "66": {"author": "josh", "date": "1606395828699", "content": "Ah, got it \nIf you navigate in a terminal to the directory with the data, you can run the command pwd. This will give you the location of the directory.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/67"}, "67": {"author": "_risto", "date": "1608384863467", "content": "Hi again \nHow could I put this quantum layer in various ResNet networks? (50, 101,\u2026)? Is it possible or is it structures only to work on ResNet18?\nBest,\nRisto", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/68"}, "68": {"author": "nathan", "date": "1608570093292", "content": "Hi @_risto,\nThanks for the question. As this post thread is now getting very long, would you be able to make a standalone post with your new question? This will help users find targeted questions & answers a bit easier. \nThanks!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/69"}, "69": {"author": "mahesh", "date": "1619121918837", "content": "Hi!, in the embedding layer what is the necessity of RY gates after Hadamard gates?\nAnd also what is the significance of using (pi/2) as a constant scaling factor, I understand that it is used for converting to quantum data but why (pi/2) in particular?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/70"}, "70": {"author": "andreamari", "date": "1619168128984", "content": "Hi @mahesh,\nthe RY(x_j) gates are used to apply a quantum operation which depends on the input classical parameters x_j. As you said this can be used to convert classical data to quantum data: x_j --> |quantumstate(x_j) > .\nThe choice of the gate is quite arbitrary and other methods can be used: https://pennylane.readthedocs.io/en/stable/introduction/templates.htm\nThe choice of the pi/2 scaling is quite arbitrary too. The motivation was that a \u201ctypical\u201d domain for classical data is often within [-1, 1], while a more natural domain for quantum rotation angles is  [-pi/2, pi/2].3", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/71"}, "71": {"author": "Harshit_Mogalapalli", "date": "1619176668356", "content": "Hi !! , How is it beneficial to run on IBM\u2019s real quantum device than Pennylane noiseless simulators? Ultimately only the final weights matter. Pennylane Simulators generate a model with better accuracy, so the generated weights can perform the classification.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/72"}, "72": {"author": "glassnotes", "date": "1619180006711", "content": "Hi @Harshit_Mogalapalli,\nThanks for your question! Due to subject and the length of the existing thread, could you please make a new thread for your question and add a bit of context? This will help others with similar questions find the information more easily.\nThanks!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/73"}, "73": {"author": "Jonathan_Kim1", "date": "1656501506301", "content": "I don\u2019t suppose there\u2019s been any updates on the quantum embedding & metric learning demo code? I\u2019ve had a quite a thorough look through it myself (both the data prep code and the embedding code) and tried retraining the paramaters for quite a high number of steps (1,500 and 10,000, where the latter shows no improvement over the former) but I can\u2019t see anything obvious that\u2019s wrong and I\u2019m having no luck with classification (I\u2019m seeing no decrease in cost function, nor a subsequent increase in the ability to classify).\nWhen I do use the original pretrained parameters and the initial ants/bees txt files provided in earlier versions of the repo, the code does of course classify. However, in the initial provided txt files, the contents of the training and test data files are identical (which I\u2019m sure shouldn\u2019t be the case), and is of course the reason why the test data is classified well but the training data is not, when using the most recent versions of the provided ant/bee txt files.\nI just can\u2019t seem to replicate the code\u2019s ability to classify when using a freshly generated, \u2018correct\u2019 set of ant/bee txt files (from image_to_resnet_output.py). This is the case both when I\u2019m using newly trained parameters, but also with the provided pretrained ones.\nI do think the problem may lie in the paramater training steps (the loop that uses the RMSPropOptimizer), however.\nThe reason is that even when I use the old ant/bee txt files (where the training/test files are identical) and run the training loop for 1500 steps, the program is still unable classify neither the training data, nor the test data (the training and test costs each still remain above 0.95). It feels as though the parameter training code provided in the demo must vary in some way from the original parameter training code used (which I of course do not have access to, if it does indeed vary) to generate the pretrained parameters.\nOne more thing to note is that I do get the following warning message when running the embedding code, although I\u2019m not sure how important it is:\nUserWarning: Attempted to differentiate a function with no trainable parameters. If this is unintended, please add trainable parameters via the \u2018requires_grad\u2019 attribute or \u2018argnum\u2019 keyword.\nI can try playing around with the parameter training/optimizing code a bit and I could try debugging the warning message but other than that I feel like I\u2019ve about exhausted the things I can try to get it to work.\nWould be great to hear an update or to get some thoughts on the problem! \nThanks,\nJonathan", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/74"}, "74": {"author": "CatalinaAlbornoz", "date": "1656545500407", "content": "Hi @Jonathan_Kim1, welcome to the forum!\nThank you for asking this question here. There have been some strange behaviours regarding that demo as you can see here 1.\nWe will take a deeper look into the warning you\u2019re getting and the specific details of the issue you\u2019re facing. We will be back with an answer soon.\nThank you for bringing this to our attention!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/75"}, "75": {"author": "Jonathan_Kim1", "date": "1656583503826", "content": "Hi @CatalinaAlbornoz,\nThanks for the reply.\nJust thought it would be worth mentioning, the specific demo I am looking into is actually the embeddings & metric learnings one (which was actually removed from the repo around two years ago due to the problems in question), as opposed to the transfer learning one - Maria Schuld and _risto were discussing the problem in this thread back in September 2020 (even though this thread was originally about the transfer learning demo, not the embeddings & metric learning demo).\nIt is interesting however, that from the link you sent, there seems to be a better test performance than training performance within the transfer learning demo too. This is also observed within the embedding & metric learning demo, if one uses the correct (freshly generated) ant/bee txt files alongside the pretrained parameters provided by the demo. But in this case, it\u2019s more that the training set is not classified at all, while the test set is classified perfectly. When the parameters are generated from scratch by using the code in the demo (instead of using the pretrained parameters), nothing classifies properly at all, however (neither training set nor test set).\nThanks,\nJonathan", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/76"}, "76": {"author": "andreamari", "date": "1656593697592", "content": "Hi @Jonathan_Kim1,\nAbout the issue of validation vs training loss, I just left a possible explanation at this link 2.\nI don\u2019t know instead the answer to your further questions.\nBest wishes,\nAndrea", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/77"}, "77": {"author": "CatalinaAlbornoz", "date": "1656635250104", "content": "Hi @Jonathan_Kim1,\nThank you for the clarification!\nAs far as I know there haven\u2019t been any updates to the quantum embedding & metric learning demo code (which was removed a few years ago).\nThank you @andreamari for the explanation here!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/78"}, "78": {"author": "Jonathan_Kim1", "date": "1657019126363", "content": "Having looked into the problem further I\u2019m pretty certain that the issue is associated with the aforementioned UserWarning: Attempted to differentiate a function with no trainable parameters. If this is unintended, please add trainable parameters via the \u2018requires_grad\u2019 attribute or \u2018argnum\u2019 keyword. error. The parameters are not changing at all between each iteration step. The associated part of the code is as below:\n# generate initial parameters for circuit\ninit_pars_quantum = np.random.normal(loc=0, scale=0.1, size=(4, 3))\n\n# generate initial parameters for linear layer\ninit_pars_classical = np.random.normal(loc=0, scale=0.1, size=(2, 512))\n\ninit_pars = [init_pars_classical, init_pars_quantum]\n\n\noptimizer = qml.RMSPropOptimizer(stepsize=0.01)\nbatch_size = 5\npars = init_pars\nselectA = np.random.choice(range(len(A)), size=(batch_size,), replace=True)\nselectB = np.random.choice(range(len(B)), size=(batch_size,), replace=True)\nA_batch = [A[s] for s in selectA]\nB_batch = [B[s] for s in selectB]\n\n\nfor i in range(100):\n\n    # Sample a batch of training inputs from each class\n    selectA = np.random.choice(range(len(A)), size=(batch_size,), replace=True)\n    selectB = np.random.choice(range(len(B)), size=(batch_size,), replace=True)\n    A_batch = [A[s] for s in selectA]\n    B_batch = [B[s] for s in selectB]\n    print(selectA)\n    print(selectB)\n    print(A_batch[0][0])\n    print(B_batch[0][0])\n\n    # Walk one optimization step\n    pars = optimizer.step(lambda w: cost(w, A=A_batch, B=B_batch), pars)\n    print(pars)\n    print(\"Step\", i, \"done.\")\n\n    # Print the validation cost every 5 steps\n    if i % 5 == 0 and i != 0:\n        cst = cost(pars, A=A_val[:20], B=B_val[:20])\n        print(\"Cost on validation set {:2f}\".format(cst))\n\nSpecifically, the line causing the warning message is:\npars = optimizer.step(lambda w: cost(w, A=A_batch, B=B_batch), pars)\n\nThe warning message is mentioned within here 1, but I\u2019m not really sure how to approach  it.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/79"}, "79": {"author": "CatalinaAlbornoz", "date": "1657059803649", "content": "Hi @Jonathan_Kim1,\nWhat this warning means is that pars is never set as trainable. You could try defining pars = np.array(init_pars,requires_grad=True), although I\u2019m not sure if this will fix all of your problems.\nPlease let me know if this does help! Otherwise please make sure to share the full code so that I can try to replicate the issue.1 Reply", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/80"}, "80": {"author": "Jonathan_Kim1", "date": "1657062039855", "content": "Hi @CatalinaAlbornoz,\nThank you for your reply.\nWhen I try defining pars as you suggested I get:\nValueError: array is not broadcastable to correct shape\n\nAs a new user to the forums I cannot directly attach the full code but here is a google drive link to the full code: https://drive.google.com/drive/folders/1Ykp_ipqNVFtyrH02EXEwMcSEAAz9XECE?usp=sharing 1\nThis drive also includes the X_antbees, X_antbees_test, Y_antbees and Y_antbees_test txt files that must be contained in a folder named \u2018embedding_metric_learning\u2019, within the same directory as the \u2018tutorial_embeddings_metric_learning_test\u2019 code provided.\nThanks,\nJonathan", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/81"}, "81": {"author": "CatalinaAlbornoz", "date": "1657157828891", "content": "Hi @Jonathan_Kim1, thank you for posting the link to your code.\nI can confirm that I get the same warning. I\u2019m looking into the issue.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/82"}, "82": {"author": "Jonathan_Kim1", "date": "1657744904416", "content": "I\u2019ve managed to get the training to work (it doesn\u2019t seem to generalize at all for the validation dataset but that\u2019s a different issue) - I found that the training works for versions of pennylane 0.18.0 and earlier, but not for versions 0.19.0 onwards.", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/83"}, "83": {"author": "CatalinaAlbornoz", "date": "1657767452414", "content": "Thank you for sharing this insight @Jonathan_Kim1. Was there any particular change that you made that made it compatible with these versions? Or did you have to change a lot of the code?", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/84"}, "84": {"author": "Jonathan_Kim1", "date": "1657794301435", "content": "@CatalinaAlbornoz I didn\u2019t make any code changes, it just ran successfully as soon as I changed the version number. In versions 0.19.0 to 0.23.0, it doesn\u2019t run at all (there is an error message), while of course in versions 0.23.1 and versions 0.24.0 there only the warning message (but no parameter training occurs).\nVersions earlier than 0.18.0 work too, but versions prior to 0.15.0 run very slowly, although they do work (I think due to lack of support for the pennylane-lightning plugin, which is understandable).", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/85"}, "85": {"author": "CatalinaAlbornoz", "date": "1657843137485", "content": "Thank you for providing these details @Jonathan_Kim1!", "link": "https://discuss.pennylane.ai//t/quantum-transfer-learning-question/360/86"}}